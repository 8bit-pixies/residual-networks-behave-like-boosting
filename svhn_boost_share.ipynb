{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"svhn_boost_share.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"kt_bqdZgHt1b","colab_type":"code","outputId":"c3a71969-d0e3-443d-9618-d37d9520ad85","executionInfo":{"status":"ok","timestamp":1539852719219,"user_tz":-660,"elapsed":727,"user":{"displayName":"Anonymous Anonymous","photoUrl":"","userId":"12345678912345678912"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"metadata":{"id":"MZa5u_SOEbBl","colab_type":"code","outputId":"e2a6a571-aa54-478e-d2aa-1363def2e8a2","executionInfo":{"status":"ok","timestamp":1539852721627,"user_tz":-660,"elapsed":2074,"user":{"displayName":"Anonymous Anonymous","photoUrl":"","userId":"12345678912345678912"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["\"\"\"Trains a ResNet on the CIFAR10 dataset.\n","\n","ResNet v1\n","[a] Deep Residual Learning for Image Recognition\n","https://arxiv.org/pdf/1512.03385.pdf\n","\n","ResNet v2\n","[b] Identity Mappings in Deep Residual Networks\n","https://arxiv.org/pdf/1603.05027.pdf\n","\"\"\"\n","\n","import keras\n","from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n","from keras.layers import AveragePooling2D, Input, Flatten\n","from keras.optimizers import Adam\n","from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n","from keras.callbacks import ReduceLROnPlateau\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.regularizers import l2\n","from keras import backend as K\n","from keras.models import Model\n","from keras.datasets import cifar10\n","from keras.callbacks import Callback\n","\n","import numpy as np\n","import pandas as pd\n","from datetime import datetime\n","import time\n","import os\n","from keras.constraints import Constraint\n","from keras import initializers, layers\n","from keras.layers import Lambda\n","\n","import scipy.io as sio\n","\n","\n","\n","class ShrinkageConstraint(Constraint):\n","    def __init__(self, axis=0):\n","        self.axis = axis    \n","    \n","    def __call__(self, w):\n","        # apply unitnorm\n","        #w = w / (K.epsilon() + K.sqrt(K.sum(K.square(w),\n","        #                                    axis=self.axis,\n","        #                                    keepdims=True)))\n","        \n","        # apply non negative\n","        w *= K.cast(K.greater_equal(w, 0.), K.floatx())\n","        # apply max value to be 1\n","        w *= K.cast(K.less_equal(w, 1.), K.floatx())\n","        return w\n","\n","\n","class ShrinkageFactor(layers.Layer):\n","    \"\"\"\n","    This is the sigma object in the algorithm 1 by Beygelzimer (Online Gradient Boosting)\n","    \"\"\"\n","    def __init__(self, step_size, trainable=True, **kwargs):\n","        self.step_size = step_size\n","        self.trainable = trainable\n","        super(ShrinkageFactor, self).__init__(**kwargs)\n","    \n","    def build(self, input_shape):\n","        # Create a trainable weight variable for this layer.\n","        self.W = self.add_weight(name='highway', \n","                                 shape=(1, 1),\n","                                 initializer=initializers.Zeros(),\n","                                 constraint=ShrinkageConstraint(),\n","                                 regularizer=l2(0.01),\n","                                 trainable=self.trainable)\n","        self.count = K.variable(0, name=\"epoch\")\n","        super(ShrinkageFactor, self).build(input_shape)  # Be sure to call this at the end\n","    \n","    def call(self, x):\n","        return (1-self.step_size*self.W)*x\n","        updates = []\n","        \n","        if self.count < 80:\n","            updates.append((self.count, self.count+1))\n","            return x\n","        else:\n","            updates.append((self.count, self.count+1))\n","            return (1-self.step_size*self.W)*x\n","    \n","    def compute_output_shape(self, input_shape):\n","        if isinstance(input_shape, list):\n","            return input_shape[0]\n","        return input_shape\n","\n","class TimingCallback(Callback):\n","    def on_train_begin(self, logs={}):\n","        self.times = []\n","    \n","    def on_epoch_begin(self, batch, logs={}):\n","        self.epoch_time_start = time.time()\n","    \n","    def on_epoch_end(self, batch, logs={}):\n","        # write stuff to disc here...\n","        self.times.append(time.time() - self.epoch_time_start)\n","\n","def lr_schedule(epoch):\n","    \"\"\"Learning Rate Schedule\n","    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n","    Called automatically every epoch as part of callbacks during training.\n","    # Arguments\n","        epoch (int): The number of epochs\n","    # Returns\n","        lr (float32): learning rate\n","    \"\"\"\n","    lr = 1e-3\n","    if epoch > 180:\n","        lr *= 0.5e-3\n","    elif epoch > 160:\n","        lr *= 1e-3\n","    elif epoch > 120:\n","        lr *= 1e-2\n","    elif epoch > 80:\n","        lr *= 1e-1\n","    print('Learning rate: ', lr)\n","    return lr\n","\n","\n","def resnet_layer(inputs,\n","                 num_filters=16,\n","                 kernel_size=3,\n","                 strides=1,\n","                 activation='relu',\n","                 batch_normalization=True,\n","                 conv_first=True,\n","                 stack=0, \n","                 res_block=\"placeholder\"):\n","    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n","    \n","    # Arguments\n","        inputs (tensor): input tensor from input image or previous layer\n","        num_filters (int): Conv2D number of filters\n","        kernel_size (int): Conv2D square kernel dimensions\n","        strides (int): Conv2D square stride dimensions\n","        activation (string): activation name\n","        batch_normalization (bool): whether to include batch normalization\n","        conv_first (bool): conv-bn-activation (True) or\n","            bn-activation-conv (False)\n","        \n","        stack (int): stack number for layer naming purposes\n","        res_block (string): name of the res_block for naming purposes\n","    \n","    # Returns\n","        x (tensor): tensor as input to the next layer\n","    \"\"\"\n","    conv = Conv2D(num_filters,\n","                  kernel_size=kernel_size,\n","                  strides=strides,\n","                  padding='same',\n","                  kernel_initializer='he_normal',\n","                  kernel_regularizer=l2(1e-4),\n","                  name=f\"resnet_{stack}_{res_block}\"\n","                  )\n","    \n","    x = inputs\n","    if conv_first:\n","        x = conv(x)\n","        if batch_normalization:\n","            x = BatchNormalization(name=f\"bn_{stack}_{res_block}\")(x)\n","        if activation is not None:\n","            x = Activation(activation)(x)\n","    else:\n","        if batch_normalization:\n","            x = BatchNormalization(f\"bn_{stack}_{res_block}\")(x)\n","        if activation is not None:\n","            x = Activation(activation)(x)\n","        x = conv(x)\n","    return x\n","\n","\n","def resnet_block(x, stack, res_block, num_filters, boost=True):\n","    strides = 1\n","    if stack > 0 and res_block == 0:  # first layer but not first stack\n","        strides = 2  # downsample\n","    y = resnet_layer(inputs=x,\n","                     num_filters=num_filters,\n","                     strides=strides,\n","                     stack=stack,\n","                     res_block=f\"{res_block}a\")\n","    y = resnet_layer(inputs=y,\n","                     num_filters=num_filters,\n","                     activation=None,\n","                     stack=stack,\n","                     res_block=f\"{res_block}b\")\n","    if stack > 0 and res_block == 0:  # first layer but not first stack\n","        # linear projection residual shortcut connection to match\n","        # changed dims\n","        x = resnet_layer(inputs=x,\n","                         num_filters=num_filters,\n","                         kernel_size=1,\n","                         strides=strides,\n","                         activation=None,\n","                         batch_normalization=False,\n","                         stack=stack,\n","                         res_block=f\"{res_block}c\")\n","    \n","    if boost:\n","        step_size = 1.0\n","        y = ShrinkageFactor(step_size, False, name=f\"shrinkage_{stack}_{res_block}\")(y)\n","        # x = Lambda(lambda x: x * step_size, name=f\"shrinkage_lambda_{stack}_{res_block}\")(x)\n","    \n","    x = keras.layers.add([x, y], name=f\"add_{stack}_{res_block}\")\n","    x = Activation('relu')(x)\n","    return x\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"m_Sn5-vcAbuy","colab_type":"code","colab":{}},"cell_type":"code","source":["# Training parameters\n","batch_size = 32  # orig paper trained all networks with batch_size=128\n","epochs = 200\n","data_augmentation = True\n","num_classes = 10\n","\n","# Subtracting pixel mean improves accuracy\n","subtract_pixel_mean = True\n","\n","# Model parameter\n","# ----------------------------------------------------------------------------\n","#           |      | 200-epoch | Orig Paper| 200-epoch | Orig Paper| sec/epoch\n","# Model     |  n   | ResNet v1 | ResNet v1 | ResNet v2 | ResNet v2 | GTX1080Ti\n","#           |v1(v2)| %Accuracy | %Accuracy | %Accuracy | %Accuracy | v1 (v2)\n","# ----------------------------------------------------------------------------\n","# ResNet20  | 3 (2)| 92.16     | 91.25     | -----     | -----     | 35 (---)\n","# ResNet32  | 5(NA)| 92.46     | 92.49     | NA        | NA        | 50 ( NA)\n","# ResNet44  | 7(NA)| 92.50     | 92.83     | NA        | NA        | 70 ( NA)\n","# ResNet56  | 9 (6)| 92.71     | 93.03     | 93.01     | NA        | 90 (100)\n","# ResNet110 |18(12)| 92.65     | 93.39+-.16| 93.15     | 93.63     | 165(180)\n","# ResNet164 |27(18)| -----     | 94.07     | -----     | 94.54     | ---(---)\n","# ResNet1001| (111)| -----     | 92.39     | -----     | 95.08+-.14| ---(---)\n","# ---------------------------------------------------------------------------\n","n = 3\n","\n","# Model version\n","# Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\n","version = 1\n","\n","# Computed depth from supplied model parameter n\n","depth = n * 6 + 2 # n=3 --> 20, n=5 --> 32, n=7 --> 44, n=9 --> 56\n","\n","# Model name, depth and version\n","model_type = 'SVHN_ResNet%dv%d_shared' % (depth, version)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Si99s5jkAiXs","colab_type":"code","colab":{}},"cell_type":"code","source":["# Load SVHN (dataset 2)\n","path = \"/content/gdrive/My Drive/colab/svhn\"\n","train_images = sio.loadmat(path+'/train_32x32.mat')\n","test_images = sio.loadmat(path+'/test_32x32.mat')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"XN7-KxI8BSlQ","colab_type":"code","colab":{}},"cell_type":"code","source":["x_train = train_images[\"X\"]\n","x_train = np.transpose(x_train, (3, 0, 1, 2))\n","y_train = train_images[\"y\"]\n","y_train[y_train == 10] = 0\n","\n","x_test = test_images[\"X\"]\n","x_test = np.transpose(x_test, (3, 0, 1, 2))\n","y_test = test_images[\"y\"]\n","y_test[y_test == 10] = 0"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wab8Co6qDMpD","colab_type":"code","outputId":"51e53dc5-acc1-4eb7-e6ac-6e1afed730db","executionInfo":{"status":"ok","timestamp":1539852731174,"user_tz":-660,"elapsed":783,"user":{"displayName":"Anonymous Anonymous","photoUrl":"","userId":"12345678912345678912"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["x_test.shape"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(26032, 32, 32, 3)"]},"metadata":{"tags":[]},"execution_count":7}]},{"metadata":{"id":"buBpYdrSAglY","colab_type":"code","outputId":"d68c1132-495a-4f78-8962-9d475645e3e3","executionInfo":{"status":"ok","timestamp":1539852733733,"user_tz":-660,"elapsed":2397,"user":{"displayName":"Anonymous Anonymous","photoUrl":"","userId":"12345678912345678912"}},"colab":{"base_uri":"https://localhost:8080/","height":86}},"cell_type":"code","source":["\n","# Load the CIFAR10 data.\n","# (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","\n","# Input image dimensions.\n","input_shape = x_train.shape[1:]\n","\n","# Normalize data.\n","x_train = x_train.astype('float32') / 255\n","x_test = x_test.astype('float32') / 255\n","\n","# If subtract pixel mean is enabled\n","if subtract_pixel_mean:\n","    x_train_mean = np.mean(x_train, axis=0)\n","    x_train -= x_train_mean\n","    x_test -= x_train_mean\n","\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","print('y_train shape:', y_train.shape)\n","\n","# Convert class vectors to binary class matrices.\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["x_train shape: (73257, 32, 32, 3)\n","73257 train samples\n","26032 test samples\n","y_train shape: (73257, 1)\n"],"name":"stdout"}]},{"metadata":{"id":"ZBcYE65FCL5j","colab_type":"code","outputId":"93e26209-b2b3-4b0c-b4ff-8fea19e5524c","executionInfo":{"status":"ok","timestamp":1539852734588,"user_tz":-660,"elapsed":793,"user":{"displayName":"Anonymous Anonymous","photoUrl":"","userId":"12345678912345678912"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["73257/32"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2289.28125"]},"metadata":{"tags":[]},"execution_count":9}]},{"metadata":{"id":"qetyT-4WGRNt","colab_type":"code","outputId":"b298461d-3941-490b-e5e2-0032be457ade","executionInfo":{"status":"ok","timestamp":1539852740058,"user_tz":-660,"elapsed":5300,"user":{"displayName":"Anonymous Anonymous","photoUrl":"","userId":"12345678912345678912"}},"colab":{"base_uri":"https://localhost:8080/","height":3872}},"cell_type":"code","source":["# model = resnet_v1(input_shape=input_shape, depth=depth)\n","# we shall hardcode the model...with num_res_blocks=3\n","\n","\n","# model = resnet_v1(input_shape=input_shape, depth=depth)\n","# we shall hardcode the model...with num_res_blocks=3\n","\n","num_filters = 16\n","\n","inputs = Input(shape=input_shape)\n","x = resnet_layer(inputs=inputs, res_block='preprocessing')\n","\n","block0_0 = resnet_block(x, 0, 0, num_filters)\n","block0_1 = resnet_block(block0_0, 0, 1, num_filters)\n","block0_2 = resnet_block(block0_1, 0, 2, num_filters)\n","\n","block1_0 = resnet_block(block0_2, 1, 0, num_filters*2)\n","block1_1 = resnet_block(block1_0, 1, 1, num_filters*2)\n","block1_2 = resnet_block(block1_1, 1, 2, num_filters*2)\n","\n","block2_0 = resnet_block(block1_2, 2, 0, num_filters*4)\n","block2_1 = resnet_block(block2_0, 2, 1, num_filters*4)\n","block2_2 = resnet_block(block2_1, 2, 2, num_filters*4)\n","\n","block_output = AveragePooling2D(pool_size=8, name=\"avg_pool_2_2\")(block2_2)\n","block_output_flatten = Flatten(name=\"flatten_2_2\")(block_output)\n","#y = Dense(128)(block_output_flatten)\n","\n","pred_layer_0 = Dense(num_classes,\n","                activation='softmax',\n","                name='pred_layer_0')\n","\n","pred_layer_1 = Dense(num_classes,\n","                activation='softmax',\n","                name='pred_layer_1')\n","\n","pred_layer_2 = Dense(num_classes,\n","                activation='softmax',\n","                name='pred_layer_2')\n","outputs = pred_layer_2(block_output_flatten)\n","\n","# add auxiliary layers...\n","block0_0_output = AveragePooling2D(pool_size=8, name=\"avg_pool_0_0\")(block0_0)\n","block0_0_flatten = Flatten(name=\"flatten_0_0\")(block0_0_output)\n","#block0_0_y = Dense(128)(block0_0_flatten)\n","block0_0_outputs = pred_layer_0(block0_0_flatten)\n","\n","block0_1_output = AveragePooling2D(pool_size=8, name='avg_pool_0_1')(block0_1)\n","block0_1_flatten = Flatten(name=\"flatten_0_1\")(block0_1_output)\n","#block0_1_y = Dense(128)(block0_1_flatten)\n","block0_1_outputs = pred_layer_0(block0_1_flatten)\n","\n","\n","block0_2_output = AveragePooling2D(pool_size=8, name=\"avg_pool_0_2\")(block0_2)\n","block0_2_flatten = Flatten(name=\"flatten_0_2\")(block0_2_output)\n","#block0_2_y = Dense(128)(block0_2_flatten)\n","block0_2_outputs = pred_layer_0(block0_2_flatten)\n","\n","\n","block1_0_output = AveragePooling2D(pool_size=8, name=\"avg_pool_1_0\")(block1_0)\n","block1_0_flatten = Flatten(name=\"flatten_1_0\")(block1_0_output)\n","#block1_0_y = Dense(128)(block1_0_flatten)\n","block1_0_outputs = pred_layer_1(block1_0_flatten)\n","\n","\n","block1_1_output = AveragePooling2D(pool_size=8, name=\"avg_pool_1_1\")(block1_1)\n","block1_1_flatten = Flatten(name=\"flatten_1_1\")(block1_1_output)\n","#block1_1_y = Dense(128)(block1_1_flatten)\n","block1_1_outputs = pred_layer_1(block1_1_flatten)\n","\n","\n","block1_2_output = AveragePooling2D(pool_size=8, name=\"avg_pool_1_2\")(block1_2)\n","block1_2_flatten = Flatten(name=\"flatten_1_2\")(block1_2_output)\n","#block1_2_y = Dense(128)(block1_2_flatten)\n","block1_2_outputs = pred_layer_1(block1_2_flatten)\n","\n","\n","block2_0_output = AveragePooling2D(pool_size=8, name='avg_pool_2_0')(block2_0)\n","block2_0_flatten = Flatten(name=\"flatten_2_0\")(block2_0_output)\n","#block2_0_y = Dense(128)(block2_0_flatten)\n","block2_0_outputs = pred_layer_2(block2_0_flatten)\n","\n","\n","block2_1_output = AveragePooling2D(pool_size=8, name=\"avg_pool_2_1\")(block2_1)\n","block2_1_flatten = Flatten(name=\"flatten_2_1\")(block2_1_output)\n","#block2_1_y = Dense(128)(block2_1_flatten)\n","block2_1_outputs = pred_layer_2(block2_1_flatten)\n","\n","\n","# block2_2_output = AveragePooling2D(pool_size=4)(block2_2)\n","# block2_2_flatten = Flatten()(block2_2_output)\n","# block2_2_y = Dense(128)(block2_2_flatten)\n","# block2_2_outputs = pred_layer(block2_2_y)\n","\n","model = Model(inputs=[inputs], outputs=[outputs, block0_0_outputs, block0_1_outputs, block0_2_outputs, block1_0_outputs, block1_1_outputs, block1_2_outputs, block2_0_outputs, block2_1_outputs])\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=Adam(lr=lr_schedule(0)),\n","              metrics=['accuracy'])\n","model.summary()\n","\n","# print(model_type)\n","\n","# Prepare model model saving directory.\n","save_dir = os.path.join(os.getcwd(), 'saved_models')\n","save_dir = \"/content/gdrive/My Drive/colab/weights/\"\n","model_name = 'svhn_%s_model.{epoch:03d}.h5' % model_type\n","if not os.path.isdir(save_dir):\n","    os.makedirs(save_dir)\n","filepath = os.path.join(save_dir, model_name)\n","\n","# Prepare callbacks for model saving and for learning rate adjustment.\n","checkpoint = ModelCheckpoint(filepath=filepath,\n","                             monitor='val_pred_layer_2_acc',\n","                             verbose=1,\n","                             save_best_only=True)\n","\n","lr_scheduler = LearningRateScheduler(lr_schedule)\n","\n","lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n","                               cooldown=0,\n","                               patience=5,\n","                               min_lr=0.5e-6)\n","\n","time_cb = TimingCallback()\n","\n","callbacks = [checkpoint, lr_reducer, lr_scheduler, time_cb]\n","\n","print('Using real-time data augmentation.')\n","# This will do preprocessing and realtime data augmentation:\n","datagen = ImageDataGenerator(\n","    # set input mean to 0 over the dataset\n","    featurewise_center=False,\n","    # set each sample mean to 0\n","    samplewise_center=False,\n","    # divide inputs by std of dataset\n","    featurewise_std_normalization=False,\n","    # divide each input by its std\n","    samplewise_std_normalization=False,\n","    # apply ZCA whitening\n","    zca_whitening=False,\n","    # epsilon for ZCA whitening\n","    zca_epsilon=1e-06,\n","    # randomly rotate images in the range (deg 0 to 180)\n","    rotation_range=0,\n","    # randomly shift images horizontally\n","    width_shift_range=0.1,\n","    # randomly shift images vertically\n","    height_shift_range=0.1,\n","    # set range for random shear\n","    shear_range=0.,\n","    # set range for random zoom\n","    zoom_range=0.,\n","    # set range for random channel shifts\n","    channel_shift_range=0.,\n","    # set mode for filling points outside the input boundaries\n","    fill_mode='nearest',\n","    # value used for fill_mode = \"constant\"\n","    cval=0.,\n","    # randomly flip images\n","    horizontal_flip=True,\n","    # randomly flip images\n","    vertical_flip=False,\n","    # set rescaling factor (applied before any other transformation)\n","    rescale=None,\n","    # set function that will be applied on each input\n","    preprocessing_function=None,\n","    # image data format, either \"channels_first\" or \"channels_last\"\n","    data_format=None,\n","    # fraction of images reserved for validation (strictly between 0 and 1)\n","    validation_split=0.0)\n","\n","# Compute quantities required for featurewise normalization\n","# (std, mean, and principal components if ZCA whitening is applied).\n","datagen.fit(x_train)\n","\n","\n","def data_gen(gen, x, y1, y2, y3, y4, y5, y6, y7, y8, y9):\n","    gen = gen.flow(x, y1, seed=7, batch_size=batch_size)\n","    while True:\n","        X = gen.next()\n","        #Assert arrays are equal - this was for peace of mind, but slows down training\n","        #np.testing.assert_array_equal(X1i[0],X2i[0])\n","        yield X[0], [X[1], X[1], X[1], X[1], X[1], X[1], X[1], X[1], X[1]]\n"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Learning rate:  0.001\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n","__________________________________________________________________________________________________\n","resnet_0_preprocessing (Conv2D) (None, 32, 32, 16)   448         input_1[0][0]                    \n","__________________________________________________________________________________________________\n","bn_0_preprocessing (BatchNormal (None, 32, 32, 16)   64          resnet_0_preprocessing[0][0]     \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 32, 32, 16)   0           bn_0_preprocessing[0][0]         \n","__________________________________________________________________________________________________\n","resnet_0_0a (Conv2D)            (None, 32, 32, 16)   2320        activation_1[0][0]               \n","__________________________________________________________________________________________________\n","bn_0_0a (BatchNormalization)    (None, 32, 32, 16)   64          resnet_0_0a[0][0]                \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 32, 32, 16)   0           bn_0_0a[0][0]                    \n","__________________________________________________________________________________________________\n","resnet_0_0b (Conv2D)            (None, 32, 32, 16)   2320        activation_2[0][0]               \n","__________________________________________________________________________________________________\n","bn_0_0b (BatchNormalization)    (None, 32, 32, 16)   64          resnet_0_0b[0][0]                \n","__________________________________________________________________________________________________\n","shrinkage_0_0 (ShrinkageFactor) (None, 32, 32, 16)   1           bn_0_0b[0][0]                    \n","__________________________________________________________________________________________________\n","add_0_0 (Add)                   (None, 32, 32, 16)   0           activation_1[0][0]               \n","                                                                 shrinkage_0_0[0][0]              \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 32, 32, 16)   0           add_0_0[0][0]                    \n","__________________________________________________________________________________________________\n","resnet_0_1a (Conv2D)            (None, 32, 32, 16)   2320        activation_3[0][0]               \n","__________________________________________________________________________________________________\n","bn_0_1a (BatchNormalization)    (None, 32, 32, 16)   64          resnet_0_1a[0][0]                \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 32, 32, 16)   0           bn_0_1a[0][0]                    \n","__________________________________________________________________________________________________\n","resnet_0_1b (Conv2D)            (None, 32, 32, 16)   2320        activation_4[0][0]               \n","__________________________________________________________________________________________________\n","bn_0_1b (BatchNormalization)    (None, 32, 32, 16)   64          resnet_0_1b[0][0]                \n","__________________________________________________________________________________________________\n","shrinkage_0_1 (ShrinkageFactor) (None, 32, 32, 16)   1           bn_0_1b[0][0]                    \n","__________________________________________________________________________________________________\n","add_0_1 (Add)                   (None, 32, 32, 16)   0           activation_3[0][0]               \n","                                                                 shrinkage_0_1[0][0]              \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 32, 32, 16)   0           add_0_1[0][0]                    \n","__________________________________________________________________________________________________\n","resnet_0_2a (Conv2D)            (None, 32, 32, 16)   2320        activation_5[0][0]               \n","__________________________________________________________________________________________________\n","bn_0_2a (BatchNormalization)    (None, 32, 32, 16)   64          resnet_0_2a[0][0]                \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 32, 32, 16)   0           bn_0_2a[0][0]                    \n","__________________________________________________________________________________________________\n","resnet_0_2b (Conv2D)            (None, 32, 32, 16)   2320        activation_6[0][0]               \n","__________________________________________________________________________________________________\n","bn_0_2b (BatchNormalization)    (None, 32, 32, 16)   64          resnet_0_2b[0][0]                \n","__________________________________________________________________________________________________\n","shrinkage_0_2 (ShrinkageFactor) (None, 32, 32, 16)   1           bn_0_2b[0][0]                    \n","__________________________________________________________________________________________________\n","add_0_2 (Add)                   (None, 32, 32, 16)   0           activation_5[0][0]               \n","                                                                 shrinkage_0_2[0][0]              \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 32, 32, 16)   0           add_0_2[0][0]                    \n","__________________________________________________________________________________________________\n","resnet_1_0a (Conv2D)            (None, 16, 16, 32)   4640        activation_7[0][0]               \n","__________________________________________________________________________________________________\n","bn_1_0a (BatchNormalization)    (None, 16, 16, 32)   128         resnet_1_0a[0][0]                \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 16, 16, 32)   0           bn_1_0a[0][0]                    \n","__________________________________________________________________________________________________\n","resnet_1_0b (Conv2D)            (None, 16, 16, 32)   9248        activation_8[0][0]               \n","__________________________________________________________________________________________________\n","bn_1_0b (BatchNormalization)    (None, 16, 16, 32)   128         resnet_1_0b[0][0]                \n","__________________________________________________________________________________________________\n","resnet_1_0c (Conv2D)            (None, 16, 16, 32)   544         activation_7[0][0]               \n","__________________________________________________________________________________________________\n","shrinkage_1_0 (ShrinkageFactor) (None, 16, 16, 32)   1           bn_1_0b[0][0]                    \n","__________________________________________________________________________________________________\n","add_1_0 (Add)                   (None, 16, 16, 32)   0           resnet_1_0c[0][0]                \n","                                                                 shrinkage_1_0[0][0]              \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 16, 16, 32)   0           add_1_0[0][0]                    \n","__________________________________________________________________________________________________\n","resnet_1_1a (Conv2D)            (None, 16, 16, 32)   9248        activation_9[0][0]               \n","__________________________________________________________________________________________________\n","bn_1_1a (BatchNormalization)    (None, 16, 16, 32)   128         resnet_1_1a[0][0]                \n","__________________________________________________________________________________________________\n","activation_10 (Activation)      (None, 16, 16, 32)   0           bn_1_1a[0][0]                    \n","__________________________________________________________________________________________________\n","resnet_1_1b (Conv2D)            (None, 16, 16, 32)   9248        activation_10[0][0]              \n","__________________________________________________________________________________________________\n","bn_1_1b (BatchNormalization)    (None, 16, 16, 32)   128         resnet_1_1b[0][0]                \n","__________________________________________________________________________________________________\n","shrinkage_1_1 (ShrinkageFactor) (None, 16, 16, 32)   1           bn_1_1b[0][0]                    \n","__________________________________________________________________________________________________\n","add_1_1 (Add)                   (None, 16, 16, 32)   0           activation_9[0][0]               \n","                                                                 shrinkage_1_1[0][0]              \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 16, 16, 32)   0           add_1_1[0][0]                    \n","__________________________________________________________________________________________________\n","resnet_1_2a (Conv2D)            (None, 16, 16, 32)   9248        activation_11[0][0]              \n","__________________________________________________________________________________________________\n","bn_1_2a (BatchNormalization)    (None, 16, 16, 32)   128         resnet_1_2a[0][0]                \n","__________________________________________________________________________________________________\n","activation_12 (Activation)      (None, 16, 16, 32)   0           bn_1_2a[0][0]                    \n","__________________________________________________________________________________________________\n","resnet_1_2b (Conv2D)            (None, 16, 16, 32)   9248        activation_12[0][0]              \n","__________________________________________________________________________________________________\n","bn_1_2b (BatchNormalization)    (None, 16, 16, 32)   128         resnet_1_2b[0][0]                \n","__________________________________________________________________________________________________\n","shrinkage_1_2 (ShrinkageFactor) (None, 16, 16, 32)   1           bn_1_2b[0][0]                    \n","__________________________________________________________________________________________________\n","add_1_2 (Add)                   (None, 16, 16, 32)   0           activation_11[0][0]              \n","                                                                 shrinkage_1_2[0][0]              \n","__________________________________________________________________________________________________\n","activation_13 (Activation)      (None, 16, 16, 32)   0           add_1_2[0][0]                    \n","__________________________________________________________________________________________________\n","resnet_2_0a (Conv2D)            (None, 8, 8, 64)     18496       activation_13[0][0]              \n","__________________________________________________________________________________________________\n","bn_2_0a (BatchNormalization)    (None, 8, 8, 64)     256         resnet_2_0a[0][0]                \n","__________________________________________________________________________________________________\n","activation_14 (Activation)      (None, 8, 8, 64)     0           bn_2_0a[0][0]                    \n","__________________________________________________________________________________________________\n","resnet_2_0b (Conv2D)            (None, 8, 8, 64)     36928       activation_14[0][0]              \n","__________________________________________________________________________________________________\n","bn_2_0b (BatchNormalization)    (None, 8, 8, 64)     256         resnet_2_0b[0][0]                \n","__________________________________________________________________________________________________\n","resnet_2_0c (Conv2D)            (None, 8, 8, 64)     2112        activation_13[0][0]              \n","__________________________________________________________________________________________________\n","shrinkage_2_0 (ShrinkageFactor) (None, 8, 8, 64)     1           bn_2_0b[0][0]                    \n","__________________________________________________________________________________________________\n","add_2_0 (Add)                   (None, 8, 8, 64)     0           resnet_2_0c[0][0]                \n","                                                                 shrinkage_2_0[0][0]              \n","__________________________________________________________________________________________________\n","activation_15 (Activation)      (None, 8, 8, 64)     0           add_2_0[0][0]                    \n","__________________________________________________________________________________________________\n","resnet_2_1a (Conv2D)            (None, 8, 8, 64)     36928       activation_15[0][0]              \n","__________________________________________________________________________________________________\n","bn_2_1a (BatchNormalization)    (None, 8, 8, 64)     256         resnet_2_1a[0][0]                \n","__________________________________________________________________________________________________\n","activation_16 (Activation)      (None, 8, 8, 64)     0           bn_2_1a[0][0]                    \n","__________________________________________________________________________________________________\n","resnet_2_1b (Conv2D)            (None, 8, 8, 64)     36928       activation_16[0][0]              \n","__________________________________________________________________________________________________\n","bn_2_1b (BatchNormalization)    (None, 8, 8, 64)     256         resnet_2_1b[0][0]                \n","__________________________________________________________________________________________________\n","shrinkage_2_1 (ShrinkageFactor) (None, 8, 8, 64)     1           bn_2_1b[0][0]                    \n","__________________________________________________________________________________________________\n","add_2_1 (Add)                   (None, 8, 8, 64)     0           activation_15[0][0]              \n","                                                                 shrinkage_2_1[0][0]              \n","__________________________________________________________________________________________________\n","activation_17 (Activation)      (None, 8, 8, 64)     0           add_2_1[0][0]                    \n","__________________________________________________________________________________________________\n","resnet_2_2a (Conv2D)            (None, 8, 8, 64)     36928       activation_17[0][0]              \n","__________________________________________________________________________________________________\n","bn_2_2a (BatchNormalization)    (None, 8, 8, 64)     256         resnet_2_2a[0][0]                \n","__________________________________________________________________________________________________\n","activation_18 (Activation)      (None, 8, 8, 64)     0           bn_2_2a[0][0]                    \n","__________________________________________________________________________________________________\n","resnet_2_2b (Conv2D)            (None, 8, 8, 64)     36928       activation_18[0][0]              \n","__________________________________________________________________________________________________\n","bn_2_2b (BatchNormalization)    (None, 8, 8, 64)     256         resnet_2_2b[0][0]                \n","__________________________________________________________________________________________________\n","shrinkage_2_2 (ShrinkageFactor) (None, 8, 8, 64)     1           bn_2_2b[0][0]                    \n","__________________________________________________________________________________________________\n","add_2_2 (Add)                   (None, 8, 8, 64)     0           activation_17[0][0]              \n","                                                                 shrinkage_2_2[0][0]              \n","__________________________________________________________________________________________________\n","activation_19 (Activation)      (None, 8, 8, 64)     0           add_2_2[0][0]                    \n","__________________________________________________________________________________________________\n","avg_pool_2_2 (AveragePooling2D) (None, 1, 1, 64)     0           activation_19[0][0]              \n","__________________________________________________________________________________________________\n","avg_pool_0_0 (AveragePooling2D) (None, 4, 4, 16)     0           activation_3[0][0]               \n","__________________________________________________________________________________________________\n","avg_pool_0_1 (AveragePooling2D) (None, 4, 4, 16)     0           activation_5[0][0]               \n","__________________________________________________________________________________________________\n","avg_pool_0_2 (AveragePooling2D) (None, 4, 4, 16)     0           activation_7[0][0]               \n","__________________________________________________________________________________________________\n","avg_pool_1_0 (AveragePooling2D) (None, 2, 2, 32)     0           activation_9[0][0]               \n","__________________________________________________________________________________________________\n","avg_pool_1_1 (AveragePooling2D) (None, 2, 2, 32)     0           activation_11[0][0]              \n","__________________________________________________________________________________________________\n","avg_pool_1_2 (AveragePooling2D) (None, 2, 2, 32)     0           activation_13[0][0]              \n","__________________________________________________________________________________________________\n","avg_pool_2_0 (AveragePooling2D) (None, 1, 1, 64)     0           activation_15[0][0]              \n","__________________________________________________________________________________________________\n","avg_pool_2_1 (AveragePooling2D) (None, 1, 1, 64)     0           activation_17[0][0]              \n","__________________________________________________________________________________________________\n","flatten_2_2 (Flatten)           (None, 64)           0           avg_pool_2_2[0][0]               \n","__________________________________________________________________________________________________\n","flatten_0_0 (Flatten)           (None, 256)          0           avg_pool_0_0[0][0]               \n","__________________________________________________________________________________________________\n","flatten_0_1 (Flatten)           (None, 256)          0           avg_pool_0_1[0][0]               \n","__________________________________________________________________________________________________\n","flatten_0_2 (Flatten)           (None, 256)          0           avg_pool_0_2[0][0]               \n","__________________________________________________________________________________________________\n","flatten_1_0 (Flatten)           (None, 128)          0           avg_pool_1_0[0][0]               \n","__________________________________________________________________________________________________\n","flatten_1_1 (Flatten)           (None, 128)          0           avg_pool_1_1[0][0]               \n","__________________________________________________________________________________________________\n","flatten_1_2 (Flatten)           (None, 128)          0           avg_pool_1_2[0][0]               \n","__________________________________________________________________________________________________\n","flatten_2_0 (Flatten)           (None, 64)           0           avg_pool_2_0[0][0]               \n","__________________________________________________________________________________________________\n","flatten_2_1 (Flatten)           (None, 64)           0           avg_pool_2_1[0][0]               \n","__________________________________________________________________________________________________\n","pred_layer_2 (Dense)            (None, 10)           650         flatten_2_2[0][0]                \n","                                                                 flatten_2_0[0][0]                \n","                                                                 flatten_2_1[0][0]                \n","__________________________________________________________________________________________________\n","pred_layer_0 (Dense)            (None, 10)           2570        flatten_0_0[0][0]                \n","                                                                 flatten_0_1[0][0]                \n","                                                                 flatten_0_2[0][0]                \n","__________________________________________________________________________________________________\n","pred_layer_1 (Dense)            (None, 10)           1290        flatten_1_0[0][0]                \n","                                                                 flatten_1_1[0][0]                \n","                                                                 flatten_1_2[0][0]                \n","==================================================================================================\n","Total params: 278,311\n","Trainable params: 276,935\n","Non-trainable params: 1,376\n","__________________________________________________________________________________________________\n","Using real-time data augmentation.\n"],"name":"stdout"}]},{"metadata":{"id":"tmQlq24uGWZV","colab_type":"code","outputId":"b6bbfeee-a140-440c-d40c-0c3ed6d414fa","executionInfo":{"status":"ok","timestamp":1539763223926,"user_tz":-660,"elapsed":1794296,"user":{"displayName":"Anonymous Anonymous","photoUrl":"","userId":"12345678912345678912"}},"colab":{"base_uri":"https://localhost:8080/","height":13270}},"cell_type":"code","source":["\n","\n","# Fit the model on the batches generated by datagen.flow().\n","hist = model.fit_generator(data_gen(datagen, x_train, y_train, y_train, y_train, y_train, y_train, y_train, y_train, y_train, y_train),\n","                    validation_data=(x_test, [y_test, y_test, y_test, y_test, y_test, y_test, y_test, y_test, y_test]),\n","                    steps_per_epoch=2290,\n","                    epochs=epochs, verbose=2, workers=10,\n","                    callbacks=callbacks)\n","hist_df = pd.DataFrame(hist.history)\n","hist_df['times'] = time_cb.times[-hist_df.shape[0]:]\n","hist_df.to_csv('/content/gdrive/My Drive/colab/weights/svhn_training_history_resnetv1_share{}.csv'.format(datetime.now().strftime('%Y-%m-%d_%H-%M-%S')), index=True)\n","\n","# Score trained model.\n","scores = model.evaluate(x_test, [y_test], verbose=1)\n","print('Test output:', scores)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/200\n","Learning rate:  0.001\n"," - 288s - loss: 11.9501 - pred_layer_2_loss: 0.9650 - pred_layer_0_loss: 1.5006 - pred_layer_1_loss: 1.0799 - pred_layer_2_acc: 0.6845 - pred_layer_0_acc: 0.3804 - pred_layer_0_acc_1: 0.4624 - pred_layer_0_acc_2: 0.4915 - pred_layer_1_acc: 0.4827 - pred_layer_1_acc_1: 0.6026 - pred_layer_1_acc_2: 0.6400 - pred_layer_2_acc_1: 0.6365 - pred_layer_2_acc_2: 0.6804 - val_loss: 8.7629 - val_pred_layer_2_loss: 0.8044 - val_pred_layer_0_loss: 1.0369 - val_pred_layer_1_loss: 0.7233 - val_pred_layer_2_acc: 0.7487 - val_pred_layer_0_acc: 0.5426 - val_pred_layer_0_acc_1: 0.6262 - val_pred_layer_0_acc_2: 0.6725 - val_pred_layer_1_acc: 0.6909 - val_pred_layer_1_acc_1: 0.7596 - val_pred_layer_1_acc_2: 0.7664 - val_pred_layer_2_acc_1: 0.7349 - val_pred_layer_2_acc_2: 0.7382\n","\n","Epoch 00001: val_pred_layer_2_acc improved from -inf to 0.74873, saving model to /content/gdrive/My Drive/colab/weights/svhn_SVHN_ResNet20v1_shared_model.001.h5\n","Epoch 2/200\n","Learning rate:  0.001\n"," - 278s - loss: 7.2271 - pred_layer_2_loss: 0.4652 - pred_layer_0_loss: 1.0471 - pred_layer_1_loss: 0.5430 - pred_layer_2_acc: 0.8546 - pred_layer_0_acc: 0.5651 - pred_layer_0_acc_1: 0.6360 - pred_layer_0_acc_2: 0.6621 - pred_layer_1_acc: 0.7041 - pred_layer_1_acc_1: 0.8044 - pred_layer_1_acc_2: 0.8309 - pred_layer_2_acc_1: 0.8451 - pred_layer_2_acc_2: 0.8549 - val_loss: 6.1108 - val_pred_layer_2_loss: 0.4228 - val_pred_layer_0_loss: 0.8293 - val_pred_layer_1_loss: 0.4445 - val_pred_layer_2_acc: 0.8704 - val_pred_layer_0_acc: 0.6317 - val_pred_layer_0_acc_1: 0.7154 - val_pred_layer_0_acc_2: 0.7419 - val_pred_layer_1_acc: 0.7740 - val_pred_layer_1_acc_1: 0.8336 - val_pred_layer_1_acc_2: 0.8644 - val_pred_layer_2_acc_1: 0.8701 - val_pred_layer_2_acc_2: 0.8705\n","\n","Epoch 00002: val_pred_layer_2_acc improved from 0.74873 to 0.87043, saving model to /content/gdrive/My Drive/colab/weights/svhn_SVHN_ResNet20v1_shared_model.002.h5\n","Epoch 3/200\n","Learning rate:  0.001\n"," - 276s - loss: 6.3136 - pred_layer_2_loss: 0.4018 - pred_layer_0_loss: 0.9400 - pred_layer_1_loss: 0.4603 - pred_layer_2_acc: 0.8771 - pred_layer_0_acc: 0.6131 - pred_layer_0_acc_1: 0.6779 - pred_layer_0_acc_2: 0.7023 - pred_layer_1_acc: 0.7563 - pred_layer_1_acc_1: 0.8367 - pred_layer_1_acc_2: 0.8581 - pred_layer_2_acc_1: 0.8722 - pred_layer_2_acc_2: 0.8776 - val_loss: 5.5044 - val_pred_layer_2_loss: 0.3830 - val_pred_layer_0_loss: 0.7580 - val_pred_layer_1_loss: 0.3654 - val_pred_layer_2_acc: 0.8802 - val_pred_layer_0_acc: 0.6579 - val_pred_layer_0_acc_1: 0.7218 - val_pred_layer_0_acc_2: 0.7588 - val_pred_layer_1_acc: 0.7831 - val_pred_layer_1_acc_1: 0.8736 - val_pred_layer_1_acc_2: 0.8900 - val_pred_layer_2_acc_1: 0.8814 - val_pred_layer_2_acc_2: 0.8850\n","\n","Epoch 00003: val_pred_layer_2_acc improved from 0.87043 to 0.88019, saving model to /content/gdrive/My Drive/colab/weights/svhn_SVHN_ResNet20v1_shared_model.003.h5\n","Epoch 4/200\n","Learning rate:  0.001\n"," - 276s - loss: 5.7904 - pred_layer_2_loss: 0.3654 - pred_layer_0_loss: 0.8708 - pred_layer_1_loss: 0.4166 - pred_layer_2_acc: 0.8873 - pred_layer_0_acc: 0.6403 - pred_layer_0_acc_1: 0.6994 - pred_layer_0_acc_2: 0.7231 - pred_layer_1_acc: 0.7858 - pred_layer_1_acc_1: 0.8550 - pred_layer_1_acc_2: 0.8729 - pred_layer_2_acc_1: 0.8849 - pred_layer_2_acc_2: 0.8879 - val_loss: 4.8991 - val_pred_layer_2_loss: 0.3481 - val_pred_layer_0_loss: 0.7066 - val_pred_layer_1_loss: 0.3170 - val_pred_layer_2_acc: 0.8966 - val_pred_layer_0_acc: 0.6991 - val_pred_layer_0_acc_1: 0.7558 - val_pred_layer_0_acc_2: 0.7737 - val_pred_layer_1_acc: 0.8229 - val_pred_layer_1_acc_1: 0.8920 - val_pred_layer_1_acc_2: 0.9070 - val_pred_layer_2_acc_1: 0.9016 - val_pred_layer_2_acc_2: 0.8965\n","\n","Epoch 00004: val_pred_layer_2_acc improved from 0.88019 to 0.89655, saving model to /content/gdrive/My Drive/colab/weights/svhn_SVHN_ResNet20v1_shared_model.004.h5\n","Epoch 5/200\n","Learning rate:  0.001\n"," - 274s - loss: 5.4898 - pred_layer_2_loss: 0.3450 - pred_layer_0_loss: 0.8309 - pred_layer_1_loss: 0.3934 - pred_layer_2_acc: 0.8954 - pred_layer_0_acc: 0.6622 - pred_layer_0_acc_1: 0.7156 - pred_layer_0_acc_2: 0.7382 - pred_layer_1_acc: 0.8001 - pred_layer_1_acc_1: 0.8621 - pred_layer_1_acc_2: 0.8794 - pred_layer_2_acc_1: 0.8933 - pred_layer_2_acc_2: 0.8956 - val_loss: 4.7242 - val_pred_layer_2_loss: 0.3427 - val_pred_layer_0_loss: 0.6686 - val_pred_layer_1_loss: 0.3096 - val_pred_layer_2_acc: 0.8972 - val_pred_layer_0_acc: 0.7059 - val_pred_layer_0_acc_1: 0.7553 - val_pred_layer_0_acc_2: 0.7892 - val_pred_layer_1_acc: 0.8453 - val_pred_layer_1_acc_1: 0.8896 - val_pred_layer_1_acc_2: 0.9088 - val_pred_layer_2_acc_1: 0.9021 - val_pred_layer_2_acc_2: 0.8968\n","\n","Epoch 00005: val_pred_layer_2_acc improved from 0.89655 to 0.89724, saving model to /content/gdrive/My Drive/colab/weights/svhn_SVHN_ResNet20v1_shared_model.005.h5\n","Epoch 6/200\n","Learning rate:  0.001\n"," - 274s - loss: 5.2684 - pred_layer_2_loss: 0.3304 - pred_layer_0_loss: 0.7978 - pred_layer_1_loss: 0.3734 - pred_layer_2_acc: 0.9000 - pred_layer_0_acc: 0.6740 - pred_layer_0_acc_1: 0.7250 - pred_layer_0_acc_2: 0.7475 - pred_layer_1_acc: 0.8115 - pred_layer_1_acc_1: 0.8707 - pred_layer_1_acc_2: 0.8867 - pred_layer_2_acc_1: 0.8988 - pred_layer_2_acc_2: 0.8998 - val_loss: 4.3642 - val_pred_layer_2_loss: 0.2589 - val_pred_layer_0_loss: 0.6676 - val_pred_layer_1_loss: 0.2844 - val_pred_layer_2_acc: 0.9241 - val_pred_layer_0_acc: 0.7277 - val_pred_layer_0_acc_1: 0.7693 - val_pred_layer_0_acc_2: 0.7905 - val_pred_layer_1_acc: 0.8435 - val_pred_layer_1_acc_1: 0.9029 - val_pred_layer_1_acc_2: 0.9174 - val_pred_layer_2_acc_1: 0.9203 - val_pred_layer_2_acc_2: 0.9239\n","\n","Epoch 00006: val_pred_layer_2_acc improved from 0.89724 to 0.92406, saving model to /content/gdrive/My Drive/colab/weights/svhn_SVHN_ResNet20v1_shared_model.006.h5\n","Epoch 7/200\n","Learning rate:  0.001\n"," - 269s - loss: 5.1017 - pred_layer_2_loss: 0.3175 - pred_layer_0_loss: 0.7731 - pred_layer_1_loss: 0.3594 - pred_layer_2_acc: 0.9039 - pred_layer_0_acc: 0.6842 - pred_layer_0_acc_1: 0.7320 - pred_layer_0_acc_2: 0.7562 - pred_layer_1_acc: 0.8219 - pred_layer_1_acc_1: 0.8779 - pred_layer_1_acc_2: 0.8917 - pred_layer_2_acc_1: 0.9032 - pred_layer_2_acc_2: 0.9044 - val_loss: 4.5380 - val_pred_layer_2_loss: 0.3102 - val_pred_layer_0_loss: 0.6584 - val_pred_layer_1_loss: 0.3133 - val_pred_layer_2_acc: 0.9086 - val_pred_layer_0_acc: 0.7337 - val_pred_layer_0_acc_1: 0.7744 - val_pred_layer_0_acc_2: 0.7878 - val_pred_layer_1_acc: 0.8345 - val_pred_layer_1_acc_1: 0.8863 - val_pred_layer_1_acc_2: 0.9073 - val_pred_layer_2_acc_1: 0.9073 - val_pred_layer_2_acc_2: 0.9077\n","\n","Epoch 00007: val_pred_layer_2_acc did not improve from 0.92406\n","Epoch 8/200\n","Learning rate:  0.001\n"," - 270s - loss: 4.9414 - pred_layer_2_loss: 0.3069 - pred_layer_0_loss: 0.7468 - pred_layer_1_loss: 0.3463 - pred_layer_2_acc: 0.9069 - pred_layer_0_acc: 0.6915 - pred_layer_0_acc_1: 0.7410 - pred_layer_0_acc_2: 0.7652 - pred_layer_1_acc: 0.8290 - pred_layer_1_acc_1: 0.8812 - pred_layer_1_acc_2: 0.8946 - pred_layer_2_acc_1: 0.9063 - pred_layer_2_acc_2: 0.9073 - val_loss: 4.3480 - val_pred_layer_2_loss: 0.2885 - val_pred_layer_0_loss: 0.6428 - val_pred_layer_1_loss: 0.3062 - val_pred_layer_2_acc: 0.9161 - val_pred_layer_0_acc: 0.7417 - val_pred_layer_0_acc_1: 0.7816 - val_pred_layer_0_acc_2: 0.7952 - val_pred_layer_1_acc: 0.8564 - val_pred_layer_1_acc_1: 0.8978 - val_pred_layer_1_acc_2: 0.9101 - val_pred_layer_2_acc_1: 0.9181 - val_pred_layer_2_acc_2: 0.9161\n","\n","Epoch 00008: val_pred_layer_2_acc did not improve from 0.92406\n","Epoch 9/200\n","Learning rate:  0.001\n"," - 269s - loss: 4.8342 - pred_layer_2_loss: 0.2990 - pred_layer_0_loss: 0.7300 - pred_layer_1_loss: 0.3370 - pred_layer_2_acc: 0.9105 - pred_layer_0_acc: 0.6969 - pred_layer_0_acc_1: 0.7472 - pred_layer_0_acc_2: 0.7701 - pred_layer_1_acc: 0.8358 - pred_layer_1_acc_1: 0.8859 - pred_layer_1_acc_2: 0.8995 - pred_layer_2_acc_1: 0.9102 - pred_layer_2_acc_2: 0.9109 - val_loss: 4.1425 - val_pred_layer_2_loss: 0.2644 - val_pred_layer_0_loss: 0.6040 - val_pred_layer_1_loss: 0.2853 - val_pred_layer_2_acc: 0.9234 - val_pred_layer_0_acc: 0.7417 - val_pred_layer_0_acc_1: 0.7886 - val_pred_layer_0_acc_2: 0.8102 - val_pred_layer_1_acc: 0.8603 - val_pred_layer_1_acc_1: 0.9088 - val_pred_layer_1_acc_2: 0.9166 - val_pred_layer_2_acc_1: 0.9230 - val_pred_layer_2_acc_2: 0.9225\n","\n","Epoch 00009: val_pred_layer_2_acc did not improve from 0.92406\n","Epoch 10/200\n","Learning rate:  0.001\n"," - 273s - loss: 4.7467 - pred_layer_2_loss: 0.2932 - pred_layer_0_loss: 0.7118 - pred_layer_1_loss: 0.3300 - pred_layer_2_acc: 0.9107 - pred_layer_0_acc: 0.7020 - pred_layer_0_acc_1: 0.7503 - pred_layer_0_acc_2: 0.7756 - pred_layer_1_acc: 0.8396 - pred_layer_1_acc_1: 0.8879 - pred_layer_1_acc_2: 0.9003 - pred_layer_2_acc_1: 0.9109 - pred_layer_2_acc_2: 0.9107 - val_loss: 4.0512 - val_pred_layer_2_loss: 0.2595 - val_pred_layer_0_loss: 0.5949 - val_pred_layer_1_loss: 0.2865 - val_pred_layer_2_acc: 0.9266 - val_pred_layer_0_acc: 0.7583 - val_pred_layer_0_acc_1: 0.8024 - val_pred_layer_0_acc_2: 0.8163 - val_pred_layer_1_acc: 0.8752 - val_pred_layer_1_acc_1: 0.9116 - val_pred_layer_1_acc_2: 0.9173 - val_pred_layer_2_acc_1: 0.9244 - val_pred_layer_2_acc_2: 0.9252\n","\n","Epoch 00010: val_pred_layer_2_acc improved from 0.92406 to 0.92655, saving model to /content/gdrive/My Drive/colab/weights/svhn_SVHN_ResNet20v1_shared_model.010.h5\n","Epoch 11/200\n","Learning rate:  0.001\n"," - 274s - loss: 4.6772 - pred_layer_2_loss: 0.2881 - pred_layer_0_loss: 0.7000 - pred_layer_1_loss: 0.3247 - pred_layer_2_acc: 0.9140 - pred_layer_0_acc: 0.7075 - pred_layer_0_acc_1: 0.7555 - pred_layer_0_acc_2: 0.7793 - pred_layer_1_acc: 0.8430 - pred_layer_1_acc_1: 0.8892 - pred_layer_1_acc_2: 0.9027 - pred_layer_2_acc_1: 0.9136 - pred_layer_2_acc_2: 0.9139 - val_loss: 3.8385 - val_pred_layer_2_loss: 0.2442 - val_pred_layer_0_loss: 0.5612 - val_pred_layer_1_loss: 0.2556 - val_pred_layer_2_acc: 0.9307 - val_pred_layer_0_acc: 0.7637 - val_pred_layer_0_acc_1: 0.8067 - val_pred_layer_0_acc_2: 0.8273 - val_pred_layer_1_acc: 0.8796 - val_pred_layer_1_acc_1: 0.9227 - val_pred_layer_1_acc_2: 0.9287 - val_pred_layer_2_acc_1: 0.9297 - val_pred_layer_2_acc_2: 0.9301\n","\n","Epoch 00011: val_pred_layer_2_acc improved from 0.92655 to 0.93066, saving model to /content/gdrive/My Drive/colab/weights/svhn_SVHN_ResNet20v1_shared_model.011.h5\n","Epoch 12/200\n","Learning rate:  0.001\n"," - 281s - loss: 4.5655 - pred_layer_2_loss: 0.2797 - pred_layer_0_loss: 0.6820 - pred_layer_1_loss: 0.3138 - pred_layer_2_acc: 0.9161 - pred_layer_0_acc: 0.7119 - pred_layer_0_acc_1: 0.7614 - pred_layer_0_acc_2: 0.7856 - pred_layer_1_acc: 0.8483 - pred_layer_1_acc_1: 0.8941 - pred_layer_1_acc_2: 0.9072 - pred_layer_2_acc_1: 0.9157 - pred_layer_2_acc_2: 0.9160 - val_loss: 4.1414 - val_pred_layer_2_loss: 0.2710 - val_pred_layer_0_loss: 0.5926 - val_pred_layer_1_loss: 0.2834 - val_pred_layer_2_acc: 0.9227 - val_pred_layer_0_acc: 0.7500 - val_pred_layer_0_acc_1: 0.7976 - val_pred_layer_0_acc_2: 0.8148 - val_pred_layer_1_acc: 0.8667 - val_pred_layer_1_acc_1: 0.9045 - val_pred_layer_1_acc_2: 0.9206 - val_pred_layer_2_acc_1: 0.9202 - val_pred_layer_2_acc_2: 0.9215\n","\n","Epoch 00012: val_pred_layer_2_acc did not improve from 0.93066\n","Epoch 13/200\n","Learning rate:  0.001\n"," - 279s - loss: 4.5249 - pred_layer_2_loss: 0.2784 - pred_layer_0_loss: 0.6704 - pred_layer_1_loss: 0.3130 - pred_layer_2_acc: 0.9167 - pred_layer_0_acc: 0.7172 - pred_layer_0_acc_1: 0.7648 - pred_layer_0_acc_2: 0.7898 - pred_layer_1_acc: 0.8522 - pred_layer_1_acc_1: 0.8942 - pred_layer_1_acc_2: 0.9061 - pred_layer_2_acc_1: 0.9165 - pred_layer_2_acc_2: 0.9165 - val_loss: 3.8618 - val_pred_layer_2_loss: 0.2382 - val_pred_layer_0_loss: 0.5627 - val_pred_layer_1_loss: 0.2521 - val_pred_layer_2_acc: 0.9314 - val_pred_layer_0_acc: 0.7672 - val_pred_layer_0_acc_1: 0.8038 - val_pred_layer_0_acc_2: 0.8250 - val_pred_layer_1_acc: 0.8754 - val_pred_layer_1_acc_1: 0.9170 - val_pred_layer_1_acc_2: 0.9268 - val_pred_layer_2_acc_1: 0.9313 - val_pred_layer_2_acc_2: 0.9313\n","\n","Epoch 00013: val_pred_layer_2_acc improved from 0.93066 to 0.93143, saving model to /content/gdrive/My Drive/colab/weights/svhn_SVHN_ResNet20v1_shared_model.013.h5\n","Epoch 14/200\n","Learning rate:  0.001\n"," - 277s - loss: 4.4693 - pred_layer_2_loss: 0.2737 - pred_layer_0_loss: 0.6611 - pred_layer_1_loss: 0.3073 - pred_layer_2_acc: 0.9184 - pred_layer_0_acc: 0.7163 - pred_layer_0_acc_1: 0.7670 - pred_layer_0_acc_2: 0.7915 - pred_layer_1_acc: 0.8541 - pred_layer_1_acc_1: 0.8968 - pred_layer_1_acc_2: 0.9085 - pred_layer_2_acc_1: 0.9188 - pred_layer_2_acc_2: 0.9184 - val_loss: 4.0763 - val_pred_layer_2_loss: 0.2608 - val_pred_layer_0_loss: 0.6040 - val_pred_layer_1_loss: 0.2643 - val_pred_layer_2_acc: 0.9248 - val_pred_layer_0_acc: 0.7473 - val_pred_layer_0_acc_1: 0.7918 - val_pred_layer_0_acc_2: 0.8086 - val_pred_layer_1_acc: 0.8618 - val_pred_layer_1_acc_1: 0.9114 - val_pred_layer_1_acc_2: 0.9241 - val_pred_layer_2_acc_1: 0.9238 - val_pred_layer_2_acc_2: 0.9247\n","\n","Epoch 00014: val_pred_layer_2_acc did not improve from 0.93143\n","Epoch 15/200\n","Learning rate:  0.001\n"," - 279s - loss: 4.4178 - pred_layer_2_loss: 0.2697 - pred_layer_0_loss: 0.6516 - pred_layer_1_loss: 0.3033 - pred_layer_2_acc: 0.9206 - pred_layer_0_acc: 0.7200 - pred_layer_0_acc_1: 0.7704 - pred_layer_0_acc_2: 0.7956 - pred_layer_1_acc: 0.8551 - pred_layer_1_acc_1: 0.8983 - pred_layer_1_acc_2: 0.9109 - pred_layer_2_acc_1: 0.9203 - pred_layer_2_acc_2: 0.9209 - val_loss: 4.1282 - val_pred_layer_2_loss: 0.2951 - val_pred_layer_0_loss: 0.5777 - val_pred_layer_1_loss: 0.2767 - val_pred_layer_2_acc: 0.9101 - val_pred_layer_0_acc: 0.7496 - val_pred_layer_0_acc_1: 0.7994 - val_pred_layer_0_acc_2: 0.8189 - val_pred_layer_1_acc: 0.8674 - val_pred_layer_1_acc_1: 0.9079 - val_pred_layer_1_acc_2: 0.9191 - val_pred_layer_2_acc_1: 0.9133 - val_pred_layer_2_acc_2: 0.9098\n","\n","Epoch 00015: val_pred_layer_2_acc did not improve from 0.93143\n","Epoch 16/200\n","Learning rate:  0.001\n"," - 272s - loss: 4.3795 - pred_layer_2_loss: 0.2659 - pred_layer_0_loss: 0.6458 - pred_layer_1_loss: 0.2989 - pred_layer_2_acc: 0.9212 - pred_layer_0_acc: 0.7196 - pred_layer_0_acc_1: 0.7710 - pred_layer_0_acc_2: 0.7971 - pred_layer_1_acc: 0.8573 - pred_layer_1_acc_1: 0.8994 - pred_layer_1_acc_2: 0.9106 - pred_layer_2_acc_1: 0.9210 - pred_layer_2_acc_2: 0.9210 - val_loss: 3.8576 - val_pred_layer_2_loss: 0.2516 - val_pred_layer_0_loss: 0.5541 - val_pred_layer_1_loss: 0.2560 - val_pred_layer_2_acc: 0.9254 - val_pred_layer_0_acc: 0.7656 - val_pred_layer_0_acc_1: 0.8028 - val_pred_layer_0_acc_2: 0.8273 - val_pred_layer_1_acc: 0.8849 - val_pred_layer_1_acc_1: 0.9191 - val_pred_layer_1_acc_2: 0.9269 - val_pred_layer_2_acc_1: 0.9253 - val_pred_layer_2_acc_2: 0.9256\n","\n","Epoch 00016: val_pred_layer_2_acc did not improve from 0.93143\n","Epoch 17/200\n","Learning rate:  0.001\n"," - 272s - loss: 4.3391 - pred_layer_2_loss: 0.2640 - pred_layer_0_loss: 0.6374 - pred_layer_1_loss: 0.2960 - pred_layer_2_acc: 0.9216 - pred_layer_0_acc: 0.7238 - pred_layer_0_acc_1: 0.7762 - pred_layer_0_acc_2: 0.7995 - pred_layer_1_acc: 0.8597 - pred_layer_1_acc_1: 0.8991 - pred_layer_1_acc_2: 0.9113 - pred_layer_2_acc_1: 0.9212 - pred_layer_2_acc_2: 0.9215 - val_loss: 3.7666 - val_pred_layer_2_loss: 0.2466 - val_pred_layer_0_loss: 0.5362 - val_pred_layer_1_loss: 0.2546 - val_pred_layer_2_acc: 0.9281 - val_pred_layer_0_acc: 0.7651 - val_pred_layer_0_acc_1: 0.8112 - val_pred_layer_0_acc_2: 0.8334 - val_pred_layer_1_acc: 0.8907 - val_pred_layer_1_acc_1: 0.9230 - val_pred_layer_1_acc_2: 0.9265 - val_pred_layer_2_acc_1: 0.9275 - val_pred_layer_2_acc_2: 0.9280\n","\n","Epoch 00017: val_pred_layer_2_acc did not improve from 0.93143\n","Epoch 18/200\n","Learning rate:  0.001\n"," - 276s - loss: 4.2713 - pred_layer_2_loss: 0.2588 - pred_layer_0_loss: 0.6277 - pred_layer_1_loss: 0.2893 - pred_layer_2_acc: 0.9232 - pred_layer_0_acc: 0.7275 - pred_layer_0_acc_1: 0.7773 - pred_layer_0_acc_2: 0.8011 - pred_layer_1_acc: 0.8637 - pred_layer_1_acc_1: 0.9020 - pred_layer_1_acc_2: 0.9147 - pred_layer_2_acc_1: 0.9232 - pred_layer_2_acc_2: 0.9234 - val_loss: 3.7479 - val_pred_layer_2_loss: 0.2336 - val_pred_layer_0_loss: 0.5437 - val_pred_layer_1_loss: 0.2537 - val_pred_layer_2_acc: 0.9332 - val_pred_layer_0_acc: 0.7677 - val_pred_layer_0_acc_1: 0.8170 - val_pred_layer_0_acc_2: 0.8266 - val_pred_layer_1_acc: 0.8782 - val_pred_layer_1_acc_1: 0.9171 - val_pred_layer_1_acc_2: 0.9271 - val_pred_layer_2_acc_1: 0.9337 - val_pred_layer_2_acc_2: 0.9335\n","\n","Epoch 00018: val_pred_layer_2_acc improved from 0.93143 to 0.93320, saving model to /content/gdrive/My Drive/colab/weights/svhn_SVHN_ResNet20v1_shared_model.018.h5\n","Epoch 19/200\n","Learning rate:  0.001\n"," - 276s - loss: 4.2451 - pred_layer_2_loss: 0.2563 - pred_layer_0_loss: 0.6235 - pred_layer_1_loss: 0.2883 - pred_layer_2_acc: 0.9245 - pred_layer_0_acc: 0.7299 - pred_layer_0_acc_1: 0.7803 - pred_layer_0_acc_2: 0.8031 - pred_layer_1_acc: 0.8645 - pred_layer_1_acc_1: 0.9028 - pred_layer_1_acc_2: 0.9150 - pred_layer_2_acc_1: 0.9241 - pred_layer_2_acc_2: 0.9243 - val_loss: 3.8019 - val_pred_layer_2_loss: 0.2481 - val_pred_layer_0_loss: 0.5442 - val_pred_layer_1_loss: 0.2697 - val_pred_layer_2_acc: 0.9276 - val_pred_layer_0_acc: 0.7763 - val_pred_layer_0_acc_1: 0.8188 - val_pred_layer_0_acc_2: 0.8264 - val_pred_layer_1_acc: 0.8819 - val_pred_layer_1_acc_1: 0.9131 - val_pred_layer_1_acc_2: 0.9221 - val_pred_layer_2_acc_1: 0.9266 - val_pred_layer_2_acc_2: 0.9273\n","\n","Epoch 00019: val_pred_layer_2_acc did not improve from 0.93320\n","Epoch 20/200\n","Learning rate:  0.001\n"," - 277s - loss: 4.2395 - pred_layer_2_loss: 0.2567 - pred_layer_0_loss: 0.6204 - pred_layer_1_loss: 0.2876 - pred_layer_2_acc: 0.9233 - pred_layer_0_acc: 0.7298 - pred_layer_0_acc_1: 0.7828 - pred_layer_0_acc_2: 0.8054 - pred_layer_1_acc: 0.8641 - pred_layer_1_acc_1: 0.9030 - pred_layer_1_acc_2: 0.9144 - pred_layer_2_acc_1: 0.9231 - pred_layer_2_acc_2: 0.9238 - val_loss: 3.9035 - val_pred_layer_2_loss: 0.2574 - val_pred_layer_0_loss: 0.5480 - val_pred_layer_1_loss: 0.2733 - val_pred_layer_2_acc: 0.9282 - val_pred_layer_0_acc: 0.7689 - val_pred_layer_0_acc_1: 0.8150 - val_pred_layer_0_acc_2: 0.8338 - val_pred_layer_1_acc: 0.8816 - val_pred_layer_1_acc_1: 0.9119 - val_pred_layer_1_acc_2: 0.9218 - val_pred_layer_2_acc_1: 0.9251 - val_pred_layer_2_acc_2: 0.9274\n","\n","Epoch 00020: val_pred_layer_2_acc did not improve from 0.93320\n","Epoch 21/200\n","Learning rate:  0.001\n"," - 275s - loss: 4.1823 - pred_layer_2_loss: 0.2530 - pred_layer_0_loss: 0.6103 - pred_layer_1_loss: 0.2833 - pred_layer_2_acc: 0.9243 - pred_layer_0_acc: 0.7336 - pred_layer_0_acc_1: 0.7853 - pred_layer_0_acc_2: 0.8081 - pred_layer_1_acc: 0.8670 - pred_layer_1_acc_1: 0.9041 - pred_layer_1_acc_2: 0.9158 - pred_layer_2_acc_1: 0.9241 - pred_layer_2_acc_2: 0.9242 - val_loss: 3.8755 - val_pred_layer_2_loss: 0.2470 - val_pred_layer_0_loss: 0.5647 - val_pred_layer_1_loss: 0.2827 - val_pred_layer_2_acc: 0.9294 - val_pred_layer_0_acc: 0.7689 - val_pred_layer_0_acc_1: 0.8108 - val_pred_layer_0_acc_2: 0.8200 - val_pred_layer_1_acc: 0.8861 - val_pred_layer_1_acc_1: 0.9162 - val_pred_layer_1_acc_2: 0.9183 - val_pred_layer_2_acc_1: 0.9279 - val_pred_layer_2_acc_2: 0.9292\n","\n","Epoch 00021: val_pred_layer_2_acc did not improve from 0.93320\n","Epoch 22/200\n","Learning rate:  0.001\n"," - 277s - loss: 4.1601 - pred_layer_2_loss: 0.2498 - pred_layer_0_loss: 0.6084 - pred_layer_1_loss: 0.2802 - pred_layer_2_acc: 0.9265 - pred_layer_0_acc: 0.7334 - pred_layer_0_acc_1: 0.7875 - pred_layer_0_acc_2: 0.8103 - pred_layer_1_acc: 0.8684 - pred_layer_1_acc_1: 0.9058 - pred_layer_1_acc_2: 0.9168 - pred_layer_2_acc_1: 0.9261 - pred_layer_2_acc_2: 0.9267 - val_loss: 3.8833 - val_pred_layer_2_loss: 0.2862 - val_pred_layer_0_loss: 0.5067 - val_pred_layer_1_loss: 0.2812 - val_pred_layer_2_acc: 0.9161 - val_pred_layer_0_acc: 0.7838 - val_pred_layer_0_acc_1: 0.8263 - val_pred_layer_0_acc_2: 0.8434 - val_pred_layer_1_acc: 0.8757 - val_pred_layer_1_acc_1: 0.9067 - val_pred_layer_1_acc_2: 0.9183 - val_pred_layer_2_acc_1: 0.9153 - val_pred_layer_2_acc_2: 0.9155\n","\n","Epoch 00022: val_pred_layer_2_acc did not improve from 0.93320\n","Epoch 23/200\n","Learning rate:  0.001\n"," - 276s - loss: 4.1578 - pred_layer_2_loss: 0.2509 - pred_layer_0_loss: 0.6054 - pred_layer_1_loss: 0.2807 - pred_layer_2_acc: 0.9256 - pred_layer_0_acc: 0.7361 - pred_layer_0_acc_1: 0.7884 - pred_layer_0_acc_2: 0.8091 - pred_layer_1_acc: 0.8690 - pred_layer_1_acc_1: 0.9056 - pred_layer_1_acc_2: 0.9167 - pred_layer_2_acc_1: 0.9253 - pred_layer_2_acc_2: 0.9259 - val_loss: 3.7212 - val_pred_layer_2_loss: 0.2397 - val_pred_layer_0_loss: 0.5551 - val_pred_layer_1_loss: 0.2364 - val_pred_layer_2_acc: 0.9323 - val_pred_layer_0_acc: 0.7800 - val_pred_layer_0_acc_1: 0.8153 - val_pred_layer_0_acc_2: 0.8268 - val_pred_layer_1_acc: 0.8915 - val_pred_layer_1_acc_1: 0.9210 - val_pred_layer_1_acc_2: 0.9342 - val_pred_layer_2_acc_1: 0.9332 - val_pred_layer_2_acc_2: 0.9326\n","\n","Epoch 00023: val_pred_layer_2_acc did not improve from 0.93320\n","Epoch 24/200\n","Learning rate:  0.001\n"," - 276s - loss: 4.1162 - pred_layer_2_loss: 0.2458 - pred_layer_0_loss: 0.5992 - pred_layer_1_loss: 0.2756 - pred_layer_2_acc: 0.9266 - pred_layer_0_acc: 0.7367 - pred_layer_0_acc_1: 0.7909 - pred_layer_0_acc_2: 0.8118 - pred_layer_1_acc: 0.8697 - pred_layer_1_acc_1: 0.9064 - pred_layer_1_acc_2: 0.9184 - pred_layer_2_acc_1: 0.9264 - pred_layer_2_acc_2: 0.9265 - val_loss: 3.7187 - val_pred_layer_2_loss: 0.2379 - val_pred_layer_0_loss: 0.5183 - val_pred_layer_1_loss: 0.2502 - val_pred_layer_2_acc: 0.9318 - val_pred_layer_0_acc: 0.7805 - val_pred_layer_0_acc_1: 0.8176 - val_pred_layer_0_acc_2: 0.8394 - val_pred_layer_1_acc: 0.8847 - val_pred_layer_1_acc_1: 0.9176 - val_pred_layer_1_acc_2: 0.9305 - val_pred_layer_2_acc_1: 0.9310 - val_pred_layer_2_acc_2: 0.9319\n","\n","Epoch 00024: val_pred_layer_2_acc did not improve from 0.93320\n","Epoch 25/200\n","Learning rate:  0.001\n"," - 275s - loss: 4.1036 - pred_layer_2_loss: 0.2462 - pred_layer_0_loss: 0.5960 - pred_layer_1_loss: 0.2742 - pred_layer_2_acc: 0.9269 - pred_layer_0_acc: 0.7389 - pred_layer_0_acc_1: 0.7907 - pred_layer_0_acc_2: 0.8139 - pred_layer_1_acc: 0.8711 - pred_layer_1_acc_1: 0.9073 - pred_layer_1_acc_2: 0.9187 - pred_layer_2_acc_1: 0.9264 - pred_layer_2_acc_2: 0.9268 - val_loss: 3.6685 - val_pred_layer_2_loss: 0.2465 - val_pred_layer_0_loss: 0.4951 - val_pred_layer_1_loss: 0.2517 - val_pred_layer_2_acc: 0.9296 - val_pred_layer_0_acc: 0.7814 - val_pred_layer_0_acc_1: 0.8254 - val_pred_layer_0_acc_2: 0.8480 - val_pred_layer_1_acc: 0.8906 - val_pred_layer_1_acc_1: 0.9207 - val_pred_layer_1_acc_2: 0.9285 - val_pred_layer_2_acc_1: 0.9290 - val_pred_layer_2_acc_2: 0.9295\n","\n","Epoch 00025: val_pred_layer_2_acc did not improve from 0.93320\n","Epoch 26/200\n","Learning rate:  0.001\n"," - 275s - loss: 4.0952 - pred_layer_2_loss: 0.2457 - pred_layer_0_loss: 0.5945 - pred_layer_1_loss: 0.2733 - pred_layer_2_acc: 0.9277 - pred_layer_0_acc: 0.7380 - pred_layer_0_acc_1: 0.7910 - pred_layer_0_acc_2: 0.8141 - pred_layer_1_acc: 0.8714 - pred_layer_1_acc_1: 0.9074 - pred_layer_1_acc_2: 0.9192 - pred_layer_2_acc_1: 0.9275 - pred_layer_2_acc_2: 0.9277 - val_loss: 3.6534 - val_pred_layer_2_loss: 0.2329 - val_pred_layer_0_loss: 0.5121 - val_pred_layer_1_loss: 0.2464 - val_pred_layer_2_acc: 0.9327 - val_pred_layer_0_acc: 0.7813 - val_pred_layer_0_acc_1: 0.8249 - val_pred_layer_0_acc_2: 0.8427 - val_pred_layer_1_acc: 0.8915 - val_pred_layer_1_acc_1: 0.9232 - val_pred_layer_1_acc_2: 0.9303 - val_pred_layer_2_acc_1: 0.9322 - val_pred_layer_2_acc_2: 0.9329\n","\n","Epoch 00026: val_pred_layer_2_acc did not improve from 0.93320\n","Epoch 27/200\n","Learning rate:  0.001\n"," - 275s - loss: 4.0468 - pred_layer_2_loss: 0.2412 - pred_layer_0_loss: 0.5869 - pred_layer_1_loss: 0.2692 - pred_layer_2_acc: 0.9282 - pred_layer_0_acc: 0.7402 - pred_layer_0_acc_1: 0.7949 - pred_layer_0_acc_2: 0.8161 - pred_layer_1_acc: 0.8731 - pred_layer_1_acc_1: 0.9090 - pred_layer_1_acc_2: 0.9216 - pred_layer_2_acc_1: 0.9284 - pred_layer_2_acc_2: 0.9285 - val_loss: 3.5311 - val_pred_layer_2_loss: 0.2120 - val_pred_layer_0_loss: 0.5047 - val_pred_layer_1_loss: 0.2360 - val_pred_layer_2_acc: 0.9405 - val_pred_layer_0_acc: 0.7800 - val_pred_layer_0_acc_1: 0.8309 - val_pred_layer_0_acc_2: 0.8445 - val_pred_layer_1_acc: 0.8929 - val_pred_layer_1_acc_1: 0.9259 - val_pred_layer_1_acc_2: 0.9332 - val_pred_layer_2_acc_1: 0.9400 - val_pred_layer_2_acc_2: 0.9407\n","\n","Epoch 00027: val_pred_layer_2_acc improved from 0.93320 to 0.94050, saving model to /content/gdrive/My Drive/colab/weights/svhn_SVHN_ResNet20v1_shared_model.027.h5\n","Epoch 28/200\n","Learning rate:  0.001\n"," - 276s - loss: 4.0524 - pred_layer_2_loss: 0.2408 - pred_layer_0_loss: 0.5893 - pred_layer_1_loss: 0.2698 - pred_layer_2_acc: 0.9285 - pred_layer_0_acc: 0.7409 - pred_layer_0_acc_1: 0.7942 - pred_layer_0_acc_2: 0.8135 - pred_layer_1_acc: 0.8725 - pred_layer_1_acc_1: 0.9088 - pred_layer_1_acc_2: 0.9197 - pred_layer_2_acc_1: 0.9279 - pred_layer_2_acc_2: 0.9283 - val_loss: 3.5018 - val_pred_layer_2_loss: 0.2067 - val_pred_layer_0_loss: 0.4940 - val_pred_layer_1_loss: 0.2207 - val_pred_layer_2_acc: 0.9431 - val_pred_layer_0_acc: 0.7680 - val_pred_layer_0_acc_1: 0.8245 - val_pred_layer_0_acc_2: 0.8452 - val_pred_layer_1_acc: 0.8957 - val_pred_layer_1_acc_1: 0.9303 - val_pred_layer_1_acc_2: 0.9385 - val_pred_layer_2_acc_1: 0.9427 - val_pred_layer_2_acc_2: 0.9428\n","\n","Epoch 00028: val_pred_layer_2_acc improved from 0.94050 to 0.94315, saving model to /content/gdrive/My Drive/colab/weights/svhn_SVHN_ResNet20v1_shared_model.028.h5\n","Epoch 29/200\n","Learning rate:  0.001\n"," - 277s - loss: 4.0381 - pred_layer_2_loss: 0.2422 - pred_layer_0_loss: 0.5822 - pred_layer_1_loss: 0.2688 - pred_layer_2_acc: 0.9288 - pred_layer_0_acc: 0.7427 - pred_layer_0_acc_1: 0.7959 - pred_layer_0_acc_2: 0.8186 - pred_layer_1_acc: 0.8737 - pred_layer_1_acc_1: 0.9094 - pred_layer_1_acc_2: 0.9215 - pred_layer_2_acc_1: 0.9284 - pred_layer_2_acc_2: 0.9287 - val_loss: 3.7847 - val_pred_layer_2_loss: 0.2369 - val_pred_layer_0_loss: 0.5356 - val_pred_layer_1_loss: 0.2653 - val_pred_layer_2_acc: 0.9316 - val_pred_layer_0_acc: 0.7750 - val_pred_layer_0_acc_1: 0.8239 - val_pred_layer_0_acc_2: 0.8349 - val_pred_layer_1_acc: 0.8871 - val_pred_layer_1_acc_1: 0.9092 - val_pred_layer_1_acc_2: 0.9251 - val_pred_layer_2_acc_1: 0.9305 - val_pred_layer_2_acc_2: 0.9314\n","\n","Epoch 00029: val_pred_layer_2_acc did not improve from 0.94315\n","Epoch 30/200\n","Learning rate:  0.001\n"," - 276s - loss: 4.0044 - pred_layer_2_loss: 0.2386 - pred_layer_0_loss: 0.5783 - pred_layer_1_loss: 0.2650 - pred_layer_2_acc: 0.9295 - pred_layer_0_acc: 0.7447 - pred_layer_0_acc_1: 0.7980 - pred_layer_0_acc_2: 0.8181 - pred_layer_1_acc: 0.8739 - pred_layer_1_acc_1: 0.9103 - pred_layer_1_acc_2: 0.9219 - pred_layer_2_acc_1: 0.9288 - pred_layer_2_acc_2: 0.9293 - val_loss: 3.5877 - val_pred_layer_2_loss: 0.2316 - val_pred_layer_0_loss: 0.4970 - val_pred_layer_1_loss: 0.2482 - val_pred_layer_2_acc: 0.9340 - val_pred_layer_0_acc: 0.7855 - val_pred_layer_0_acc_1: 0.8345 - val_pred_layer_0_acc_2: 0.8473 - val_pred_layer_1_acc: 0.8913 - val_pred_layer_1_acc_1: 0.9177 - val_pred_layer_1_acc_2: 0.9283 - val_pred_layer_2_acc_1: 0.9334 - val_pred_layer_2_acc_2: 0.9343\n","\n","Epoch 00030: val_pred_layer_2_acc did not improve from 0.94315\n","Epoch 31/200\n","Learning rate:  0.001\n"," - 275s - loss: 4.0009 - pred_layer_2_loss: 0.2379 - pred_layer_0_loss: 0.5756 - pred_layer_1_loss: 0.2663 - pred_layer_2_acc: 0.9293 - pred_layer_0_acc: 0.7438 - pred_layer_0_acc_1: 0.7974 - pred_layer_0_acc_2: 0.8188 - pred_layer_1_acc: 0.8749 - pred_layer_1_acc_1: 0.9099 - pred_layer_1_acc_2: 0.9213 - pred_layer_2_acc_1: 0.9293 - pred_layer_2_acc_2: 0.9293 - val_loss: 3.5868 - val_pred_layer_2_loss: 0.2315 - val_pred_layer_0_loss: 0.4783 - val_pred_layer_1_loss: 0.2603 - val_pred_layer_2_acc: 0.9358 - val_pred_layer_0_acc: 0.7797 - val_pred_layer_0_acc_1: 0.8276 - val_pred_layer_0_acc_2: 0.8521 - val_pred_layer_1_acc: 0.8961 - val_pred_layer_1_acc_1: 0.9221 - val_pred_layer_1_acc_2: 0.9255 - val_pred_layer_2_acc_1: 0.9344 - val_pred_layer_2_acc_2: 0.9355\n","\n","Epoch 00031: val_pred_layer_2_acc did not improve from 0.94315\n","Epoch 32/200\n","Learning rate:  0.001\n"," - 276s - loss: 3.9836 - pred_layer_2_loss: 0.2363 - pred_layer_0_loss: 0.5751 - pred_layer_1_loss: 0.2627 - pred_layer_2_acc: 0.9296 - pred_layer_0_acc: 0.7460 - pred_layer_0_acc_1: 0.7980 - pred_layer_0_acc_2: 0.8201 - pred_layer_1_acc: 0.8769 - pred_layer_1_acc_1: 0.9100 - pred_layer_1_acc_2: 0.9224 - pred_layer_2_acc_1: 0.9294 - pred_layer_2_acc_2: 0.9301 - val_loss: 3.6726 - val_pred_layer_2_loss: 0.2345 - val_pred_layer_0_loss: 0.5329 - val_pred_layer_1_loss: 0.2401 - val_pred_layer_2_acc: 0.9325 - val_pred_layer_0_acc: 0.7816 - val_pred_layer_0_acc_1: 0.8224 - val_pred_layer_0_acc_2: 0.8308 - val_pred_layer_1_acc: 0.8917 - val_pred_layer_1_acc_1: 0.9169 - val_pred_layer_1_acc_2: 0.9319 - val_pred_layer_2_acc_1: 0.9322 - val_pred_layer_2_acc_2: 0.9323\n","\n","Epoch 00032: val_pred_layer_2_acc did not improve from 0.94315\n","Epoch 33/200\n","Learning rate:  0.001\n"," - 274s - loss: 3.9720 - pred_layer_2_loss: 0.2342 - pred_layer_0_loss: 0.5730 - pred_layer_1_loss: 0.2607 - pred_layer_2_acc: 0.9311 - pred_layer_0_acc: 0.7461 - pred_layer_0_acc_1: 0.7998 - pred_layer_0_acc_2: 0.8209 - pred_layer_1_acc: 0.8758 - pred_layer_1_acc_1: 0.9112 - pred_layer_1_acc_2: 0.9233 - pred_layer_2_acc_1: 0.9308 - pred_layer_2_acc_2: 0.9312 - val_loss: 3.5624 - val_pred_layer_2_loss: 0.2264 - val_pred_layer_0_loss: 0.4955 - val_pred_layer_1_loss: 0.2413 - val_pred_layer_2_acc: 0.9371 - val_pred_layer_0_acc: 0.7929 - val_pred_layer_0_acc_1: 0.8332 - val_pred_layer_0_acc_2: 0.8449 - val_pred_layer_1_acc: 0.8907 - val_pred_layer_1_acc_1: 0.9184 - val_pred_layer_1_acc_2: 0.9322 - val_pred_layer_2_acc_1: 0.9357 - val_pred_layer_2_acc_2: 0.9370\n","\n","Epoch 00033: val_pred_layer_2_acc did not improve from 0.94315\n","Epoch 34/200\n","Learning rate:  0.001\n"," - 277s - loss: 3.9487 - pred_layer_2_loss: 0.2336 - pred_layer_0_loss: 0.5670 - pred_layer_1_loss: 0.2608 - pred_layer_2_acc: 0.9307 - pred_layer_0_acc: 0.7460 - pred_layer_0_acc_1: 0.8019 - pred_layer_0_acc_2: 0.8214 - pred_layer_1_acc: 0.8756 - pred_layer_1_acc_1: 0.9102 - pred_layer_1_acc_2: 0.9226 - pred_layer_2_acc_1: 0.9302 - pred_layer_2_acc_2: 0.9306 - val_loss: 3.5722 - val_pred_layer_2_loss: 0.2243 - val_pred_layer_0_loss: 0.5017 - val_pred_layer_1_loss: 0.2284 - val_pred_layer_2_acc: 0.9375 - val_pred_layer_0_acc: 0.7828 - val_pred_layer_0_acc_1: 0.8268 - val_pred_layer_0_acc_2: 0.8435 - val_pred_layer_1_acc: 0.8896 - val_pred_layer_1_acc_1: 0.9266 - val_pred_layer_1_acc_2: 0.9363 - val_pred_layer_2_acc_1: 0.9372 - val_pred_layer_2_acc_2: 0.9382\n","\n","Epoch 00034: val_pred_layer_2_acc did not improve from 0.94315\n","Epoch 35/200\n","Learning rate:  0.001\n"," - 276s - loss: 3.9239 - pred_layer_2_loss: 0.2327 - pred_layer_0_loss: 0.5631 - pred_layer_1_loss: 0.2596 - pred_layer_2_acc: 0.9310 - pred_layer_0_acc: 0.7505 - pred_layer_0_acc_1: 0.8047 - pred_layer_0_acc_2: 0.8234 - pred_layer_1_acc: 0.8784 - pred_layer_1_acc_1: 0.9117 - pred_layer_1_acc_2: 0.9238 - pred_layer_2_acc_1: 0.9305 - pred_layer_2_acc_2: 0.9310 - val_loss: 3.7253 - val_pred_layer_2_loss: 0.2465 - val_pred_layer_0_loss: 0.4911 - val_pred_layer_1_loss: 0.2534 - val_pred_layer_2_acc: 0.9299 - val_pred_layer_0_acc: 0.7798 - val_pred_layer_0_acc_1: 0.8254 - val_pred_layer_0_acc_2: 0.8493 - val_pred_layer_1_acc: 0.8886 - val_pred_layer_1_acc_1: 0.9150 - val_pred_layer_1_acc_2: 0.9277 - val_pred_layer_2_acc_1: 0.9294 - val_pred_layer_2_acc_2: 0.9304\n","\n","Epoch 00035: val_pred_layer_2_acc did not improve from 0.94315\n","Epoch 36/200\n","Learning rate:  0.001\n"," - 278s - loss: 3.9189 - pred_layer_2_loss: 0.2285 - pred_layer_0_loss: 0.5675 - pred_layer_1_loss: 0.2561 - pred_layer_2_acc: 0.9333 - pred_layer_0_acc: 0.7487 - pred_layer_0_acc_1: 0.8024 - pred_layer_0_acc_2: 0.8218 - pred_layer_1_acc: 0.8785 - pred_layer_1_acc_1: 0.9123 - pred_layer_1_acc_2: 0.9249 - pred_layer_2_acc_1: 0.9323 - pred_layer_2_acc_2: 0.9331 - val_loss: 3.5206 - val_pred_layer_2_loss: 0.2283 - val_pred_layer_0_loss: 0.4718 - val_pred_layer_1_loss: 0.2395 - val_pred_layer_2_acc: 0.9360 - val_pred_layer_0_acc: 0.7752 - val_pred_layer_0_acc_1: 0.8360 - val_pred_layer_0_acc_2: 0.8529 - val_pred_layer_1_acc: 0.8978 - val_pred_layer_1_acc_1: 0.9268 - val_pred_layer_1_acc_2: 0.9318 - val_pred_layer_2_acc_1: 0.9367 - val_pred_layer_2_acc_2: 0.9360\n","\n","Epoch 00036: val_pred_layer_2_acc did not improve from 0.94315\n","Epoch 37/200\n","Learning rate:  0.001\n"," - 278s - loss: 3.9092 - pred_layer_2_loss: 0.2296 - pred_layer_0_loss: 0.5618 - pred_layer_1_loss: 0.2568 - pred_layer_2_acc: 0.9327 - pred_layer_0_acc: 0.7510 - pred_layer_0_acc_1: 0.8036 - pred_layer_0_acc_2: 0.8230 - pred_layer_1_acc: 0.8788 - pred_layer_1_acc_1: 0.9121 - pred_layer_1_acc_2: 0.9245 - pred_layer_2_acc_1: 0.9325 - pred_layer_2_acc_2: 0.9327 - val_loss: 3.6770 - val_pred_layer_2_loss: 0.2262 - val_pred_layer_0_loss: 0.5233 - val_pred_layer_1_loss: 0.2443 - val_pred_layer_2_acc: 0.9356 - val_pred_layer_0_acc: 0.7813 - val_pred_layer_0_acc_1: 0.8147 - val_pred_layer_0_acc_2: 0.8372 - val_pred_layer_1_acc: 0.8932 - val_pred_layer_1_acc_1: 0.9209 - val_pred_layer_1_acc_2: 0.9285 - val_pred_layer_2_acc_1: 0.9350 - val_pred_layer_2_acc_2: 0.9360\n","\n","Epoch 00037: val_pred_layer_2_acc did not improve from 0.94315\n","Epoch 38/200\n","Learning rate:  0.001\n"," - 278s - loss: 3.8914 - pred_layer_2_loss: 0.2267 - pred_layer_0_loss: 0.5602 - pred_layer_1_loss: 0.2540 - pred_layer_2_acc: 0.9334 - pred_layer_0_acc: 0.7525 - pred_layer_0_acc_1: 0.8046 - pred_layer_0_acc_2: 0.8250 - pred_layer_1_acc: 0.8798 - pred_layer_1_acc_1: 0.9128 - pred_layer_1_acc_2: 0.9252 - pred_layer_2_acc_1: 0.9327 - pred_layer_2_acc_2: 0.9335 - val_loss: 3.6380 - val_pred_layer_2_loss: 0.2447 - val_pred_layer_0_loss: 0.5036 - val_pred_layer_1_loss: 0.2438 - val_pred_layer_2_acc: 0.9312 - val_pred_layer_0_acc: 0.7854 - val_pred_layer_0_acc_1: 0.8303 - val_pred_layer_0_acc_2: 0.8426 - val_pred_layer_1_acc: 0.8965 - val_pred_layer_1_acc_1: 0.9207 - val_pred_layer_1_acc_2: 0.9316 - val_pred_layer_2_acc_1: 0.9306 - val_pred_layer_2_acc_2: 0.9310\n","\n","Epoch 00038: val_pred_layer_2_acc did not improve from 0.94315\n","Epoch 39/200\n","Learning rate:  0.001\n"," - 279s - loss: 3.9088 - pred_layer_2_loss: 0.2302 - pred_layer_0_loss: 0.5610 - pred_layer_1_loss: 0.2572 - pred_layer_2_acc: 0.9327 - pred_layer_0_acc: 0.7514 - pred_layer_0_acc_1: 0.8051 - pred_layer_0_acc_2: 0.8253 - pred_layer_1_acc: 0.8798 - pred_layer_1_acc_1: 0.9125 - pred_layer_1_acc_2: 0.9246 - pred_layer_2_acc_1: 0.9326 - pred_layer_2_acc_2: 0.9327 - val_loss: 3.3418 - val_pred_layer_2_loss: 0.2075 - val_pred_layer_0_loss: 0.4656 - val_pred_layer_1_loss: 0.2145 - val_pred_layer_2_acc: 0.9428 - val_pred_layer_0_acc: 0.7941 - val_pred_layer_0_acc_1: 0.8353 - val_pred_layer_0_acc_2: 0.8561 - val_pred_layer_1_acc: 0.9075 - val_pred_layer_1_acc_1: 0.9338 - val_pred_layer_1_acc_2: 0.9411 - val_pred_layer_2_acc_1: 0.9425 - val_pred_layer_2_acc_2: 0.9425\n","\n","Epoch 00039: val_pred_layer_2_acc did not improve from 0.94315\n","Epoch 40/200\n","Learning rate:  0.001\n"," - 278s - loss: 3.8737 - pred_layer_2_loss: 0.2260 - pred_layer_0_loss: 0.5553 - pred_layer_1_loss: 0.2529 - pred_layer_2_acc: 0.9333 - pred_layer_0_acc: 0.7513 - pred_layer_0_acc_1: 0.8065 - pred_layer_0_acc_2: 0.8268 - pred_layer_1_acc: 0.8806 - pred_layer_1_acc_1: 0.9137 - pred_layer_1_acc_2: 0.9259 - pred_layer_2_acc_1: 0.9328 - pred_layer_2_acc_2: 0.9333 - val_loss: 3.4432 - val_pred_layer_2_loss: 0.2084 - val_pred_layer_0_loss: 0.4814 - val_pred_layer_1_loss: 0.2237 - val_pred_layer_2_acc: 0.9418 - val_pred_layer_0_acc: 0.7867 - val_pred_layer_0_acc_1: 0.8363 - val_pred_layer_0_acc_2: 0.8514 - val_pred_layer_1_acc: 0.9013 - val_pred_layer_1_acc_1: 0.9282 - val_pred_layer_1_acc_2: 0.9373 - val_pred_layer_2_acc_1: 0.9419 - val_pred_layer_2_acc_2: 0.9421\n","\n","Epoch 00040: val_pred_layer_2_acc did not improve from 0.94315\n","Epoch 41/200\n","Learning rate:  0.001\n"," - 275s - loss: 3.8708 - pred_layer_2_loss: 0.2263 - pred_layer_0_loss: 0.5546 - pred_layer_1_loss: 0.2538 - pred_layer_2_acc: 0.9333 - pred_layer_0_acc: 0.7536 - pred_layer_0_acc_1: 0.8081 - pred_layer_0_acc_2: 0.8276 - pred_layer_1_acc: 0.8800 - pred_layer_1_acc_1: 0.9137 - pred_layer_1_acc_2: 0.9250 - pred_layer_2_acc_1: 0.9331 - pred_layer_2_acc_2: 0.9335 - val_loss: 3.5055 - val_pred_layer_2_loss: 0.2236 - val_pred_layer_0_loss: 0.4888 - val_pred_layer_1_loss: 0.2344 - val_pred_layer_2_acc: 0.9371 - val_pred_layer_0_acc: 0.7895 - val_pred_layer_0_acc_1: 0.8328 - val_pred_layer_0_acc_2: 0.8512 - val_pred_layer_1_acc: 0.9015 - val_pred_layer_1_acc_1: 0.9266 - val_pred_layer_1_acc_2: 0.9347 - val_pred_layer_2_acc_1: 0.9366 - val_pred_layer_2_acc_2: 0.9370\n","\n","Epoch 00041: val_pred_layer_2_acc did not improve from 0.94315\n","Epoch 42/200\n","Learning rate:  0.001\n"," - 275s - loss: 3.8603 - pred_layer_2_loss: 0.2248 - pred_layer_0_loss: 0.5528 - pred_layer_1_loss: 0.2512 - pred_layer_2_acc: 0.9341 - pred_layer_0_acc: 0.7528 - pred_layer_0_acc_1: 0.8062 - pred_layer_0_acc_2: 0.8264 - pred_layer_1_acc: 0.8807 - pred_layer_1_acc_1: 0.9146 - pred_layer_1_acc_2: 0.9254 - pred_layer_2_acc_1: 0.9337 - pred_layer_2_acc_2: 0.9338 - val_loss: 3.5512 - val_pred_layer_2_loss: 0.2308 - val_pred_layer_0_loss: 0.4897 - val_pred_layer_1_loss: 0.2396 - val_pred_layer_2_acc: 0.9356 - val_pred_layer_0_acc: 0.7973 - val_pred_layer_0_acc_1: 0.8385 - val_pred_layer_0_acc_2: 0.8497 - val_pred_layer_1_acc: 0.8877 - val_pred_layer_1_acc_1: 0.9221 - val_pred_layer_1_acc_2: 0.9322 - val_pred_layer_2_acc_1: 0.9352 - val_pred_layer_2_acc_2: 0.9354\n","\n","Epoch 00042: val_pred_layer_2_acc did not improve from 0.94315\n","Epoch 43/200\n","Learning rate:  0.001\n"," - 274s - loss: 3.8614 - pred_layer_2_loss: 0.2259 - pred_layer_0_loss: 0.5522 - pred_layer_1_loss: 0.2522 - pred_layer_2_acc: 0.9334 - pred_layer_0_acc: 0.7538 - pred_layer_0_acc_1: 0.8075 - pred_layer_0_acc_2: 0.8276 - pred_layer_1_acc: 0.8816 - pred_layer_1_acc_1: 0.9135 - pred_layer_1_acc_2: 0.9258 - pred_layer_2_acc_1: 0.9330 - pred_layer_2_acc_2: 0.9334 - val_loss: 3.6899 - val_pred_layer_2_loss: 0.2269 - val_pred_layer_0_loss: 0.5225 - val_pred_layer_1_loss: 0.2376 - val_pred_layer_2_acc: 0.9350 - val_pred_layer_0_acc: 0.7700 - val_pred_layer_0_acc_1: 0.8139 - val_pred_layer_0_acc_2: 0.8382 - val_pred_layer_1_acc: 0.8982 - val_pred_layer_1_acc_1: 0.9236 - val_pred_layer_1_acc_2: 0.9334 - val_pred_layer_2_acc_1: 0.9352 - val_pred_layer_2_acc_2: 0.9355\n","\n","Epoch 00043: val_pred_layer_2_acc did not improve from 0.94315\n","Epoch 44/200\n","Learning rate:  0.001\n"," - 276s - loss: 3.8508 - pred_layer_2_loss: 0.2244 - pred_layer_0_loss: 0.5524 - pred_layer_1_loss: 0.2516 - pred_layer_2_acc: 0.9343 - pred_layer_0_acc: 0.7554 - pred_layer_0_acc_1: 0.8070 - pred_layer_0_acc_2: 0.8270 - pred_layer_1_acc: 0.8816 - pred_layer_1_acc_1: 0.9138 - pred_layer_1_acc_2: 0.9267 - pred_layer_2_acc_1: 0.9338 - pred_layer_2_acc_2: 0.9345 - val_loss: 3.4543 - val_pred_layer_2_loss: 0.2238 - val_pred_layer_0_loss: 0.4745 - val_pred_layer_1_loss: 0.2294 - val_pred_layer_2_acc: 0.9373 - val_pred_layer_0_acc: 0.7984 - val_pred_layer_0_acc_1: 0.8385 - val_pred_layer_0_acc_2: 0.8538 - val_pred_layer_1_acc: 0.9004 - val_pred_layer_1_acc_1: 0.9265 - val_pred_layer_1_acc_2: 0.9369 - val_pred_layer_2_acc_1: 0.9377 - val_pred_layer_2_acc_2: 0.9373\n","\n","Epoch 00044: val_pred_layer_2_acc did not improve from 0.94315\n","Epoch 45/200\n","Learning rate:  0.001\n"," - 280s - loss: 3.8375 - pred_layer_2_loss: 0.2226 - pred_layer_0_loss: 0.5516 - pred_layer_1_loss: 0.2467 - pred_layer_2_acc: 0.9339 - pred_layer_0_acc: 0.7520 - pred_layer_0_acc_1: 0.8086 - pred_layer_0_acc_2: 0.8277 - pred_layer_1_acc: 0.8824 - pred_layer_1_acc_1: 0.9161 - pred_layer_1_acc_2: 0.9269 - pred_layer_2_acc_1: 0.9337 - pred_layer_2_acc_2: 0.9339 - val_loss: 3.4850 - val_pred_layer_2_loss: 0.2202 - val_pred_layer_0_loss: 0.4758 - val_pred_layer_1_loss: 0.2307 - val_pred_layer_2_acc: 0.9372 - val_pred_layer_0_acc: 0.7951 - val_pred_layer_0_acc_1: 0.8330 - val_pred_layer_0_acc_2: 0.8536 - val_pred_layer_1_acc: 0.8974 - val_pred_layer_1_acc_1: 0.9256 - val_pred_layer_1_acc_2: 0.9332 - val_pred_layer_2_acc_1: 0.9361 - val_pred_layer_2_acc_2: 0.9368\n","\n","Epoch 00045: val_pred_layer_2_acc did not improve from 0.94315\n","Epoch 46/200\n","Learning rate:  0.001\n"," - 282s - loss: 3.7965 - pred_layer_2_loss: 0.2203 - pred_layer_0_loss: 0.5443 - pred_layer_1_loss: 0.2450 - pred_layer_2_acc: 0.9349 - pred_layer_0_acc: 0.7558 - pred_layer_0_acc_1: 0.8108 - pred_layer_0_acc_2: 0.8295 - pred_layer_1_acc: 0.8832 - pred_layer_1_acc_1: 0.9175 - pred_layer_1_acc_2: 0.9271 - pred_layer_2_acc_1: 0.9342 - pred_layer_2_acc_2: 0.9346 - val_loss: 3.4810 - val_pred_layer_2_loss: 0.2293 - val_pred_layer_0_loss: 0.4603 - val_pred_layer_1_loss: 0.2434 - val_pred_layer_2_acc: 0.9355 - val_pred_layer_0_acc: 0.8001 - val_pred_layer_0_acc_1: 0.8380 - val_pred_layer_0_acc_2: 0.8595 - val_pred_layer_1_acc: 0.9032 - val_pred_layer_1_acc_1: 0.9258 - val_pred_layer_1_acc_2: 0.9320 - val_pred_layer_2_acc_1: 0.9347 - val_pred_layer_2_acc_2: 0.9352\n","\n","Epoch 00046: val_pred_layer_2_acc did not improve from 0.94315\n","Epoch 47/200\n","Learning rate:  0.001\n"," - 282s - loss: 3.8396 - pred_layer_2_loss: 0.2241 - pred_layer_0_loss: 0.5479 - pred_layer_1_loss: 0.2510 - pred_layer_2_acc: 0.9345 - pred_layer_0_acc: 0.7563 - pred_layer_0_acc_1: 0.8105 - pred_layer_0_acc_2: 0.8305 - pred_layer_1_acc: 0.8821 - pred_layer_1_acc_1: 0.9157 - pred_layer_1_acc_2: 0.9271 - pred_layer_2_acc_1: 0.9342 - pred_layer_2_acc_2: 0.9346 - val_loss: 3.6211 - val_pred_layer_2_loss: 0.2294 - val_pred_layer_0_loss: 0.4994 - val_pred_layer_1_loss: 0.2440 - val_pred_layer_2_acc: 0.9367 - val_pred_layer_0_acc: 0.7924 - val_pred_layer_0_acc_1: 0.8292 - val_pred_layer_0_acc_2: 0.8451 - val_pred_layer_1_acc: 0.8888 - val_pred_layer_1_acc_1: 0.9173 - val_pred_layer_1_acc_2: 0.9301 - val_pred_layer_2_acc_1: 0.9346 - val_pred_layer_2_acc_2: 0.9357\n","\n","Epoch 00047: val_pred_layer_2_acc did not improve from 0.94315\n","Epoch 48/200\n","Learning rate:  0.001\n"," - 289s - loss: 3.8226 - pred_layer_2_loss: 0.2224 - pred_layer_0_loss: 0.5479 - pred_layer_1_loss: 0.2468 - pred_layer_2_acc: 0.9346 - pred_layer_0_acc: 0.7554 - pred_layer_0_acc_1: 0.8100 - pred_layer_0_acc_2: 0.8285 - pred_layer_1_acc: 0.8832 - pred_layer_1_acc_1: 0.9166 - pred_layer_1_acc_2: 0.9283 - pred_layer_2_acc_1: 0.9341 - pred_layer_2_acc_2: 0.9342 - val_loss: 3.3887 - val_pred_layer_2_loss: 0.2158 - val_pred_layer_0_loss: 0.4556 - val_pred_layer_1_loss: 0.2226 - val_pred_layer_2_acc: 0.9391 - val_pred_layer_0_acc: 0.7934 - val_pred_layer_0_acc_1: 0.8403 - val_pred_layer_0_acc_2: 0.8596 - val_pred_layer_1_acc: 0.9040 - val_pred_layer_1_acc_1: 0.9286 - val_pred_layer_1_acc_2: 0.9384 - val_pred_layer_2_acc_1: 0.9392 - val_pred_layer_2_acc_2: 0.9393\n","\n","Epoch 00048: val_pred_layer_2_acc did not improve from 0.94315\n","Epoch 49/200\n","Learning rate:  0.001\n"," - 281s - loss: 3.7838 - pred_layer_2_loss: 0.2214 - pred_layer_0_loss: 0.5378 - pred_layer_1_loss: 0.2459 - pred_layer_2_acc: 0.9352 - pred_layer_0_acc: 0.7586 - pred_layer_0_acc_1: 0.8120 - pred_layer_0_acc_2: 0.8308 - pred_layer_1_acc: 0.8843 - pred_layer_1_acc_1: 0.9156 - pred_layer_1_acc_2: 0.9281 - pred_layer_2_acc_1: 0.9343 - pred_layer_2_acc_2: 0.9353 - val_loss: 3.5607 - val_pred_layer_2_loss: 0.2522 - val_pred_layer_0_loss: 0.4530 - val_pred_layer_1_loss: 0.2467 - val_pred_layer_2_acc: 0.9285 - val_pred_layer_0_acc: 0.7944 - val_pred_layer_0_acc_1: 0.8434 - val_pred_layer_0_acc_2: 0.8615 - val_pred_layer_1_acc: 0.8996 - val_pred_layer_1_acc_1: 0.9213 - val_pred_layer_1_acc_2: 0.9294 - val_pred_layer_2_acc_1: 0.9272 - val_pred_layer_2_acc_2: 0.9281\n","\n","Epoch 00049: val_pred_layer_2_acc did not improve from 0.94315\n","Epoch 50/200\n","Learning rate:  0.001\n"," - 269s - loss: 3.7998 - pred_layer_2_loss: 0.2206 - pred_layer_0_loss: 0.5422 - pred_layer_1_loss: 0.2451 - pred_layer_2_acc: 0.9346 - pred_layer_0_acc: 0.7578 - pred_layer_0_acc_1: 0.8109 - pred_layer_0_acc_2: 0.8299 - pred_layer_1_acc: 0.8822 - pred_layer_1_acc_1: 0.9145 - pred_layer_1_acc_2: 0.9266 - pred_layer_2_acc_1: 0.9344 - pred_layer_2_acc_2: 0.9344 - val_loss: 3.5698 - val_pred_layer_2_loss: 0.2295 - val_pred_layer_0_loss: 0.5089 - val_pred_layer_1_loss: 0.2334 - val_pred_layer_2_acc: 0.9363 - val_pred_layer_0_acc: 0.7856 - val_pred_layer_0_acc_1: 0.8320 - val_pred_layer_0_acc_2: 0.8422 - val_pred_layer_1_acc: 0.9012 - val_pred_layer_1_acc_1: 0.9290 - val_pred_layer_1_acc_2: 0.9337 - val_pred_layer_2_acc_1: 0.9359 - val_pred_layer_2_acc_2: 0.9363\n","\n","Epoch 00050: val_pred_layer_2_acc did not improve from 0.94315\n","Epoch 51/200\n","Learning rate:  0.001\n"," - 269s - loss: 3.8097 - pred_layer_2_loss: 0.2209 - pred_layer_0_loss: 0.5432 - pred_layer_1_loss: 0.2470 - pred_layer_2_acc: 0.9345 - pred_layer_0_acc: 0.7559 - pred_layer_0_acc_1: 0.8100 - pred_layer_0_acc_2: 0.8295 - pred_layer_1_acc: 0.8835 - pred_layer_1_acc_1: 0.9158 - pred_layer_1_acc_2: 0.9273 - pred_layer_2_acc_1: 0.9344 - pred_layer_2_acc_2: 0.9345 - val_loss: 3.5716 - val_pred_layer_2_loss: 0.2286 - val_pred_layer_0_loss: 0.4959 - val_pred_layer_1_loss: 0.2406 - val_pred_layer_2_acc: 0.9368 - val_pred_layer_0_acc: 0.7910 - val_pred_layer_0_acc_1: 0.8280 - val_pred_layer_0_acc_2: 0.8462 - val_pred_layer_1_acc: 0.8972 - val_pred_layer_1_acc_1: 0.9212 - val_pred_layer_1_acc_2: 0.9327 - val_pred_layer_2_acc_1: 0.9343 - val_pred_layer_2_acc_2: 0.9357\n","\n","Epoch 00051: val_pred_layer_2_acc did not improve from 0.94315\n","Epoch 52/200\n","Learning rate:  0.001\n"," - 268s - loss: 3.7974 - pred_layer_2_loss: 0.2192 - pred_layer_0_loss: 0.5431 - pred_layer_1_loss: 0.2437 - pred_layer_2_acc: 0.9359 - pred_layer_0_acc: 0.7591 - pred_layer_0_acc_1: 0.8108 - pred_layer_0_acc_2: 0.8314 - pred_layer_1_acc: 0.8839 - pred_layer_1_acc_1: 0.9166 - pred_layer_1_acc_2: 0.9293 - pred_layer_2_acc_1: 0.9356 - pred_layer_2_acc_2: 0.9357 - val_loss: 3.4134 - val_pred_layer_2_loss: 0.2172 - val_pred_layer_0_loss: 0.4561 - val_pred_layer_1_loss: 0.2261 - val_pred_layer_2_acc: 0.9384 - val_pred_layer_0_acc: 0.7975 - val_pred_layer_0_acc_1: 0.8438 - val_pred_layer_0_acc_2: 0.8600 - val_pred_layer_1_acc: 0.9006 - val_pred_layer_1_acc_1: 0.9265 - val_pred_layer_1_acc_2: 0.9366 - val_pred_layer_2_acc_1: 0.9378 - val_pred_layer_2_acc_2: 0.9382\n","\n","Epoch 00052: val_pred_layer_2_acc did not improve from 0.94315\n","Epoch 53/200\n","Learning rate:  0.001\n"," - 267s - loss: 3.7745 - pred_layer_2_loss: 0.2196 - pred_layer_0_loss: 0.5359 - pred_layer_1_loss: 0.2434 - pred_layer_2_acc: 0.9352 - pred_layer_0_acc: 0.7590 - pred_layer_0_acc_1: 0.8141 - pred_layer_0_acc_2: 0.8337 - pred_layer_1_acc: 0.8861 - pred_layer_1_acc_1: 0.9175 - pred_layer_1_acc_2: 0.9285 - pred_layer_2_acc_1: 0.9346 - pred_layer_2_acc_2: 0.9353 - val_loss: 3.2776 - val_pred_layer_2_loss: 0.2021 - val_pred_layer_0_loss: 0.4436 - val_pred_layer_1_loss: 0.2055 - val_pred_layer_2_acc: 0.9431 - val_pred_layer_0_acc: 0.7984 - val_pred_layer_0_acc_1: 0.8485 - val_pred_layer_0_acc_2: 0.8612 - val_pred_layer_1_acc: 0.9038 - val_pred_layer_1_acc_1: 0.9330 - val_pred_layer_1_acc_2: 0.9423 - val_pred_layer_2_acc_1: 0.9431 - val_pred_layer_2_acc_2: 0.9427\n","\n","Epoch 00053: val_pred_layer_2_acc did not improve from 0.94315\n","Epoch 54/200\n","Learning rate:  0.001\n"," - 266s - loss: 3.7816 - pred_layer_2_loss: 0.2182 - pred_layer_0_loss: 0.5392 - pred_layer_1_loss: 0.2436 - pred_layer_2_acc: 0.9355 - pred_layer_0_acc: 0.7597 - pred_layer_0_acc_1: 0.8128 - pred_layer_0_acc_2: 0.8331 - pred_layer_1_acc: 0.8844 - pred_layer_1_acc_1: 0.9159 - pred_layer_1_acc_2: 0.9290 - pred_layer_2_acc_1: 0.9350 - pred_layer_2_acc_2: 0.9355 - val_loss: 3.3198 - val_pred_layer_2_loss: 0.2020 - val_pred_layer_0_loss: 0.4661 - val_pred_layer_1_loss: 0.2063 - val_pred_layer_2_acc: 0.9441 - val_pred_layer_0_acc: 0.7908 - val_pred_layer_0_acc_1: 0.8448 - val_pred_layer_0_acc_2: 0.8597 - val_pred_layer_1_acc: 0.9081 - val_pred_layer_1_acc_1: 0.9334 - val_pred_layer_1_acc_2: 0.9422 - val_pred_layer_2_acc_1: 0.9438 - val_pred_layer_2_acc_2: 0.9444\n","\n","Epoch 00054: val_pred_layer_2_acc improved from 0.94315 to 0.94415, saving model to /content/gdrive/My Drive/colab/weights/svhn_SVHN_ResNet20v1_shared_model.054.h5\n","Epoch 55/200\n","Learning rate:  0.001\n"," - 266s - loss: 3.7621 - pred_layer_2_loss: 0.2177 - pred_layer_0_loss: 0.5360 - pred_layer_1_loss: 0.2421 - pred_layer_2_acc: 0.9364 - pred_layer_0_acc: 0.7596 - pred_layer_0_acc_1: 0.8136 - pred_layer_0_acc_2: 0.8323 - pred_layer_1_acc: 0.8855 - pred_layer_1_acc_1: 0.9175 - pred_layer_1_acc_2: 0.9294 - pred_layer_2_acc_1: 0.9359 - pred_layer_2_acc_2: 0.9363 - val_loss: 3.4814 - val_pred_layer_2_loss: 0.2287 - val_pred_layer_0_loss: 0.4721 - val_pred_layer_1_loss: 0.2282 - val_pred_layer_2_acc: 0.9365 - val_pred_layer_0_acc: 0.7919 - val_pred_layer_0_acc_1: 0.8386 - val_pred_layer_0_acc_2: 0.8534 - val_pred_layer_1_acc: 0.9007 - val_pred_layer_1_acc_1: 0.9258 - val_pred_layer_1_acc_2: 0.9360 - val_pred_layer_2_acc_1: 0.9363 - val_pred_layer_2_acc_2: 0.9361\n","\n","Epoch 00055: val_pred_layer_2_acc did not improve from 0.94415\n","Epoch 56/200\n","Learning rate:  0.001\n"," - 265s - loss: 3.7625 - pred_layer_2_loss: 0.2160 - pred_layer_0_loss: 0.5370 - pred_layer_1_loss: 0.2416 - pred_layer_2_acc: 0.9365 - pred_layer_0_acc: 0.7589 - pred_layer_0_acc_1: 0.8138 - pred_layer_0_acc_2: 0.8327 - pred_layer_1_acc: 0.8841 - pred_layer_1_acc_1: 0.9170 - pred_layer_1_acc_2: 0.9289 - pred_layer_2_acc_1: 0.9360 - pred_layer_2_acc_2: 0.9364 - val_loss: 3.3265 - val_pred_layer_2_loss: 0.2027 - val_pred_layer_0_loss: 0.4472 - val_pred_layer_1_loss: 0.2092 - val_pred_layer_2_acc: 0.9445 - val_pred_layer_0_acc: 0.7867 - val_pred_layer_0_acc_1: 0.8460 - val_pred_layer_0_acc_2: 0.8641 - val_pred_layer_1_acc: 0.9057 - val_pred_layer_1_acc_1: 0.9320 - val_pred_layer_1_acc_2: 0.9423 - val_pred_layer_2_acc_1: 0.9437 - val_pred_layer_2_acc_2: 0.9446\n","\n","Epoch 00056: val_pred_layer_2_acc improved from 0.94415 to 0.94449, saving model to /content/gdrive/My Drive/colab/weights/svhn_SVHN_ResNet20v1_shared_model.056.h5\n","Epoch 57/200\n","Learning rate:  0.001\n"," - 273s - loss: 3.7894 - pred_layer_2_loss: 0.2189 - pred_layer_0_loss: 0.5416 - pred_layer_1_loss: 0.2441 - pred_layer_2_acc: 0.9357 - pred_layer_0_acc: 0.7589 - pred_layer_0_acc_1: 0.8118 - pred_layer_0_acc_2: 0.8318 - pred_layer_1_acc: 0.8844 - pred_layer_1_acc_1: 0.9160 - pred_layer_1_acc_2: 0.9286 - pred_layer_2_acc_1: 0.9351 - pred_layer_2_acc_2: 0.9356 - val_loss: 3.4518 - val_pred_layer_2_loss: 0.2049 - val_pred_layer_0_loss: 0.4921 - val_pred_layer_1_loss: 0.2212 - val_pred_layer_2_acc: 0.9426 - val_pred_layer_0_acc: 0.7913 - val_pred_layer_0_acc_1: 0.8281 - val_pred_layer_0_acc_2: 0.8476 - val_pred_layer_1_acc: 0.9048 - val_pred_layer_1_acc_1: 0.9324 - val_pred_layer_1_acc_2: 0.9383 - val_pred_layer_2_acc_1: 0.9421 - val_pred_layer_2_acc_2: 0.9422\n","\n","Epoch 00057: val_pred_layer_2_acc did not improve from 0.94449\n","Epoch 58/200\n","Learning rate:  0.001\n"," - 286s - loss: 3.7451 - pred_layer_2_loss: 0.2159 - pred_layer_0_loss: 0.5344 - pred_layer_1_loss: 0.2403 - pred_layer_2_acc: 0.9365 - pred_layer_0_acc: 0.7621 - pred_layer_0_acc_1: 0.8153 - pred_layer_0_acc_2: 0.8344 - pred_layer_1_acc: 0.8855 - pred_layer_1_acc_1: 0.9176 - pred_layer_1_acc_2: 0.9293 - pred_layer_2_acc_1: 0.9357 - pred_layer_2_acc_2: 0.9364 - val_loss: 3.4156 - val_pred_layer_2_loss: 0.2282 - val_pred_layer_0_loss: 0.4569 - val_pred_layer_1_loss: 0.2272 - val_pred_layer_2_acc: 0.9351 - val_pred_layer_0_acc: 0.8033 - val_pred_layer_0_acc_1: 0.8481 - val_pred_layer_0_acc_2: 0.8613 - val_pred_layer_1_acc: 0.9036 - val_pred_layer_1_acc_1: 0.9285 - val_pred_layer_1_acc_2: 0.9366 - val_pred_layer_2_acc_1: 0.9347 - val_pred_layer_2_acc_2: 0.9347\n","\n","Epoch 00058: val_pred_layer_2_acc did not improve from 0.94449\n","Epoch 59/200\n","Learning rate:  0.001\n"," - 287s - loss: 3.7640 - pred_layer_2_loss: 0.2177 - pred_layer_0_loss: 0.5368 - pred_layer_1_loss: 0.2409 - pred_layer_2_acc: 0.9363 - pred_layer_0_acc: 0.7610 - pred_layer_0_acc_1: 0.8149 - pred_layer_0_acc_2: 0.8328 - pred_layer_1_acc: 0.8862 - pred_layer_1_acc_1: 0.9171 - pred_layer_1_acc_2: 0.9293 - pred_layer_2_acc_1: 0.9357 - pred_layer_2_acc_2: 0.9361 - val_loss: 3.4683 - val_pred_layer_2_loss: 0.2292 - val_pred_layer_0_loss: 0.4627 - val_pred_layer_1_loss: 0.2382 - val_pred_layer_2_acc: 0.9349 - val_pred_layer_0_acc: 0.8000 - val_pred_layer_0_acc_1: 0.8407 - val_pred_layer_0_acc_2: 0.8571 - val_pred_layer_1_acc: 0.9010 - val_pred_layer_1_acc_1: 0.9248 - val_pred_layer_1_acc_2: 0.9332 - val_pred_layer_2_acc_1: 0.9349 - val_pred_layer_2_acc_2: 0.9343\n","\n","Epoch 00059: val_pred_layer_2_acc did not improve from 0.94449\n","Epoch 60/200\n","Learning rate:  0.001\n"," - 283s - loss: 3.7265 - pred_layer_2_loss: 0.2134 - pred_layer_0_loss: 0.5329 - pred_layer_1_loss: 0.2380 - pred_layer_2_acc: 0.9372 - pred_layer_0_acc: 0.7621 - pred_layer_0_acc_1: 0.8152 - pred_layer_0_acc_2: 0.8341 - pred_layer_1_acc: 0.8868 - pred_layer_1_acc_1: 0.9176 - pred_layer_1_acc_2: 0.9297 - pred_layer_2_acc_1: 0.9365 - pred_layer_2_acc_2: 0.9371 - val_loss: 3.5002 - val_pred_layer_2_loss: 0.2263 - val_pred_layer_0_loss: 0.4928 - val_pred_layer_1_loss: 0.2283 - val_pred_layer_2_acc: 0.9366 - val_pred_layer_0_acc: 0.7920 - val_pred_layer_0_acc_1: 0.8387 - val_pred_layer_0_acc_2: 0.8466 - val_pred_layer_1_acc: 0.8984 - val_pred_layer_1_acc_1: 0.9287 - val_pred_layer_1_acc_2: 0.9360 - val_pred_layer_2_acc_1: 0.9353 - val_pred_layer_2_acc_2: 0.9363\n","\n","Epoch 00060: val_pred_layer_2_acc did not improve from 0.94449\n","Epoch 61/200\n","Learning rate:  0.001\n"," - 285s - loss: 3.7386 - pred_layer_2_loss: 0.2140 - pred_layer_0_loss: 0.5345 - pred_layer_1_loss: 0.2383 - pred_layer_2_acc: 0.9377 - pred_layer_0_acc: 0.7603 - pred_layer_0_acc_1: 0.8137 - pred_layer_0_acc_2: 0.8326 - pred_layer_1_acc: 0.8858 - pred_layer_1_acc_1: 0.9181 - pred_layer_1_acc_2: 0.9304 - pred_layer_2_acc_1: 0.9373 - pred_layer_2_acc_2: 0.9374 - val_loss: 3.4387 - val_pred_layer_2_loss: 0.2251 - val_pred_layer_0_loss: 0.4623 - val_pred_layer_1_loss: 0.2257 - val_pred_layer_2_acc: 0.9372 - val_pred_layer_0_acc: 0.7968 - val_pred_layer_0_acc_1: 0.8426 - val_pred_layer_0_acc_2: 0.8589 - val_pred_layer_1_acc: 0.9047 - val_pred_layer_1_acc_1: 0.9276 - val_pred_layer_1_acc_2: 0.9372 - val_pred_layer_2_acc_1: 0.9349 - val_pred_layer_2_acc_2: 0.9367\n","\n","Epoch 00061: val_pred_layer_2_acc did not improve from 0.94449\n","Epoch 62/200\n","Learning rate:  0.001\n"," - 289s - loss: 3.7273 - pred_layer_2_loss: 0.2126 - pred_layer_0_loss: 0.5313 - pred_layer_1_loss: 0.2384 - pred_layer_2_acc: 0.9377 - pred_layer_0_acc: 0.7600 - pred_layer_0_acc_1: 0.8164 - pred_layer_0_acc_2: 0.8349 - pred_layer_1_acc: 0.8866 - pred_layer_1_acc_1: 0.9186 - pred_layer_1_acc_2: 0.9311 - pred_layer_2_acc_1: 0.9371 - pred_layer_2_acc_2: 0.9378 - val_loss: 3.3217 - val_pred_layer_2_loss: 0.2179 - val_pred_layer_0_loss: 0.4338 - val_pred_layer_1_loss: 0.2341 - val_pred_layer_2_acc: 0.9389 - val_pred_layer_0_acc: 0.8083 - val_pred_layer_0_acc_1: 0.8525 - val_pred_layer_0_acc_2: 0.8684 - val_pred_layer_1_acc: 0.9076 - val_pred_layer_1_acc_1: 0.9271 - val_pred_layer_1_acc_2: 0.9336 - val_pred_layer_2_acc_1: 0.9382 - val_pred_layer_2_acc_2: 0.9379\n","\n","Epoch 00062: val_pred_layer_2_acc did not improve from 0.94449\n","Epoch 63/200\n","Learning rate:  0.001\n"," - 291s - loss: 3.7282 - pred_layer_2_loss: 0.2147 - pred_layer_0_loss: 0.5326 - pred_layer_1_loss: 0.2383 - pred_layer_2_acc: 0.9364 - pred_layer_0_acc: 0.7638 - pred_layer_0_acc_1: 0.8134 - pred_layer_0_acc_2: 0.8332 - pred_layer_1_acc: 0.8863 - pred_layer_1_acc_1: 0.9172 - pred_layer_1_acc_2: 0.9294 - pred_layer_2_acc_1: 0.9360 - pred_layer_2_acc_2: 0.9364 - val_loss: 3.3509 - val_pred_layer_2_loss: 0.2107 - val_pred_layer_0_loss: 0.4440 - val_pred_layer_1_loss: 0.2300 - val_pred_layer_2_acc: 0.9406 - val_pred_layer_0_acc: 0.7953 - val_pred_layer_0_acc_1: 0.8476 - val_pred_layer_0_acc_2: 0.8648 - val_pred_layer_1_acc: 0.9060 - val_pred_layer_1_acc_1: 0.9281 - val_pred_layer_1_acc_2: 0.9345 - val_pred_layer_2_acc_1: 0.9393 - val_pred_layer_2_acc_2: 0.9407\n","\n","Epoch 00063: val_pred_layer_2_acc did not improve from 0.94449\n","Epoch 64/200\n","Learning rate:  0.001\n"," - 283s - loss: 3.7125 - pred_layer_2_loss: 0.2125 - pred_layer_0_loss: 0.5300 - pred_layer_1_loss: 0.2366 - pred_layer_2_acc: 0.9381 - pred_layer_0_acc: 0.7638 - pred_layer_0_acc_1: 0.8183 - pred_layer_0_acc_2: 0.8357 - pred_layer_1_acc: 0.8880 - pred_layer_1_acc_1: 0.9192 - pred_layer_1_acc_2: 0.9314 - pred_layer_2_acc_1: 0.9376 - pred_layer_2_acc_2: 0.9381 - val_loss: 3.4640 - val_pred_layer_2_loss: 0.2249 - val_pred_layer_0_loss: 0.4672 - val_pred_layer_1_loss: 0.2287 - val_pred_layer_2_acc: 0.9370 - val_pred_layer_0_acc: 0.7930 - val_pred_layer_0_acc_1: 0.8392 - val_pred_layer_0_acc_2: 0.8554 - val_pred_layer_1_acc: 0.9040 - val_pred_layer_1_acc_1: 0.9290 - val_pred_layer_1_acc_2: 0.9340 - val_pred_layer_2_acc_1: 0.9340 - val_pred_layer_2_acc_2: 0.9363\n","\n","Epoch 00064: val_pred_layer_2_acc did not improve from 0.94449\n","Epoch 65/200\n","Learning rate:  0.001\n"," - 280s - loss: 3.6995 - pred_layer_2_loss: 0.2123 - pred_layer_0_loss: 0.5279 - pred_layer_1_loss: 0.2364 - pred_layer_2_acc: 0.9379 - pred_layer_0_acc: 0.7651 - pred_layer_0_acc_1: 0.8165 - pred_layer_0_acc_2: 0.8353 - pred_layer_1_acc: 0.8859 - pred_layer_1_acc_1: 0.9196 - pred_layer_1_acc_2: 0.9309 - pred_layer_2_acc_1: 0.9369 - pred_layer_2_acc_2: 0.9380 - val_loss: 3.2663 - val_pred_layer_2_loss: 0.2019 - val_pred_layer_0_loss: 0.4301 - val_pred_layer_1_loss: 0.2155 - val_pred_layer_2_acc: 0.9446 - val_pred_layer_0_acc: 0.8040 - val_pred_layer_0_acc_1: 0.8518 - val_pred_layer_0_acc_2: 0.8704 - val_pred_layer_1_acc: 0.9052 - val_pred_layer_1_acc_1: 0.9322 - val_pred_layer_1_acc_2: 0.9402 - val_pred_layer_2_acc_1: 0.9431 - val_pred_layer_2_acc_2: 0.9442\n","\n","Epoch 00065: val_pred_layer_2_acc improved from 0.94449 to 0.94461, saving model to /content/gdrive/My Drive/colab/weights/svhn_SVHN_ResNet20v1_shared_model.065.h5\n","Epoch 66/200\n","Learning rate:  0.001\n"," - 279s - loss: 3.7111 - pred_layer_2_loss: 0.2119 - pred_layer_0_loss: 0.5279 - pred_layer_1_loss: 0.2377 - pred_layer_2_acc: 0.9381 - pred_layer_0_acc: 0.7650 - pred_layer_0_acc_1: 0.8167 - pred_layer_0_acc_2: 0.8346 - pred_layer_1_acc: 0.8875 - pred_layer_1_acc_1: 0.9184 - pred_layer_1_acc_2: 0.9300 - pred_layer_2_acc_1: 0.9374 - pred_layer_2_acc_2: 0.9382 - val_loss: 3.4818 - val_pred_layer_2_loss: 0.2172 - val_pred_layer_0_loss: 0.4741 - val_pred_layer_1_loss: 0.2377 - val_pred_layer_2_acc: 0.9387 - val_pred_layer_0_acc: 0.7996 - val_pred_layer_0_acc_1: 0.8373 - val_pred_layer_0_acc_2: 0.8581 - val_pred_layer_1_acc: 0.9042 - val_pred_layer_1_acc_1: 0.9264 - val_pred_layer_1_acc_2: 0.9331 - val_pred_layer_2_acc_1: 0.9374 - val_pred_layer_2_acc_2: 0.9386\n","\n","Epoch 00066: val_pred_layer_2_acc did not improve from 0.94461\n","Epoch 67/200\n","Learning rate:  0.001\n"," - 279s - loss: 3.7097 - pred_layer_2_loss: 0.2129 - pred_layer_0_loss: 0.5289 - pred_layer_1_loss: 0.2364 - pred_layer_2_acc: 0.9369 - pred_layer_0_acc: 0.7640 - pred_layer_0_acc_1: 0.8160 - pred_layer_0_acc_2: 0.8349 - pred_layer_1_acc: 0.8881 - pred_layer_1_acc_1: 0.9193 - pred_layer_1_acc_2: 0.9317 - pred_layer_2_acc_1: 0.9366 - pred_layer_2_acc_2: 0.9369 - val_loss: 3.2744 - val_pred_layer_2_loss: 0.1861 - val_pred_layer_0_loss: 0.4570 - val_pred_layer_1_loss: 0.1975 - val_pred_layer_2_acc: 0.9504 - val_pred_layer_0_acc: 0.7909 - val_pred_layer_0_acc_1: 0.8394 - val_pred_layer_0_acc_2: 0.8599 - val_pred_layer_1_acc: 0.9093 - val_pred_layer_1_acc_1: 0.9365 - val_pred_layer_1_acc_2: 0.9472 - val_pred_layer_2_acc_1: 0.9501 - val_pred_layer_2_acc_2: 0.9505\n","\n","Epoch 00067: val_pred_layer_2_acc improved from 0.94461 to 0.95037, saving model to /content/gdrive/My Drive/colab/weights/svhn_SVHN_ResNet20v1_shared_model.067.h5\n","Epoch 68/200\n","Learning rate:  0.001\n"," - 279s - loss: 3.7164 - pred_layer_2_loss: 0.2133 - pred_layer_0_loss: 0.5297 - pred_layer_1_loss: 0.2377 - pred_layer_2_acc: 0.9377 - pred_layer_0_acc: 0.7658 - pred_layer_0_acc_1: 0.8180 - pred_layer_0_acc_2: 0.8359 - pred_layer_1_acc: 0.8878 - pred_layer_1_acc_1: 0.9183 - pred_layer_1_acc_2: 0.9305 - pred_layer_2_acc_1: 0.9370 - pred_layer_2_acc_2: 0.9377 - val_loss: 3.2916 - val_pred_layer_2_loss: 0.2024 - val_pred_layer_0_loss: 0.4341 - val_pred_layer_1_loss: 0.2183 - val_pred_layer_2_acc: 0.9426 - val_pred_layer_0_acc: 0.8012 - val_pred_layer_0_acc_1: 0.8503 - val_pred_layer_0_acc_2: 0.8702 - val_pred_layer_1_acc: 0.9100 - val_pred_layer_1_acc_1: 0.9326 - val_pred_layer_1_acc_2: 0.9400 - val_pred_layer_2_acc_1: 0.9412 - val_pred_layer_2_acc_2: 0.9427\n","\n","Epoch 00068: val_pred_layer_2_acc did not improve from 0.95037\n","Epoch 69/200\n","Learning rate:  0.001\n"," - 276s - loss: 3.7057 - pred_layer_2_loss: 0.2118 - pred_layer_0_loss: 0.5274 - pred_layer_1_loss: 0.2367 - pred_layer_2_acc: 0.9386 - pred_layer_0_acc: 0.7652 - pred_layer_0_acc_1: 0.8181 - pred_layer_0_acc_2: 0.8361 - pred_layer_1_acc: 0.8874 - pred_layer_1_acc_1: 0.9189 - pred_layer_1_acc_2: 0.9308 - pred_layer_2_acc_1: 0.9373 - pred_layer_2_acc_2: 0.9384 - val_loss: 3.3414 - val_pred_layer_2_loss: 0.2010 - val_pred_layer_0_loss: 0.4578 - val_pred_layer_1_loss: 0.2088 - val_pred_layer_2_acc: 0.9426 - val_pred_layer_0_acc: 0.7972 - val_pred_layer_0_acc_1: 0.8399 - val_pred_layer_0_acc_2: 0.8631 - val_pred_layer_1_acc: 0.9074 - val_pred_layer_1_acc_1: 0.9342 - val_pred_layer_1_acc_2: 0.9411 - val_pred_layer_2_acc_1: 0.9428 - val_pred_layer_2_acc_2: 0.9428\n","\n","Epoch 00069: val_pred_layer_2_acc did not improve from 0.95037\n","Epoch 70/200\n","Learning rate:  0.001\n"," - 277s - loss: 3.6982 - pred_layer_2_loss: 0.2113 - pred_layer_0_loss: 0.5282 - pred_layer_1_loss: 0.2347 - pred_layer_2_acc: 0.9389 - pred_layer_0_acc: 0.7644 - pred_layer_0_acc_1: 0.8171 - pred_layer_0_acc_2: 0.8351 - pred_layer_1_acc: 0.8880 - pred_layer_1_acc_1: 0.9206 - pred_layer_1_acc_2: 0.9314 - pred_layer_2_acc_1: 0.9381 - pred_layer_2_acc_2: 0.9390 - val_loss: 3.3017 - val_pred_layer_2_loss: 0.2050 - val_pred_layer_0_loss: 0.4416 - val_pred_layer_1_loss: 0.2205 - val_pred_layer_2_acc: 0.9421 - val_pred_layer_0_acc: 0.8045 - val_pred_layer_0_acc_1: 0.8470 - val_pred_layer_0_acc_2: 0.8647 - val_pred_layer_1_acc: 0.9068 - val_pred_layer_1_acc_1: 0.9319 - val_pred_layer_1_acc_2: 0.9378 - val_pred_layer_2_acc_1: 0.9419 - val_pred_layer_2_acc_2: 0.9422\n","\n","Epoch 00070: val_pred_layer_2_acc did not improve from 0.95037\n","Epoch 71/200\n","Learning rate:  0.001\n"," - 274s - loss: 3.7088 - pred_layer_2_loss: 0.2128 - pred_layer_0_loss: 0.5282 - pred_layer_1_loss: 0.2364 - pred_layer_2_acc: 0.9377 - pred_layer_0_acc: 0.7655 - pred_layer_0_acc_1: 0.8188 - pred_layer_0_acc_2: 0.8366 - pred_layer_1_acc: 0.8869 - pred_layer_1_acc_1: 0.9196 - pred_layer_1_acc_2: 0.9308 - pred_layer_2_acc_1: 0.9369 - pred_layer_2_acc_2: 0.9378 - val_loss: 3.4072 - val_pred_layer_2_loss: 0.2234 - val_pred_layer_0_loss: 0.4483 - val_pred_layer_1_loss: 0.2295 - val_pred_layer_2_acc: 0.9368 - val_pred_layer_0_acc: 0.8016 - val_pred_layer_0_acc_1: 0.8481 - val_pred_layer_0_acc_2: 0.8632 - val_pred_layer_1_acc: 0.9018 - val_pred_layer_1_acc_1: 0.9284 - val_pred_layer_1_acc_2: 0.9349 - val_pred_layer_2_acc_1: 0.9348 - val_pred_layer_2_acc_2: 0.9363\n","\n","Epoch 00071: val_pred_layer_2_acc did not improve from 0.95037\n","Epoch 72/200\n","Learning rate:  0.001\n"," - 273s - loss: 3.6823 - pred_layer_2_loss: 0.2081 - pred_layer_0_loss: 0.5274 - pred_layer_1_loss: 0.2335 - pred_layer_2_acc: 0.9394 - pred_layer_0_acc: 0.7673 - pred_layer_0_acc_1: 0.8190 - pred_layer_0_acc_2: 0.8385 - pred_layer_1_acc: 0.8874 - pred_layer_1_acc_1: 0.9197 - pred_layer_1_acc_2: 0.9311 - pred_layer_2_acc_1: 0.9390 - pred_layer_2_acc_2: 0.9396 - val_loss: 3.3181 - val_pred_layer_2_loss: 0.2077 - val_pred_layer_0_loss: 0.4407 - val_pred_layer_1_loss: 0.2245 - val_pred_layer_2_acc: 0.9416 - val_pred_layer_0_acc: 0.8053 - val_pred_layer_0_acc_1: 0.8501 - val_pred_layer_0_acc_2: 0.8676 - val_pred_layer_1_acc: 0.9075 - val_pred_layer_1_acc_1: 0.9305 - val_pred_layer_1_acc_2: 0.9378 - val_pred_layer_2_acc_1: 0.9411 - val_pred_layer_2_acc_2: 0.9417\n","\n","Epoch 00072: val_pred_layer_2_acc did not improve from 0.95037\n","Epoch 73/200\n","Learning rate:  0.001\n"," - 274s - loss: 3.6995 - pred_layer_2_loss: 0.2119 - pred_layer_0_loss: 0.5265 - pred_layer_1_loss: 0.2361 - pred_layer_2_acc: 0.9372 - pred_layer_0_acc: 0.7654 - pred_layer_0_acc_1: 0.8188 - pred_layer_0_acc_2: 0.8366 - pred_layer_1_acc: 0.8874 - pred_layer_1_acc_1: 0.9194 - pred_layer_1_acc_2: 0.9303 - pred_layer_2_acc_1: 0.9368 - pred_layer_2_acc_2: 0.9374 - val_loss: 3.2871 - val_pred_layer_2_loss: 0.2057 - val_pred_layer_0_loss: 0.4367 - val_pred_layer_1_loss: 0.2122 - val_pred_layer_2_acc: 0.9425 - val_pred_layer_0_acc: 0.8047 - val_pred_layer_0_acc_1: 0.8454 - val_pred_layer_0_acc_2: 0.8682 - val_pred_layer_1_acc: 0.9116 - val_pred_layer_1_acc_1: 0.9361 - val_pred_layer_1_acc_2: 0.9425 - val_pred_layer_2_acc_1: 0.9420 - val_pred_layer_2_acc_2: 0.9424\n","\n","Epoch 00073: val_pred_layer_2_acc did not improve from 0.95037\n","Epoch 74/200\n","Learning rate:  0.001\n"," - 274s - loss: 3.6592 - pred_layer_2_loss: 0.2080 - pred_layer_0_loss: 0.5204 - pred_layer_1_loss: 0.2308 - pred_layer_2_acc: 0.9391 - pred_layer_0_acc: 0.7682 - pred_layer_0_acc_1: 0.8215 - pred_layer_0_acc_2: 0.8391 - pred_layer_1_acc: 0.8890 - pred_layer_1_acc_1: 0.9207 - pred_layer_1_acc_2: 0.9330 - pred_layer_2_acc_1: 0.9388 - pred_layer_2_acc_2: 0.9391 - val_loss: 3.5581 - val_pred_layer_2_loss: 0.2211 - val_pred_layer_0_loss: 0.4961 - val_pred_layer_1_loss: 0.2333 - val_pred_layer_2_acc: 0.9357 - val_pred_layer_0_acc: 0.8018 - val_pred_layer_0_acc_1: 0.8332 - val_pred_layer_0_acc_2: 0.8455 - val_pred_layer_1_acc: 0.8874 - val_pred_layer_1_acc_1: 0.9216 - val_pred_layer_1_acc_2: 0.9339 - val_pred_layer_2_acc_1: 0.9353 - val_pred_layer_2_acc_2: 0.9357\n","\n","Epoch 00074: val_pred_layer_2_acc did not improve from 0.95037\n","Epoch 75/200\n","Learning rate:  0.001\n"," - 270s - loss: 3.6871 - pred_layer_2_loss: 0.2096 - pred_layer_0_loss: 0.5255 - pred_layer_1_loss: 0.2346 - pred_layer_2_acc: 0.9388 - pred_layer_0_acc: 0.7655 - pred_layer_0_acc_1: 0.8194 - pred_layer_0_acc_2: 0.8363 - pred_layer_1_acc: 0.8895 - pred_layer_1_acc_1: 0.9193 - pred_layer_1_acc_2: 0.9310 - pred_layer_2_acc_1: 0.9385 - pred_layer_2_acc_2: 0.9388 - val_loss: 3.3040 - val_pred_layer_2_loss: 0.2175 - val_pred_layer_0_loss: 0.4326 - val_pred_layer_1_loss: 0.2213 - val_pred_layer_2_acc: 0.9372 - val_pred_layer_0_acc: 0.8114 - val_pred_layer_0_acc_1: 0.8527 - val_pred_layer_0_acc_2: 0.8686 - val_pred_layer_1_acc: 0.9039 - val_pred_layer_1_acc_1: 0.9311 - val_pred_layer_1_acc_2: 0.9371 - val_pred_layer_2_acc_1: 0.9372 - val_pred_layer_2_acc_2: 0.9373\n","\n","Epoch 00075: val_pred_layer_2_acc did not improve from 0.95037\n","Epoch 76/200\n","Learning rate:  0.001\n"," - 271s - loss: 3.6762 - pred_layer_2_loss: 0.2083 - pred_layer_0_loss: 0.5257 - pred_layer_1_loss: 0.2321 - pred_layer_2_acc: 0.9393 - pred_layer_0_acc: 0.7665 - pred_layer_0_acc_1: 0.8187 - pred_layer_0_acc_2: 0.8360 - pred_layer_1_acc: 0.8889 - pred_layer_1_acc_1: 0.9201 - pred_layer_1_acc_2: 0.9324 - pred_layer_2_acc_1: 0.9387 - pred_layer_2_acc_2: 0.9395 - val_loss: 3.2802 - val_pred_layer_2_loss: 0.2002 - val_pred_layer_0_loss: 0.4391 - val_pred_layer_1_loss: 0.2054 - val_pred_layer_2_acc: 0.9458 - val_pred_layer_0_acc: 0.8001 - val_pred_layer_0_acc_1: 0.8443 - val_pred_layer_0_acc_2: 0.8700 - val_pred_layer_1_acc: 0.9125 - val_pred_layer_1_acc_1: 0.9374 - val_pred_layer_1_acc_2: 0.9441 - val_pred_layer_2_acc_1: 0.9439 - val_pred_layer_2_acc_2: 0.9456\n","\n","Epoch 00076: val_pred_layer_2_acc did not improve from 0.95037\n","Epoch 77/200\n","Learning rate:  0.001\n"," - 265s - loss: 3.6560 - pred_layer_2_loss: 0.2072 - pred_layer_0_loss: 0.5207 - pred_layer_1_loss: 0.2305 - pred_layer_2_acc: 0.9384 - pred_layer_0_acc: 0.7683 - pred_layer_0_acc_1: 0.8191 - pred_layer_0_acc_2: 0.8365 - pred_layer_1_acc: 0.8892 - pred_layer_1_acc_1: 0.9204 - pred_layer_1_acc_2: 0.9316 - pred_layer_2_acc_1: 0.9378 - pred_layer_2_acc_2: 0.9387 - val_loss: 3.2687 - val_pred_layer_2_loss: 0.2078 - val_pred_layer_0_loss: 0.4325 - val_pred_layer_1_loss: 0.2098 - val_pred_layer_2_acc: 0.9420 - val_pred_layer_0_acc: 0.8045 - val_pred_layer_0_acc_1: 0.8486 - val_pred_layer_0_acc_2: 0.8673 - val_pred_layer_1_acc: 0.9078 - val_pred_layer_1_acc_1: 0.9354 - val_pred_layer_1_acc_2: 0.9424 - val_pred_layer_2_acc_1: 0.9416 - val_pred_layer_2_acc_2: 0.9423\n","\n","Epoch 00077: val_pred_layer_2_acc did not improve from 0.95037\n","Epoch 78/200\n","Learning rate:  0.001\n"," - 264s - loss: 3.6682 - pred_layer_2_loss: 0.2089 - pred_layer_0_loss: 0.5214 - pred_layer_1_loss: 0.2316 - pred_layer_2_acc: 0.9391 - pred_layer_0_acc: 0.7679 - pred_layer_0_acc_1: 0.8200 - pred_layer_0_acc_2: 0.8369 - pred_layer_1_acc: 0.8889 - pred_layer_1_acc_1: 0.9215 - pred_layer_1_acc_2: 0.9325 - pred_layer_2_acc_1: 0.9387 - pred_layer_2_acc_2: 0.9392 - val_loss: 3.4137 - val_pred_layer_2_loss: 0.2180 - val_pred_layer_0_loss: 0.4709 - val_pred_layer_1_loss: 0.2245 - val_pred_layer_2_acc: 0.9384 - val_pred_layer_0_acc: 0.7973 - val_pred_layer_0_acc_1: 0.8386 - val_pred_layer_0_acc_2: 0.8541 - val_pred_layer_1_acc: 0.9072 - val_pred_layer_1_acc_1: 0.9327 - val_pred_layer_1_acc_2: 0.9385 - val_pred_layer_2_acc_1: 0.9370 - val_pred_layer_2_acc_2: 0.9385\n","\n","Epoch 00078: val_pred_layer_2_acc did not improve from 0.95037\n","Epoch 79/200\n","Learning rate:  0.001\n"," - 260s - loss: 3.6520 - pred_layer_2_loss: 0.2072 - pred_layer_0_loss: 0.5196 - pred_layer_1_loss: 0.2309 - pred_layer_2_acc: 0.9390 - pred_layer_0_acc: 0.7679 - pred_layer_0_acc_1: 0.8225 - pred_layer_0_acc_2: 0.8389 - pred_layer_1_acc: 0.8904 - pred_layer_1_acc_1: 0.9204 - pred_layer_1_acc_2: 0.9325 - pred_layer_2_acc_1: 0.9381 - pred_layer_2_acc_2: 0.9390 - val_loss: 3.4051 - val_pred_layer_2_loss: 0.2085 - val_pred_layer_0_loss: 0.4580 - val_pred_layer_1_loss: 0.2198 - val_pred_layer_2_acc: 0.9421 - val_pred_layer_0_acc: 0.7920 - val_pred_layer_0_acc_1: 0.8391 - val_pred_layer_0_acc_2: 0.8586 - val_pred_layer_1_acc: 0.9010 - val_pred_layer_1_acc_1: 0.9288 - val_pred_layer_1_acc_2: 0.9384 - val_pred_layer_2_acc_1: 0.9414 - val_pred_layer_2_acc_2: 0.9419\n","\n","Epoch 00079: val_pred_layer_2_acc did not improve from 0.95037\n","Epoch 80/200\n","Learning rate:  0.001\n"," - 274s - loss: 3.6861 - pred_layer_2_loss: 0.2118 - pred_layer_0_loss: 0.5220 - pred_layer_1_loss: 0.2359 - pred_layer_2_acc: 0.9371 - pred_layer_0_acc: 0.7671 - pred_layer_0_acc_1: 0.8209 - pred_layer_0_acc_2: 0.8369 - pred_layer_1_acc: 0.8885 - pred_layer_1_acc_1: 0.9183 - pred_layer_1_acc_2: 0.9293 - pred_layer_2_acc_1: 0.9367 - pred_layer_2_acc_2: 0.9371 - val_loss: 3.3840 - val_pred_layer_2_loss: 0.2166 - val_pred_layer_0_loss: 0.4671 - val_pred_layer_1_loss: 0.2211 - val_pred_layer_2_acc: 0.9397 - val_pred_layer_0_acc: 0.8064 - val_pred_layer_0_acc_1: 0.8413 - val_pred_layer_0_acc_2: 0.8558 - val_pred_layer_1_acc: 0.9009 - val_pred_layer_1_acc_1: 0.9300 - val_pred_layer_1_acc_2: 0.9394 - val_pred_layer_2_acc_1: 0.9396 - val_pred_layer_2_acc_2: 0.9403\n","\n","Epoch 00080: val_pred_layer_2_acc did not improve from 0.95037\n","Epoch 81/200\n","Learning rate:  0.001\n"," - 286s - loss: 3.6684 - pred_layer_2_loss: 0.2101 - pred_layer_0_loss: 0.5194 - pred_layer_1_loss: 0.2326 - pred_layer_2_acc: 0.9387 - pred_layer_0_acc: 0.7693 - pred_layer_0_acc_1: 0.8201 - pred_layer_0_acc_2: 0.8381 - pred_layer_1_acc: 0.8887 - pred_layer_1_acc_1: 0.9210 - pred_layer_1_acc_2: 0.9317 - pred_layer_2_acc_1: 0.9379 - pred_layer_2_acc_2: 0.9384 - val_loss: 3.3711 - val_pred_layer_2_loss: 0.2109 - val_pred_layer_0_loss: 0.4579 - val_pred_layer_1_loss: 0.2230 - val_pred_layer_2_acc: 0.9402 - val_pred_layer_0_acc: 0.8080 - val_pred_layer_0_acc_1: 0.8478 - val_pred_layer_0_acc_2: 0.8598 - val_pred_layer_1_acc: 0.9009 - val_pred_layer_1_acc_1: 0.9258 - val_pred_layer_1_acc_2: 0.9376 - val_pred_layer_2_acc_1: 0.9397 - val_pred_layer_2_acc_2: 0.9402\n","\n","Epoch 00081: val_pred_layer_2_acc did not improve from 0.95037\n","Epoch 82/200\n","Learning rate:  0.0001\n"," - 283s - loss: 3.3682 - pred_layer_2_loss: 0.1701 - pred_layer_0_loss: 0.4922 - pred_layer_1_loss: 0.1981 - pred_layer_2_acc: 0.9512 - pred_layer_0_acc: 0.7783 - pred_layer_0_acc_1: 0.8296 - pred_layer_0_acc_2: 0.8482 - pred_layer_1_acc: 0.8984 - pred_layer_1_acc_1: 0.9305 - pred_layer_1_acc_2: 0.9426 - pred_layer_2_acc_1: 0.9512 - pred_layer_2_acc_2: 0.9513 - val_loss: 3.0063 - val_pred_layer_2_loss: 0.1730 - val_pred_layer_0_loss: 0.4083 - val_pred_layer_1_loss: 0.1839 - val_pred_layer_2_acc: 0.9526 - val_pred_layer_0_acc: 0.8155 - val_pred_layer_0_acc_1: 0.8596 - val_pred_layer_0_acc_2: 0.8753 - val_pred_layer_1_acc: 0.9191 - val_pred_layer_1_acc_1: 0.9423 - val_pred_layer_1_acc_2: 0.9511 - val_pred_layer_2_acc_1: 0.9524 - val_pred_layer_2_acc_2: 0.9528\n","\n","Epoch 00082: val_pred_layer_2_acc improved from 0.95037 to 0.95264, saving model to /content/gdrive/My Drive/colab/weights/svhn_SVHN_ResNet20v1_shared_model.082.h5\n","Epoch 83/200\n","Learning rate:  0.0001\n"," - 287s - loss: 3.3081 - pred_layer_2_loss: 0.1607 - pred_layer_0_loss: 0.4879 - pred_layer_1_loss: 0.1900 - pred_layer_2_acc: 0.9537 - pred_layer_0_acc: 0.7781 - pred_layer_0_acc_1: 0.8303 - pred_layer_0_acc_2: 0.8486 - pred_layer_1_acc: 0.9006 - pred_layer_1_acc_1: 0.9315 - pred_layer_1_acc_2: 0.9459 - pred_layer_2_acc_1: 0.9533 - pred_layer_2_acc_2: 0.9536 - val_loss: 3.0115 - val_pred_layer_2_loss: 0.1777 - val_pred_layer_0_loss: 0.4059 - val_pred_layer_1_loss: 0.1857 - val_pred_layer_2_acc: 0.9514 - val_pred_layer_0_acc: 0.8187 - val_pred_layer_0_acc_1: 0.8619 - val_pred_layer_0_acc_2: 0.8772 - val_pred_layer_1_acc: 0.9186 - val_pred_layer_1_acc_1: 0.9420 - val_pred_layer_1_acc_2: 0.9494 - val_pred_layer_2_acc_1: 0.9510 - val_pred_layer_2_acc_2: 0.9511\n","\n","Epoch 00083: val_pred_layer_2_acc did not improve from 0.95264\n","Epoch 84/200\n","Learning rate:  0.0001\n"," - 285s - loss: 3.2939 - pred_layer_2_loss: 0.1575 - pred_layer_0_loss: 0.4894 - pred_layer_1_loss: 0.1880 - pred_layer_2_acc: 0.9551 - pred_layer_0_acc: 0.7803 - pred_layer_0_acc_1: 0.8307 - pred_layer_0_acc_2: 0.8484 - pred_layer_1_acc: 0.8998 - pred_layer_1_acc_1: 0.9331 - pred_layer_1_acc_2: 0.9467 - pred_layer_2_acc_1: 0.9545 - pred_layer_2_acc_2: 0.9552 - val_loss: 2.9859 - val_pred_layer_2_loss: 0.1760 - val_pred_layer_0_loss: 0.4001 - val_pred_layer_1_loss: 0.1844 - val_pred_layer_2_acc: 0.9525 - val_pred_layer_0_acc: 0.8181 - val_pred_layer_0_acc_1: 0.8626 - val_pred_layer_0_acc_2: 0.8805 - val_pred_layer_1_acc: 0.9203 - val_pred_layer_1_acc_1: 0.9433 - val_pred_layer_1_acc_2: 0.9504 - val_pred_layer_2_acc_1: 0.9516 - val_pred_layer_2_acc_2: 0.9525\n","\n","Epoch 00084: val_pred_layer_2_acc did not improve from 0.95264\n","Epoch 85/200\n","Learning rate:  0.0001\n"," - 287s - loss: 3.2698 - pred_layer_2_loss: 0.1562 - pred_layer_0_loss: 0.4848 - pred_layer_1_loss: 0.1853 - pred_layer_2_acc: 0.9556 - pred_layer_0_acc: 0.7803 - pred_layer_0_acc_1: 0.8320 - pred_layer_0_acc_2: 0.8492 - pred_layer_1_acc: 0.9012 - pred_layer_1_acc_1: 0.9334 - pred_layer_1_acc_2: 0.9469 - pred_layer_2_acc_1: 0.9551 - pred_layer_2_acc_2: 0.9557 - val_loss: 3.0194 - val_pred_layer_2_loss: 0.1775 - val_pred_layer_0_loss: 0.4115 - val_pred_layer_1_loss: 0.1862 - val_pred_layer_2_acc: 0.9520 - val_pred_layer_0_acc: 0.8168 - val_pred_layer_0_acc_1: 0.8596 - val_pred_layer_0_acc_2: 0.8760 - val_pred_layer_1_acc: 0.9188 - val_pred_layer_1_acc_1: 0.9422 - val_pred_layer_1_acc_2: 0.9502 - val_pred_layer_2_acc_1: 0.9521 - val_pred_layer_2_acc_2: 0.9521\n","\n","Epoch 00085: val_pred_layer_2_acc did not improve from 0.95264\n","Epoch 86/200\n","Learning rate:  0.0001\n"," - 286s - loss: 3.2585 - pred_layer_2_loss: 0.1540 - pred_layer_0_loss: 0.4829 - pred_layer_1_loss: 0.1854 - pred_layer_2_acc: 0.9555 - pred_layer_0_acc: 0.7810 - pred_layer_0_acc_1: 0.8328 - pred_layer_0_acc_2: 0.8496 - pred_layer_1_acc: 0.9005 - pred_layer_1_acc_1: 0.9322 - pred_layer_1_acc_2: 0.9467 - pred_layer_2_acc_1: 0.9551 - pred_layer_2_acc_2: 0.9556 - val_loss: 2.9812 - val_pred_layer_2_loss: 0.1764 - val_pred_layer_0_loss: 0.4015 - val_pred_layer_1_loss: 0.1855 - val_pred_layer_2_acc: 0.9512 - val_pred_layer_0_acc: 0.8195 - val_pred_layer_0_acc_1: 0.8619 - val_pred_layer_0_acc_2: 0.8790 - val_pred_layer_1_acc: 0.9194 - val_pred_layer_1_acc_1: 0.9434 - val_pred_layer_1_acc_2: 0.9494 - val_pred_layer_2_acc_1: 0.9514 - val_pred_layer_2_acc_2: 0.9514\n","\n","Epoch 00086: val_pred_layer_2_acc did not improve from 0.95264\n","Epoch 87/200\n","Learning rate:  0.0001\n"," - 285s - loss: 3.2518 - pred_layer_2_loss: 0.1517 - pred_layer_0_loss: 0.4856 - pred_layer_1_loss: 0.1832 - pred_layer_2_acc: 0.9566 - pred_layer_0_acc: 0.7811 - pred_layer_0_acc_1: 0.8319 - pred_layer_0_acc_2: 0.8494 - pred_layer_1_acc: 0.9006 - pred_layer_1_acc_1: 0.9333 - pred_layer_1_acc_2: 0.9477 - pred_layer_2_acc_1: 0.9566 - pred_layer_2_acc_2: 0.9567 - val_loss: 2.9930 - val_pred_layer_2_loss: 0.1751 - val_pred_layer_0_loss: 0.4078 - val_pred_layer_1_loss: 0.1849 - val_pred_layer_2_acc: 0.9525 - val_pred_layer_0_acc: 0.8196 - val_pred_layer_0_acc_1: 0.8611 - val_pred_layer_0_acc_2: 0.8773 - val_pred_layer_1_acc: 0.9191 - val_pred_layer_1_acc_1: 0.9414 - val_pred_layer_1_acc_2: 0.9505 - val_pred_layer_2_acc_1: 0.9523 - val_pred_layer_2_acc_2: 0.9527\n","\n","Epoch 00087: val_pred_layer_2_acc did not improve from 0.95264\n","Epoch 88/200\n","Learning rate:  0.0001\n"," - 290s - loss: 3.2451 - pred_layer_2_loss: 0.1507 - pred_layer_0_loss: 0.4871 - pred_layer_1_loss: 0.1827 - pred_layer_2_acc: 0.9576 - pred_layer_0_acc: 0.7823 - pred_layer_0_acc_1: 0.8323 - pred_layer_0_acc_2: 0.8491 - pred_layer_1_acc: 0.9017 - pred_layer_1_acc_1: 0.9355 - pred_layer_1_acc_2: 0.9484 - pred_layer_2_acc_1: 0.9572 - pred_layer_2_acc_2: 0.9575 - val_loss: 2.9580 - val_pred_layer_2_loss: 0.1756 - val_pred_layer_0_loss: 0.3979 - val_pred_layer_1_loss: 0.1832 - val_pred_layer_2_acc: 0.9524 - val_pred_layer_0_acc: 0.8222 - val_pred_layer_0_acc_1: 0.8632 - val_pred_layer_0_acc_2: 0.8803 - val_pred_layer_1_acc: 0.9211 - val_pred_layer_1_acc_1: 0.9433 - val_pred_layer_1_acc_2: 0.9503 - val_pred_layer_2_acc_1: 0.9521 - val_pred_layer_2_acc_2: 0.9524\n","\n","Epoch 00088: val_pred_layer_2_acc did not improve from 0.95264\n","Epoch 89/200\n","Learning rate:  0.0001\n"," - 294s - loss: 3.2269 - pred_layer_2_loss: 0.1495 - pred_layer_0_loss: 0.4814 - pred_layer_1_loss: 0.1817 - pred_layer_2_acc: 0.9575 - pred_layer_0_acc: 0.7819 - pred_layer_0_acc_1: 0.8331 - pred_layer_0_acc_2: 0.8505 - pred_layer_1_acc: 0.9019 - pred_layer_1_acc_1: 0.9335 - pred_layer_1_acc_2: 0.9485 - pred_layer_2_acc_1: 0.9568 - pred_layer_2_acc_2: 0.9575 - val_loss: 2.9910 - val_pred_layer_2_loss: 0.1793 - val_pred_layer_0_loss: 0.4022 - val_pred_layer_1_loss: 0.1867 - val_pred_layer_2_acc: 0.9515 - val_pred_layer_0_acc: 0.8208 - val_pred_layer_0_acc_1: 0.8629 - val_pred_layer_0_acc_2: 0.8791 - val_pred_layer_1_acc: 0.9195 - val_pred_layer_1_acc_1: 0.9425 - val_pred_layer_1_acc_2: 0.9506 - val_pred_layer_2_acc_1: 0.9515 - val_pred_layer_2_acc_2: 0.9516\n","\n","Epoch 00089: val_pred_layer_2_acc did not improve from 0.95264\n","Epoch 90/200\n","Learning rate:  0.0001\n"," - 291s - loss: 3.2115 - pred_layer_2_loss: 0.1477 - pred_layer_0_loss: 0.4834 - pred_layer_1_loss: 0.1781 - pred_layer_2_acc: 0.9583 - pred_layer_0_acc: 0.7825 - pred_layer_0_acc_1: 0.8338 - pred_layer_0_acc_2: 0.8507 - pred_layer_1_acc: 0.9014 - pred_layer_1_acc_1: 0.9343 - pred_layer_1_acc_2: 0.9490 - pred_layer_2_acc_1: 0.9578 - pred_layer_2_acc_2: 0.9584 - val_loss: 2.9773 - val_pred_layer_2_loss: 0.1727 - val_pred_layer_0_loss: 0.4083 - val_pred_layer_1_loss: 0.1822 - val_pred_layer_2_acc: 0.9539 - val_pred_layer_0_acc: 0.8176 - val_pred_layer_0_acc_1: 0.8593 - val_pred_layer_0_acc_2: 0.8755 - val_pred_layer_1_acc: 0.9199 - val_pred_layer_1_acc_1: 0.9438 - val_pred_layer_1_acc_2: 0.9517 - val_pred_layer_2_acc_1: 0.9533 - val_pred_layer_2_acc_2: 0.9537\n","\n","Epoch 00090: val_pred_layer_2_acc improved from 0.95264 to 0.95386, saving model to /content/gdrive/My Drive/colab/weights/svhn_SVHN_ResNet20v1_shared_model.090.h5\n","Epoch 91/200\n","Learning rate:  0.0001\n"," - 293s - loss: 3.2149 - pred_layer_2_loss: 0.1470 - pred_layer_0_loss: 0.4813 - pred_layer_1_loss: 0.1799 - pred_layer_2_acc: 0.9576 - pred_layer_0_acc: 0.7802 - pred_layer_0_acc_1: 0.8318 - pred_layer_0_acc_2: 0.8497 - pred_layer_1_acc: 0.9015 - pred_layer_1_acc_1: 0.9337 - pred_layer_1_acc_2: 0.9487 - pred_layer_2_acc_1: 0.9572 - pred_layer_2_acc_2: 0.9576 - val_loss: 2.9694 - val_pred_layer_2_loss: 0.1762 - val_pred_layer_0_loss: 0.4041 - val_pred_layer_1_loss: 0.1858 - val_pred_layer_2_acc: 0.9519 - val_pred_layer_0_acc: 0.8192 - val_pred_layer_0_acc_1: 0.8619 - val_pred_layer_0_acc_2: 0.8780 - val_pred_layer_1_acc: 0.9219 - val_pred_layer_1_acc_1: 0.9434 - val_pred_layer_1_acc_2: 0.9499 - val_pred_layer_2_acc_1: 0.9519 - val_pred_layer_2_acc_2: 0.9519\n","\n","Epoch 00091: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 92/200\n","Learning rate:  0.0001\n"," - 291s - loss: 3.2009 - pred_layer_2_loss: 0.1456 - pred_layer_0_loss: 0.4822 - pred_layer_1_loss: 0.1784 - pred_layer_2_acc: 0.9580 - pred_layer_0_acc: 0.7818 - pred_layer_0_acc_1: 0.8323 - pred_layer_0_acc_2: 0.8498 - pred_layer_1_acc: 0.9040 - pred_layer_1_acc_1: 0.9349 - pred_layer_1_acc_2: 0.9495 - pred_layer_2_acc_1: 0.9572 - pred_layer_2_acc_2: 0.9580 - val_loss: 2.9676 - val_pred_layer_2_loss: 0.1760 - val_pred_layer_0_loss: 0.4039 - val_pred_layer_1_loss: 0.1839 - val_pred_layer_2_acc: 0.9523 - val_pred_layer_0_acc: 0.8202 - val_pred_layer_0_acc_1: 0.8626 - val_pred_layer_0_acc_2: 0.8776 - val_pred_layer_1_acc: 0.9206 - val_pred_layer_1_acc_1: 0.9431 - val_pred_layer_1_acc_2: 0.9508 - val_pred_layer_2_acc_1: 0.9518 - val_pred_layer_2_acc_2: 0.9521\n","\n","Epoch 00092: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 93/200\n","Learning rate:  0.0001\n"," - 293s - loss: 3.1971 - pred_layer_2_loss: 0.1452 - pred_layer_0_loss: 0.4822 - pred_layer_1_loss: 0.1776 - pred_layer_2_acc: 0.9587 - pred_layer_0_acc: 0.7819 - pred_layer_0_acc_1: 0.8329 - pred_layer_0_acc_2: 0.8503 - pred_layer_1_acc: 0.9017 - pred_layer_1_acc_1: 0.9353 - pred_layer_1_acc_2: 0.9493 - pred_layer_2_acc_1: 0.9579 - pred_layer_2_acc_2: 0.9586 - val_loss: 2.9580 - val_pred_layer_2_loss: 0.1747 - val_pred_layer_0_loss: 0.4013 - val_pred_layer_1_loss: 0.1850 - val_pred_layer_2_acc: 0.9525 - val_pred_layer_0_acc: 0.8207 - val_pred_layer_0_acc_1: 0.8627 - val_pred_layer_0_acc_2: 0.8784 - val_pred_layer_1_acc: 0.9216 - val_pred_layer_1_acc_1: 0.9437 - val_pred_layer_1_acc_2: 0.9503 - val_pred_layer_2_acc_1: 0.9521 - val_pred_layer_2_acc_2: 0.9527\n","\n","Epoch 00093: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 94/200\n","Learning rate:  0.0001\n"," - 291s - loss: 3.1978 - pred_layer_2_loss: 0.1446 - pred_layer_0_loss: 0.4821 - pred_layer_1_loss: 0.1763 - pred_layer_2_acc: 0.9582 - pred_layer_0_acc: 0.7794 - pred_layer_0_acc_1: 0.8318 - pred_layer_0_acc_2: 0.8504 - pred_layer_1_acc: 0.9021 - pred_layer_1_acc_1: 0.9339 - pred_layer_1_acc_2: 0.9496 - pred_layer_2_acc_1: 0.9578 - pred_layer_2_acc_2: 0.9582 - val_loss: 2.9695 - val_pred_layer_2_loss: 0.1736 - val_pred_layer_0_loss: 0.4038 - val_pred_layer_1_loss: 0.1843 - val_pred_layer_2_acc: 0.9531 - val_pred_layer_0_acc: 0.8182 - val_pred_layer_0_acc_1: 0.8620 - val_pred_layer_0_acc_2: 0.8792 - val_pred_layer_1_acc: 0.9211 - val_pred_layer_1_acc_1: 0.9433 - val_pred_layer_1_acc_2: 0.9505 - val_pred_layer_2_acc_1: 0.9520 - val_pred_layer_2_acc_2: 0.9529\n","\n","Epoch 00094: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 95/200\n","Learning rate:  0.0001\n"," - 290s - loss: 3.1873 - pred_layer_2_loss: 0.1433 - pred_layer_0_loss: 0.4806 - pred_layer_1_loss: 0.1768 - pred_layer_2_acc: 0.9585 - pred_layer_0_acc: 0.7810 - pred_layer_0_acc_1: 0.8330 - pred_layer_0_acc_2: 0.8513 - pred_layer_1_acc: 0.9028 - pred_layer_1_acc_1: 0.9347 - pred_layer_1_acc_2: 0.9497 - pred_layer_2_acc_1: 0.9580 - pred_layer_2_acc_2: 0.9585 - val_loss: 2.9877 - val_pred_layer_2_loss: 0.1774 - val_pred_layer_0_loss: 0.4068 - val_pred_layer_1_loss: 0.1872 - val_pred_layer_2_acc: 0.9525 - val_pred_layer_0_acc: 0.8190 - val_pred_layer_0_acc_1: 0.8606 - val_pred_layer_0_acc_2: 0.8762 - val_pred_layer_1_acc: 0.9193 - val_pred_layer_1_acc_1: 0.9430 - val_pred_layer_1_acc_2: 0.9498 - val_pred_layer_2_acc_1: 0.9517 - val_pred_layer_2_acc_2: 0.9523\n","\n","Epoch 00095: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 96/200\n","Learning rate:  0.0001\n"," - 294s - loss: 3.1785 - pred_layer_2_loss: 0.1426 - pred_layer_0_loss: 0.4794 - pred_layer_1_loss: 0.1769 - pred_layer_2_acc: 0.9596 - pred_layer_0_acc: 0.7829 - pred_layer_0_acc_1: 0.8351 - pred_layer_0_acc_2: 0.8525 - pred_layer_1_acc: 0.9011 - pred_layer_1_acc_1: 0.9348 - pred_layer_1_acc_2: 0.9497 - pred_layer_2_acc_1: 0.9590 - pred_layer_2_acc_2: 0.9595 - val_loss: 2.9763 - val_pred_layer_2_loss: 0.1773 - val_pred_layer_0_loss: 0.4053 - val_pred_layer_1_loss: 0.1865 - val_pred_layer_2_acc: 0.9516 - val_pred_layer_0_acc: 0.8191 - val_pred_layer_0_acc_1: 0.8611 - val_pred_layer_0_acc_2: 0.8773 - val_pred_layer_1_acc: 0.9194 - val_pred_layer_1_acc_1: 0.9426 - val_pred_layer_1_acc_2: 0.9490 - val_pred_layer_2_acc_1: 0.9509 - val_pred_layer_2_acc_2: 0.9513\n","\n","Epoch 00096: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 97/200\n","Learning rate:  0.0001\n"," - 296s - loss: 3.1844 - pred_layer_2_loss: 0.1422 - pred_layer_0_loss: 0.4828 - pred_layer_1_loss: 0.1756 - pred_layer_2_acc: 0.9590 - pred_layer_0_acc: 0.7803 - pred_layer_0_acc_1: 0.8328 - pred_layer_0_acc_2: 0.8502 - pred_layer_1_acc: 0.9026 - pred_layer_1_acc_1: 0.9347 - pred_layer_1_acc_2: 0.9493 - pred_layer_2_acc_1: 0.9583 - pred_layer_2_acc_2: 0.9589 - val_loss: 2.9751 - val_pred_layer_2_loss: 0.1802 - val_pred_layer_0_loss: 0.4030 - val_pred_layer_1_loss: 0.1887 - val_pred_layer_2_acc: 0.9508 - val_pred_layer_0_acc: 0.8216 - val_pred_layer_0_acc_1: 0.8620 - val_pred_layer_0_acc_2: 0.8776 - val_pred_layer_1_acc: 0.9198 - val_pred_layer_1_acc_1: 0.9435 - val_pred_layer_1_acc_2: 0.9488 - val_pred_layer_2_acc_1: 0.9508 - val_pred_layer_2_acc_2: 0.9508\n","\n","Epoch 00097: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 98/200\n","Learning rate:  0.0001\n"," - 295s - loss: 3.1719 - pred_layer_2_loss: 0.1407 - pred_layer_0_loss: 0.4820 - pred_layer_1_loss: 0.1746 - pred_layer_2_acc: 0.9596 - pred_layer_0_acc: 0.7826 - pred_layer_0_acc_1: 0.8336 - pred_layer_0_acc_2: 0.8513 - pred_layer_1_acc: 0.9019 - pred_layer_1_acc_1: 0.9349 - pred_layer_1_acc_2: 0.9500 - pred_layer_2_acc_1: 0.9588 - pred_layer_2_acc_2: 0.9597 - val_loss: 2.9711 - val_pred_layer_2_loss: 0.1774 - val_pred_layer_0_loss: 0.4039 - val_pred_layer_1_loss: 0.1855 - val_pred_layer_2_acc: 0.9515 - val_pred_layer_0_acc: 0.8209 - val_pred_layer_0_acc_1: 0.8612 - val_pred_layer_0_acc_2: 0.8790 - val_pred_layer_1_acc: 0.9199 - val_pred_layer_1_acc_1: 0.9430 - val_pred_layer_1_acc_2: 0.9500 - val_pred_layer_2_acc_1: 0.9506 - val_pred_layer_2_acc_2: 0.9513\n","\n","Epoch 00098: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 99/200\n","Learning rate:  0.0001\n"," - 295s - loss: 3.1528 - pred_layer_2_loss: 0.1409 - pred_layer_0_loss: 0.4782 - pred_layer_1_loss: 0.1734 - pred_layer_2_acc: 0.9591 - pred_layer_0_acc: 0.7809 - pred_layer_0_acc_1: 0.8331 - pred_layer_0_acc_2: 0.8520 - pred_layer_1_acc: 0.9025 - pred_layer_1_acc_1: 0.9357 - pred_layer_1_acc_2: 0.9499 - pred_layer_2_acc_1: 0.9586 - pred_layer_2_acc_2: 0.9593 - val_loss: 2.9648 - val_pred_layer_2_loss: 0.1797 - val_pred_layer_0_loss: 0.4012 - val_pred_layer_1_loss: 0.1866 - val_pred_layer_2_acc: 0.9509 - val_pred_layer_0_acc: 0.8215 - val_pred_layer_0_acc_1: 0.8629 - val_pred_layer_0_acc_2: 0.8783 - val_pred_layer_1_acc: 0.9198 - val_pred_layer_1_acc_1: 0.9430 - val_pred_layer_1_acc_2: 0.9495 - val_pred_layer_2_acc_1: 0.9506 - val_pred_layer_2_acc_2: 0.9512\n","\n","Epoch 00099: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 100/200\n","Learning rate:  0.0001\n"," - 296s - loss: 3.1665 - pred_layer_2_loss: 0.1399 - pred_layer_0_loss: 0.4815 - pred_layer_1_loss: 0.1749 - pred_layer_2_acc: 0.9599 - pred_layer_0_acc: 0.7816 - pred_layer_0_acc_1: 0.8329 - pred_layer_0_acc_2: 0.8506 - pred_layer_1_acc: 0.9019 - pred_layer_1_acc_1: 0.9360 - pred_layer_1_acc_2: 0.9502 - pred_layer_2_acc_1: 0.9594 - pred_layer_2_acc_2: 0.9596 - val_loss: 2.9761 - val_pred_layer_2_loss: 0.1794 - val_pred_layer_0_loss: 0.4070 - val_pred_layer_1_loss: 0.1858 - val_pred_layer_2_acc: 0.9521 - val_pred_layer_0_acc: 0.8207 - val_pred_layer_0_acc_1: 0.8606 - val_pred_layer_0_acc_2: 0.8776 - val_pred_layer_1_acc: 0.9202 - val_pred_layer_1_acc_1: 0.9428 - val_pred_layer_1_acc_2: 0.9493 - val_pred_layer_2_acc_1: 0.9511 - val_pred_layer_2_acc_2: 0.9521\n","\n","Epoch 00100: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 101/200\n","Learning rate:  0.0001\n"," - 296s - loss: 3.1617 - pred_layer_2_loss: 0.1392 - pred_layer_0_loss: 0.4817 - pred_layer_1_loss: 0.1742 - pred_layer_2_acc: 0.9601 - pred_layer_0_acc: 0.7824 - pred_layer_0_acc_1: 0.8350 - pred_layer_0_acc_2: 0.8517 - pred_layer_1_acc: 0.9026 - pred_layer_1_acc_1: 0.9360 - pred_layer_1_acc_2: 0.9499 - pred_layer_2_acc_1: 0.9597 - pred_layer_2_acc_2: 0.9600 - val_loss: 2.9740 - val_pred_layer_2_loss: 0.1822 - val_pred_layer_0_loss: 0.4020 - val_pred_layer_1_loss: 0.1889 - val_pred_layer_2_acc: 0.9512 - val_pred_layer_0_acc: 0.8216 - val_pred_layer_0_acc_1: 0.8627 - val_pred_layer_0_acc_2: 0.8780 - val_pred_layer_1_acc: 0.9208 - val_pred_layer_1_acc_1: 0.9428 - val_pred_layer_1_acc_2: 0.9484 - val_pred_layer_2_acc_1: 0.9508 - val_pred_layer_2_acc_2: 0.9507\n","\n","Epoch 00101: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 102/200\n","Learning rate:  0.0001\n"," - 294s - loss: 3.1661 - pred_layer_2_loss: 0.1402 - pred_layer_0_loss: 0.4822 - pred_layer_1_loss: 0.1753 - pred_layer_2_acc: 0.9597 - pred_layer_0_acc: 0.7814 - pred_layer_0_acc_1: 0.8353 - pred_layer_0_acc_2: 0.8514 - pred_layer_1_acc: 0.9021 - pred_layer_1_acc_1: 0.9353 - pred_layer_1_acc_2: 0.9501 - pred_layer_2_acc_1: 0.9587 - pred_layer_2_acc_2: 0.9594 - val_loss: 2.9717 - val_pred_layer_2_loss: 0.1791 - val_pred_layer_0_loss: 0.4041 - val_pred_layer_1_loss: 0.1879 - val_pred_layer_2_acc: 0.9512 - val_pred_layer_0_acc: 0.8196 - val_pred_layer_0_acc_1: 0.8606 - val_pred_layer_0_acc_2: 0.8758 - val_pred_layer_1_acc: 0.9189 - val_pred_layer_1_acc_1: 0.9420 - val_pred_layer_1_acc_2: 0.9489 - val_pred_layer_2_acc_1: 0.9505 - val_pred_layer_2_acc_2: 0.9510\n","\n","Epoch 00102: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 103/200\n","Learning rate:  0.0001\n"," - 290s - loss: 3.1592 - pred_layer_2_loss: 0.1385 - pred_layer_0_loss: 0.4824 - pred_layer_1_loss: 0.1750 - pred_layer_2_acc: 0.9599 - pred_layer_0_acc: 0.7828 - pred_layer_0_acc_1: 0.8316 - pred_layer_0_acc_2: 0.8504 - pred_layer_1_acc: 0.9024 - pred_layer_1_acc_1: 0.9355 - pred_layer_1_acc_2: 0.9498 - pred_layer_2_acc_1: 0.9589 - pred_layer_2_acc_2: 0.9600 - val_loss: 2.9599 - val_pred_layer_2_loss: 0.1787 - val_pred_layer_0_loss: 0.4031 - val_pred_layer_1_loss: 0.1850 - val_pred_layer_2_acc: 0.9526 - val_pred_layer_0_acc: 0.8207 - val_pred_layer_0_acc_1: 0.8611 - val_pred_layer_0_acc_2: 0.8768 - val_pred_layer_1_acc: 0.9211 - val_pred_layer_1_acc_1: 0.9433 - val_pred_layer_1_acc_2: 0.9501 - val_pred_layer_2_acc_1: 0.9516 - val_pred_layer_2_acc_2: 0.9522\n","\n","Epoch 00103: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 104/200\n","Learning rate:  0.0001\n"," - 294s - loss: 3.1419 - pred_layer_2_loss: 0.1372 - pred_layer_0_loss: 0.4790 - pred_layer_1_loss: 0.1731 - pred_layer_2_acc: 0.9602 - pred_layer_0_acc: 0.7831 - pred_layer_0_acc_1: 0.8359 - pred_layer_0_acc_2: 0.8509 - pred_layer_1_acc: 0.9027 - pred_layer_1_acc_1: 0.9358 - pred_layer_1_acc_2: 0.9506 - pred_layer_2_acc_1: 0.9597 - pred_layer_2_acc_2: 0.9602 - val_loss: 2.9376 - val_pred_layer_2_loss: 0.1766 - val_pred_layer_0_loss: 0.4022 - val_pred_layer_1_loss: 0.1828 - val_pred_layer_2_acc: 0.9530 - val_pred_layer_0_acc: 0.8244 - val_pred_layer_0_acc_1: 0.8630 - val_pred_layer_0_acc_2: 0.8770 - val_pred_layer_1_acc: 0.9215 - val_pred_layer_1_acc_1: 0.9431 - val_pred_layer_1_acc_2: 0.9505 - val_pred_layer_2_acc_1: 0.9521 - val_pred_layer_2_acc_2: 0.9531\n","\n","Epoch 00104: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 105/200\n","Learning rate:  0.0001\n"," - 294s - loss: 3.1288 - pred_layer_2_loss: 0.1362 - pred_layer_0_loss: 0.4783 - pred_layer_1_loss: 0.1701 - pred_layer_2_acc: 0.9607 - pred_layer_0_acc: 0.7821 - pred_layer_0_acc_1: 0.8355 - pred_layer_0_acc_2: 0.8517 - pred_layer_1_acc: 0.9031 - pred_layer_1_acc_1: 0.9365 - pred_layer_1_acc_2: 0.9519 - pred_layer_2_acc_1: 0.9601 - pred_layer_2_acc_2: 0.9607 - val_loss: 2.9608 - val_pred_layer_2_loss: 0.1760 - val_pred_layer_0_loss: 0.4066 - val_pred_layer_1_loss: 0.1851 - val_pred_layer_2_acc: 0.9519 - val_pred_layer_0_acc: 0.8203 - val_pred_layer_0_acc_1: 0.8617 - val_pred_layer_0_acc_2: 0.8762 - val_pred_layer_1_acc: 0.9186 - val_pred_layer_1_acc_1: 0.9426 - val_pred_layer_1_acc_2: 0.9499 - val_pred_layer_2_acc_1: 0.9515 - val_pred_layer_2_acc_2: 0.9520\n","\n","Epoch 00105: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 106/200\n","Learning rate:  0.0001\n"," - 295s - loss: 3.1291 - pred_layer_2_loss: 0.1359 - pred_layer_0_loss: 0.4795 - pred_layer_1_loss: 0.1715 - pred_layer_2_acc: 0.9607 - pred_layer_0_acc: 0.7826 - pred_layer_0_acc_1: 0.8339 - pred_layer_0_acc_2: 0.8517 - pred_layer_1_acc: 0.9038 - pred_layer_1_acc_1: 0.9371 - pred_layer_1_acc_2: 0.9517 - pred_layer_2_acc_1: 0.9599 - pred_layer_2_acc_2: 0.9606 - val_loss: 2.9478 - val_pred_layer_2_loss: 0.1786 - val_pred_layer_0_loss: 0.4004 - val_pred_layer_1_loss: 0.1847 - val_pred_layer_2_acc: 0.9515 - val_pred_layer_0_acc: 0.8215 - val_pred_layer_0_acc_1: 0.8641 - val_pred_layer_0_acc_2: 0.8791 - val_pred_layer_1_acc: 0.9196 - val_pred_layer_1_acc_1: 0.9433 - val_pred_layer_1_acc_2: 0.9496 - val_pred_layer_2_acc_1: 0.9511 - val_pred_layer_2_acc_2: 0.9515\n","\n","Epoch 00106: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 107/200\n","Learning rate:  0.0001\n"," - 295s - loss: 3.1118 - pred_layer_2_loss: 0.1344 - pred_layer_0_loss: 0.4762 - pred_layer_1_loss: 0.1713 - pred_layer_2_acc: 0.9608 - pred_layer_0_acc: 0.7851 - pred_layer_0_acc_1: 0.8353 - pred_layer_0_acc_2: 0.8527 - pred_layer_1_acc: 0.9030 - pred_layer_1_acc_1: 0.9364 - pred_layer_1_acc_2: 0.9512 - pred_layer_2_acc_1: 0.9604 - pred_layer_2_acc_2: 0.9607 - val_loss: 2.9703 - val_pred_layer_2_loss: 0.1827 - val_pred_layer_0_loss: 0.4010 - val_pred_layer_1_loss: 0.1874 - val_pred_layer_2_acc: 0.9502 - val_pred_layer_0_acc: 0.8228 - val_pred_layer_0_acc_1: 0.8622 - val_pred_layer_0_acc_2: 0.8794 - val_pred_layer_1_acc: 0.9191 - val_pred_layer_1_acc_1: 0.9426 - val_pred_layer_1_acc_2: 0.9489 - val_pred_layer_2_acc_1: 0.9498 - val_pred_layer_2_acc_2: 0.9504\n","\n","Epoch 00107: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 108/200\n","Learning rate:  0.0001\n"," - 294s - loss: 3.1339 - pred_layer_2_loss: 0.1362 - pred_layer_0_loss: 0.4794 - pred_layer_1_loss: 0.1722 - pred_layer_2_acc: 0.9606 - pred_layer_0_acc: 0.7824 - pred_layer_0_acc_1: 0.8339 - pred_layer_0_acc_2: 0.8523 - pred_layer_1_acc: 0.9026 - pred_layer_1_acc_1: 0.9360 - pred_layer_1_acc_2: 0.9508 - pred_layer_2_acc_1: 0.9604 - pred_layer_2_acc_2: 0.9607 - val_loss: 2.9487 - val_pred_layer_2_loss: 0.1781 - val_pred_layer_0_loss: 0.4014 - val_pred_layer_1_loss: 0.1855 - val_pred_layer_2_acc: 0.9519 - val_pred_layer_0_acc: 0.8198 - val_pred_layer_0_acc_1: 0.8621 - val_pred_layer_0_acc_2: 0.8786 - val_pred_layer_1_acc: 0.9205 - val_pred_layer_1_acc_1: 0.9433 - val_pred_layer_1_acc_2: 0.9490 - val_pred_layer_2_acc_1: 0.9509 - val_pred_layer_2_acc_2: 0.9519\n","\n","Epoch 00108: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 109/200\n","Learning rate:  0.0001\n"," - 295s - loss: 3.1356 - pred_layer_2_loss: 0.1349 - pred_layer_0_loss: 0.4835 - pred_layer_1_loss: 0.1710 - pred_layer_2_acc: 0.9611 - pred_layer_0_acc: 0.7818 - pred_layer_0_acc_1: 0.8338 - pred_layer_0_acc_2: 0.8517 - pred_layer_1_acc: 0.9026 - pred_layer_1_acc_1: 0.9359 - pred_layer_1_acc_2: 0.9516 - pred_layer_2_acc_1: 0.9602 - pred_layer_2_acc_2: 0.9611 - val_loss: 2.9509 - val_pred_layer_2_loss: 0.1799 - val_pred_layer_0_loss: 0.4024 - val_pred_layer_1_loss: 0.1855 - val_pred_layer_2_acc: 0.9508 - val_pred_layer_0_acc: 0.8209 - val_pred_layer_0_acc_1: 0.8625 - val_pred_layer_0_acc_2: 0.8758 - val_pred_layer_1_acc: 0.9194 - val_pred_layer_1_acc_1: 0.9428 - val_pred_layer_1_acc_2: 0.9500 - val_pred_layer_2_acc_1: 0.9499 - val_pred_layer_2_acc_2: 0.9506\n","\n","Epoch 00109: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 110/200\n","Learning rate:  0.0001\n"," - 295s - loss: 3.1157 - pred_layer_2_loss: 0.1345 - pred_layer_0_loss: 0.4782 - pred_layer_1_loss: 0.1700 - pred_layer_2_acc: 0.9612 - pred_layer_0_acc: 0.7835 - pred_layer_0_acc_1: 0.8353 - pred_layer_0_acc_2: 0.8518 - pred_layer_1_acc: 0.9036 - pred_layer_1_acc_1: 0.9363 - pred_layer_1_acc_2: 0.9521 - pred_layer_2_acc_1: 0.9608 - pred_layer_2_acc_2: 0.9611 - val_loss: 2.9758 - val_pred_layer_2_loss: 0.1838 - val_pred_layer_0_loss: 0.4032 - val_pred_layer_1_loss: 0.1896 - val_pred_layer_2_acc: 0.9493 - val_pred_layer_0_acc: 0.8201 - val_pred_layer_0_acc_1: 0.8619 - val_pred_layer_0_acc_2: 0.8774 - val_pred_layer_1_acc: 0.9203 - val_pred_layer_1_acc_1: 0.9423 - val_pred_layer_1_acc_2: 0.9477 - val_pred_layer_2_acc_1: 0.9496 - val_pred_layer_2_acc_2: 0.9495\n","\n","Epoch 00110: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 111/200\n","Learning rate:  0.0001\n"," - 293s - loss: 3.0971 - pred_layer_2_loss: 0.1328 - pred_layer_0_loss: 0.4765 - pred_layer_1_loss: 0.1681 - pred_layer_2_acc: 0.9619 - pred_layer_0_acc: 0.7836 - pred_layer_0_acc_1: 0.8349 - pred_layer_0_acc_2: 0.8533 - pred_layer_1_acc: 0.9035 - pred_layer_1_acc_1: 0.9361 - pred_layer_1_acc_2: 0.9520 - pred_layer_2_acc_1: 0.9611 - pred_layer_2_acc_2: 0.9619 - val_loss: 2.9402 - val_pred_layer_2_loss: 0.1785 - val_pred_layer_0_loss: 0.4007 - val_pred_layer_1_loss: 0.1843 - val_pred_layer_2_acc: 0.9519 - val_pred_layer_0_acc: 0.8215 - val_pred_layer_0_acc_1: 0.8620 - val_pred_layer_0_acc_2: 0.8785 - val_pred_layer_1_acc: 0.9215 - val_pred_layer_1_acc_1: 0.9430 - val_pred_layer_1_acc_2: 0.9488 - val_pred_layer_2_acc_1: 0.9506 - val_pred_layer_2_acc_2: 0.9521\n","\n","Epoch 00111: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 112/200\n","Learning rate:  0.0001\n"," - 293s - loss: 3.1088 - pred_layer_2_loss: 0.1329 - pred_layer_0_loss: 0.4771 - pred_layer_1_loss: 0.1693 - pred_layer_2_acc: 0.9612 - pred_layer_0_acc: 0.7820 - pred_layer_0_acc_1: 0.8342 - pred_layer_0_acc_2: 0.8522 - pred_layer_1_acc: 0.9032 - pred_layer_1_acc_1: 0.9356 - pred_layer_1_acc_2: 0.9517 - pred_layer_2_acc_1: 0.9603 - pred_layer_2_acc_2: 0.9611 - val_loss: 2.9554 - val_pred_layer_2_loss: 0.1833 - val_pred_layer_0_loss: 0.3999 - val_pred_layer_1_loss: 0.1875 - val_pred_layer_2_acc: 0.9498 - val_pred_layer_0_acc: 0.8221 - val_pred_layer_0_acc_1: 0.8636 - val_pred_layer_0_acc_2: 0.8798 - val_pred_layer_1_acc: 0.9209 - val_pred_layer_1_acc_1: 0.9429 - val_pred_layer_1_acc_2: 0.9493 - val_pred_layer_2_acc_1: 0.9495 - val_pred_layer_2_acc_2: 0.9501\n","\n","Epoch 00112: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 113/200\n","Learning rate:  0.0001\n"," - 295s - loss: 3.0852 - pred_layer_2_loss: 0.1309 - pred_layer_0_loss: 0.4736 - pred_layer_1_loss: 0.1674 - pred_layer_2_acc: 0.9618 - pred_layer_0_acc: 0.7833 - pred_layer_0_acc_1: 0.8351 - pred_layer_0_acc_2: 0.8533 - pred_layer_1_acc: 0.9041 - pred_layer_1_acc_1: 0.9365 - pred_layer_1_acc_2: 0.9520 - pred_layer_2_acc_1: 0.9614 - pred_layer_2_acc_2: 0.9620 - val_loss: 2.9556 - val_pred_layer_2_loss: 0.1841 - val_pred_layer_0_loss: 0.3987 - val_pred_layer_1_loss: 0.1896 - val_pred_layer_2_acc: 0.9509 - val_pred_layer_0_acc: 0.8219 - val_pred_layer_0_acc_1: 0.8634 - val_pred_layer_0_acc_2: 0.8796 - val_pred_layer_1_acc: 0.9208 - val_pred_layer_1_acc_1: 0.9431 - val_pred_layer_1_acc_2: 0.9481 - val_pred_layer_2_acc_1: 0.9504 - val_pred_layer_2_acc_2: 0.9513\n","\n","Epoch 00113: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 114/200\n","Learning rate:  0.0001\n"," - 295s - loss: 3.1085 - pred_layer_2_loss: 0.1316 - pred_layer_0_loss: 0.4793 - pred_layer_1_loss: 0.1700 - pred_layer_2_acc: 0.9619 - pred_layer_0_acc: 0.7827 - pred_layer_0_acc_1: 0.8346 - pred_layer_0_acc_2: 0.8512 - pred_layer_1_acc: 0.9029 - pred_layer_1_acc_1: 0.9358 - pred_layer_1_acc_2: 0.9516 - pred_layer_2_acc_1: 0.9608 - pred_layer_2_acc_2: 0.9618 - val_loss: 2.9653 - val_pred_layer_2_loss: 0.1846 - val_pred_layer_0_loss: 0.4027 - val_pred_layer_1_loss: 0.1873 - val_pred_layer_2_acc: 0.9506 - val_pred_layer_0_acc: 0.8217 - val_pred_layer_0_acc_1: 0.8615 - val_pred_layer_0_acc_2: 0.8778 - val_pred_layer_1_acc: 0.9213 - val_pred_layer_1_acc_1: 0.9425 - val_pred_layer_1_acc_2: 0.9490 - val_pred_layer_2_acc_1: 0.9505 - val_pred_layer_2_acc_2: 0.9506\n","\n","Epoch 00114: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 115/200\n","Learning rate:  0.0001\n"," - 295s - loss: 3.0933 - pred_layer_2_loss: 0.1324 - pred_layer_0_loss: 0.4770 - pred_layer_1_loss: 0.1676 - pred_layer_2_acc: 0.9614 - pred_layer_0_acc: 0.7829 - pred_layer_0_acc_1: 0.8351 - pred_layer_0_acc_2: 0.8536 - pred_layer_1_acc: 0.9038 - pred_layer_1_acc_1: 0.9357 - pred_layer_1_acc_2: 0.9520 - pred_layer_2_acc_1: 0.9607 - pred_layer_2_acc_2: 0.9615 - val_loss: 2.9169 - val_pred_layer_2_loss: 0.1786 - val_pred_layer_0_loss: 0.3943 - val_pred_layer_1_loss: 0.1843 - val_pred_layer_2_acc: 0.9514 - val_pred_layer_0_acc: 0.8238 - val_pred_layer_0_acc_1: 0.8655 - val_pred_layer_0_acc_2: 0.8791 - val_pred_layer_1_acc: 0.9210 - val_pred_layer_1_acc_1: 0.9431 - val_pred_layer_1_acc_2: 0.9505 - val_pred_layer_2_acc_1: 0.9508 - val_pred_layer_2_acc_2: 0.9515\n","\n","Epoch 00115: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 116/200\n","Learning rate:  0.0001\n"," - 294s - loss: 3.0996 - pred_layer_2_loss: 0.1307 - pred_layer_0_loss: 0.4790 - pred_layer_1_loss: 0.1683 - pred_layer_2_acc: 0.9625 - pred_layer_0_acc: 0.7825 - pred_layer_0_acc_1: 0.8336 - pred_layer_0_acc_2: 0.8526 - pred_layer_1_acc: 0.9032 - pred_layer_1_acc_1: 0.9368 - pred_layer_1_acc_2: 0.9524 - pred_layer_2_acc_1: 0.9619 - pred_layer_2_acc_2: 0.9626 - val_loss: 2.9549 - val_pred_layer_2_loss: 0.1788 - val_pred_layer_0_loss: 0.4040 - val_pred_layer_1_loss: 0.1877 - val_pred_layer_2_acc: 0.9517 - val_pred_layer_0_acc: 0.8210 - val_pred_layer_0_acc_1: 0.8624 - val_pred_layer_0_acc_2: 0.8781 - val_pred_layer_1_acc: 0.9197 - val_pred_layer_1_acc_1: 0.9426 - val_pred_layer_1_acc_2: 0.9486 - val_pred_layer_2_acc_1: 0.9508 - val_pred_layer_2_acc_2: 0.9514\n","\n","Epoch 00116: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 117/200\n","Learning rate:  0.0001\n"," - 299s - loss: 3.1076 - pred_layer_2_loss: 0.1328 - pred_layer_0_loss: 0.4805 - pred_layer_1_loss: 0.1699 - pred_layer_2_acc: 0.9618 - pred_layer_0_acc: 0.7818 - pred_layer_0_acc_1: 0.8347 - pred_layer_0_acc_2: 0.8524 - pred_layer_1_acc: 0.9034 - pred_layer_1_acc_1: 0.9361 - pred_layer_1_acc_2: 0.9521 - pred_layer_2_acc_1: 0.9608 - pred_layer_2_acc_2: 0.9617 - val_loss: 2.9159 - val_pred_layer_2_loss: 0.1775 - val_pred_layer_0_loss: 0.3960 - val_pred_layer_1_loss: 0.1832 - val_pred_layer_2_acc: 0.9522 - val_pred_layer_0_acc: 0.8231 - val_pred_layer_0_acc_1: 0.8641 - val_pred_layer_0_acc_2: 0.8799 - val_pred_layer_1_acc: 0.9218 - val_pred_layer_1_acc_1: 0.9435 - val_pred_layer_1_acc_2: 0.9506 - val_pred_layer_2_acc_1: 0.9522 - val_pred_layer_2_acc_2: 0.9525\n","\n","Epoch 00117: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 118/200\n","Learning rate:  0.0001\n"," - 299s - loss: 3.0826 - pred_layer_2_loss: 0.1291 - pred_layer_0_loss: 0.4761 - pred_layer_1_loss: 0.1674 - pred_layer_2_acc: 0.9625 - pred_layer_0_acc: 0.7836 - pred_layer_0_acc_1: 0.8341 - pred_layer_0_acc_2: 0.8520 - pred_layer_1_acc: 0.9021 - pred_layer_1_acc_1: 0.9366 - pred_layer_1_acc_2: 0.9520 - pred_layer_2_acc_1: 0.9615 - pred_layer_2_acc_2: 0.9624 - val_loss: 2.9368 - val_pred_layer_2_loss: 0.1810 - val_pred_layer_0_loss: 0.3982 - val_pred_layer_1_loss: 0.1874 - val_pred_layer_2_acc: 0.9508 - val_pred_layer_0_acc: 0.8236 - val_pred_layer_0_acc_1: 0.8628 - val_pred_layer_0_acc_2: 0.8791 - val_pred_layer_1_acc: 0.9195 - val_pred_layer_1_acc_1: 0.9434 - val_pred_layer_1_acc_2: 0.9493 - val_pred_layer_2_acc_1: 0.9501 - val_pred_layer_2_acc_2: 0.9507\n","\n","Epoch 00118: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 119/200\n","Learning rate:  0.0001\n"," - 297s - loss: 3.1013 - pred_layer_2_loss: 0.1316 - pred_layer_0_loss: 0.4801 - pred_layer_1_loss: 0.1690 - pred_layer_2_acc: 0.9615 - pred_layer_0_acc: 0.7824 - pred_layer_0_acc_1: 0.8344 - pred_layer_0_acc_2: 0.8524 - pred_layer_1_acc: 0.9043 - pred_layer_1_acc_1: 0.9367 - pred_layer_1_acc_2: 0.9521 - pred_layer_2_acc_1: 0.9611 - pred_layer_2_acc_2: 0.9617 - val_loss: 2.9320 - val_pred_layer_2_loss: 0.1783 - val_pred_layer_0_loss: 0.4023 - val_pred_layer_1_loss: 0.1842 - val_pred_layer_2_acc: 0.9519 - val_pred_layer_0_acc: 0.8208 - val_pred_layer_0_acc_1: 0.8623 - val_pred_layer_0_acc_2: 0.8775 - val_pred_layer_1_acc: 0.9214 - val_pred_layer_1_acc_1: 0.9434 - val_pred_layer_1_acc_2: 0.9499 - val_pred_layer_2_acc_1: 0.9517 - val_pred_layer_2_acc_2: 0.9518\n","\n","Epoch 00119: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 120/200\n","Learning rate:  0.0001\n"," - 298s - loss: 3.0793 - pred_layer_2_loss: 0.1296 - pred_layer_0_loss: 0.4742 - pred_layer_1_loss: 0.1674 - pred_layer_2_acc: 0.9625 - pred_layer_0_acc: 0.7846 - pred_layer_0_acc_1: 0.8354 - pred_layer_0_acc_2: 0.8529 - pred_layer_1_acc: 0.9043 - pred_layer_1_acc_1: 0.9362 - pred_layer_1_acc_2: 0.9526 - pred_layer_2_acc_1: 0.9620 - pred_layer_2_acc_2: 0.9625 - val_loss: 2.9426 - val_pred_layer_2_loss: 0.1835 - val_pred_layer_0_loss: 0.3980 - val_pred_layer_1_loss: 0.1892 - val_pred_layer_2_acc: 0.9496 - val_pred_layer_0_acc: 0.8221 - val_pred_layer_0_acc_1: 0.8642 - val_pred_layer_0_acc_2: 0.8798 - val_pred_layer_1_acc: 0.9211 - val_pred_layer_1_acc_1: 0.9424 - val_pred_layer_1_acc_2: 0.9493 - val_pred_layer_2_acc_1: 0.9491 - val_pred_layer_2_acc_2: 0.9498\n","\n","Epoch 00120: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 121/200\n","Learning rate:  0.0001\n"," - 299s - loss: 3.0756 - pred_layer_2_loss: 0.1283 - pred_layer_0_loss: 0.4760 - pred_layer_1_loss: 0.1672 - pred_layer_2_acc: 0.9627 - pred_layer_0_acc: 0.7846 - pred_layer_0_acc_1: 0.8349 - pred_layer_0_acc_2: 0.8532 - pred_layer_1_acc: 0.9035 - pred_layer_1_acc_1: 0.9367 - pred_layer_1_acc_2: 0.9521 - pred_layer_2_acc_1: 0.9616 - pred_layer_2_acc_2: 0.9628 - val_loss: 2.9499 - val_pred_layer_2_loss: 0.1839 - val_pred_layer_0_loss: 0.3983 - val_pred_layer_1_loss: 0.1894 - val_pred_layer_2_acc: 0.9502 - val_pred_layer_0_acc: 0.8218 - val_pred_layer_0_acc_1: 0.8641 - val_pred_layer_0_acc_2: 0.8791 - val_pred_layer_1_acc: 0.9198 - val_pred_layer_1_acc_1: 0.9429 - val_pred_layer_1_acc_2: 0.9479 - val_pred_layer_2_acc_1: 0.9494 - val_pred_layer_2_acc_2: 0.9504\n","\n","Epoch 00121: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 122/200\n","Learning rate:  1e-05\n"," - 295s - loss: 3.0600 - pred_layer_2_loss: 0.1233 - pred_layer_0_loss: 0.4776 - pred_layer_1_loss: 0.1639 - pred_layer_2_acc: 0.9642 - pred_layer_0_acc: 0.7826 - pred_layer_0_acc_1: 0.8349 - pred_layer_0_acc_2: 0.8521 - pred_layer_1_acc: 0.9035 - pred_layer_1_acc_1: 0.9375 - pred_layer_1_acc_2: 0.9541 - pred_layer_2_acc_1: 0.9641 - pred_layer_2_acc_2: 0.9643 - val_loss: 2.9276 - val_pred_layer_2_loss: 0.1790 - val_pred_layer_0_loss: 0.3992 - val_pred_layer_1_loss: 0.1856 - val_pred_layer_2_acc: 0.9518 - val_pred_layer_0_acc: 0.8226 - val_pred_layer_0_acc_1: 0.8638 - val_pred_layer_0_acc_2: 0.8783 - val_pred_layer_1_acc: 0.9213 - val_pred_layer_1_acc_1: 0.9434 - val_pred_layer_1_acc_2: 0.9501 - val_pred_layer_2_acc_1: 0.9515 - val_pred_layer_2_acc_2: 0.9517\n","\n","Epoch 00122: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 123/200\n","Learning rate:  1e-05\n"," - 297s - loss: 3.0474 - pred_layer_2_loss: 0.1230 - pred_layer_0_loss: 0.4737 - pred_layer_1_loss: 0.1634 - pred_layer_2_acc: 0.9638 - pred_layer_0_acc: 0.7826 - pred_layer_0_acc_1: 0.8360 - pred_layer_0_acc_2: 0.8532 - pred_layer_1_acc: 0.9037 - pred_layer_1_acc_1: 0.9367 - pred_layer_1_acc_2: 0.9533 - pred_layer_2_acc_1: 0.9628 - pred_layer_2_acc_2: 0.9637 - val_loss: 2.9194 - val_pred_layer_2_loss: 0.1785 - val_pred_layer_0_loss: 0.3985 - val_pred_layer_1_loss: 0.1848 - val_pred_layer_2_acc: 0.9518 - val_pred_layer_0_acc: 0.8234 - val_pred_layer_0_acc_1: 0.8641 - val_pred_layer_0_acc_2: 0.8786 - val_pred_layer_1_acc: 0.9213 - val_pred_layer_1_acc_1: 0.9438 - val_pred_layer_1_acc_2: 0.9505 - val_pred_layer_2_acc_1: 0.9510 - val_pred_layer_2_acc_2: 0.9521\n","\n","Epoch 00123: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 124/200\n","Learning rate:  1e-05\n"," - 296s - loss: 3.0454 - pred_layer_2_loss: 0.1211 - pred_layer_0_loss: 0.4755 - pred_layer_1_loss: 0.1636 - pred_layer_2_acc: 0.9645 - pred_layer_0_acc: 0.7841 - pred_layer_0_acc_1: 0.8372 - pred_layer_0_acc_2: 0.8531 - pred_layer_1_acc: 0.9029 - pred_layer_1_acc_1: 0.9377 - pred_layer_1_acc_2: 0.9531 - pred_layer_2_acc_1: 0.9637 - pred_layer_2_acc_2: 0.9645 - val_loss: 2.9162 - val_pred_layer_2_loss: 0.1779 - val_pred_layer_0_loss: 0.3980 - val_pred_layer_1_loss: 0.1844 - val_pred_layer_2_acc: 0.9519 - val_pred_layer_0_acc: 0.8233 - val_pred_layer_0_acc_1: 0.8643 - val_pred_layer_0_acc_2: 0.8782 - val_pred_layer_1_acc: 0.9214 - val_pred_layer_1_acc_1: 0.9438 - val_pred_layer_1_acc_2: 0.9506 - val_pred_layer_2_acc_1: 0.9516 - val_pred_layer_2_acc_2: 0.9520\n","\n","Epoch 00124: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 125/200\n","Learning rate:  1e-05\n"," - 294s - loss: 3.0307 - pred_layer_2_loss: 0.1206 - pred_layer_0_loss: 0.4733 - pred_layer_1_loss: 0.1616 - pred_layer_2_acc: 0.9659 - pred_layer_0_acc: 0.7842 - pred_layer_0_acc_1: 0.8352 - pred_layer_0_acc_2: 0.8525 - pred_layer_1_acc: 0.9041 - pred_layer_1_acc_1: 0.9376 - pred_layer_1_acc_2: 0.9544 - pred_layer_2_acc_1: 0.9650 - pred_layer_2_acc_2: 0.9658 - val_loss: 2.9161 - val_pred_layer_2_loss: 0.1784 - val_pred_layer_0_loss: 0.3974 - val_pred_layer_1_loss: 0.1844 - val_pred_layer_2_acc: 0.9522 - val_pred_layer_0_acc: 0.8237 - val_pred_layer_0_acc_1: 0.8646 - val_pred_layer_0_acc_2: 0.8793 - val_pred_layer_1_acc: 0.9212 - val_pred_layer_1_acc_1: 0.9437 - val_pred_layer_1_acc_2: 0.9503 - val_pred_layer_2_acc_1: 0.9510 - val_pred_layer_2_acc_2: 0.9519\n","\n","Epoch 00125: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 126/200\n","Learning rate:  1e-05\n"," - 293s - loss: 3.0287 - pred_layer_2_loss: 0.1210 - pred_layer_0_loss: 0.4744 - pred_layer_1_loss: 0.1610 - pred_layer_2_acc: 0.9644 - pred_layer_0_acc: 0.7841 - pred_layer_0_acc_1: 0.8352 - pred_layer_0_acc_2: 0.8526 - pred_layer_1_acc: 0.9037 - pred_layer_1_acc_1: 0.9390 - pred_layer_1_acc_2: 0.9538 - pred_layer_2_acc_1: 0.9642 - pred_layer_2_acc_2: 0.9645 - val_loss: 2.9176 - val_pred_layer_2_loss: 0.1782 - val_pred_layer_0_loss: 0.3979 - val_pred_layer_1_loss: 0.1843 - val_pred_layer_2_acc: 0.9520 - val_pred_layer_0_acc: 0.8238 - val_pred_layer_0_acc_1: 0.8638 - val_pred_layer_0_acc_2: 0.8791 - val_pred_layer_1_acc: 0.9207 - val_pred_layer_1_acc_1: 0.9441 - val_pred_layer_1_acc_2: 0.9505 - val_pred_layer_2_acc_1: 0.9519 - val_pred_layer_2_acc_2: 0.9522\n","\n","Epoch 00126: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 127/200\n","Learning rate:  1e-05\n"," - 294s - loss: 3.0176 - pred_layer_2_loss: 0.1197 - pred_layer_0_loss: 0.4706 - pred_layer_1_loss: 0.1604 - pred_layer_2_acc: 0.9648 - pred_layer_0_acc: 0.7841 - pred_layer_0_acc_1: 0.8371 - pred_layer_0_acc_2: 0.8540 - pred_layer_1_acc: 0.9044 - pred_layer_1_acc_1: 0.9383 - pred_layer_1_acc_2: 0.9543 - pred_layer_2_acc_1: 0.9639 - pred_layer_2_acc_2: 0.9648 - val_loss: 2.9102 - val_pred_layer_2_loss: 0.1779 - val_pred_layer_0_loss: 0.3974 - val_pred_layer_1_loss: 0.1834 - val_pred_layer_2_acc: 0.9519 - val_pred_layer_0_acc: 0.8241 - val_pred_layer_0_acc_1: 0.8641 - val_pred_layer_0_acc_2: 0.8791 - val_pred_layer_1_acc: 0.9217 - val_pred_layer_1_acc_1: 0.9440 - val_pred_layer_1_acc_2: 0.9506 - val_pred_layer_2_acc_1: 0.9519 - val_pred_layer_2_acc_2: 0.9519\n","\n","Epoch 00127: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 128/200\n","Learning rate:  1e-05\n"," - 294s - loss: 3.0400 - pred_layer_2_loss: 0.1209 - pred_layer_0_loss: 0.4767 - pred_layer_1_loss: 0.1625 - pred_layer_2_acc: 0.9646 - pred_layer_0_acc: 0.7836 - pred_layer_0_acc_1: 0.8350 - pred_layer_0_acc_2: 0.8529 - pred_layer_1_acc: 0.9046 - pred_layer_1_acc_1: 0.9379 - pred_layer_1_acc_2: 0.9540 - pred_layer_2_acc_1: 0.9638 - pred_layer_2_acc_2: 0.9648 - val_loss: 2.9181 - val_pred_layer_2_loss: 0.1783 - val_pred_layer_0_loss: 0.3982 - val_pred_layer_1_loss: 0.1842 - val_pred_layer_2_acc: 0.9521 - val_pred_layer_0_acc: 0.8232 - val_pred_layer_0_acc_1: 0.8644 - val_pred_layer_0_acc_2: 0.8795 - val_pred_layer_1_acc: 0.9214 - val_pred_layer_1_acc_1: 0.9441 - val_pred_layer_1_acc_2: 0.9506 - val_pred_layer_2_acc_1: 0.9513 - val_pred_layer_2_acc_2: 0.9518\n","\n","Epoch 00128: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 129/200\n","Learning rate:  1e-05\n"," - 295s - loss: 3.0243 - pred_layer_2_loss: 0.1202 - pred_layer_0_loss: 0.4731 - pred_layer_1_loss: 0.1599 - pred_layer_2_acc: 0.9653 - pred_layer_0_acc: 0.7838 - pred_layer_0_acc_1: 0.8357 - pred_layer_0_acc_2: 0.8535 - pred_layer_1_acc: 0.9038 - pred_layer_1_acc_1: 0.9380 - pred_layer_1_acc_2: 0.9544 - pred_layer_2_acc_1: 0.9647 - pred_layer_2_acc_2: 0.9653 - val_loss: 2.9183 - val_pred_layer_2_loss: 0.1792 - val_pred_layer_0_loss: 0.3977 - val_pred_layer_1_loss: 0.1847 - val_pred_layer_2_acc: 0.9515 - val_pred_layer_0_acc: 0.8241 - val_pred_layer_0_acc_1: 0.8644 - val_pred_layer_0_acc_2: 0.8786 - val_pred_layer_1_acc: 0.9208 - val_pred_layer_1_acc_1: 0.9437 - val_pred_layer_1_acc_2: 0.9503 - val_pred_layer_2_acc_1: 0.9512 - val_pred_layer_2_acc_2: 0.9516\n","\n","Epoch 00129: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 130/200\n","Learning rate:  1e-05\n"," - 294s - loss: 3.0330 - pred_layer_2_loss: 0.1211 - pred_layer_0_loss: 0.4729 - pred_layer_1_loss: 0.1628 - pred_layer_2_acc: 0.9642 - pred_layer_0_acc: 0.7835 - pred_layer_0_acc_1: 0.8378 - pred_layer_0_acc_2: 0.8543 - pred_layer_1_acc: 0.9048 - pred_layer_1_acc_1: 0.9375 - pred_layer_1_acc_2: 0.9534 - pred_layer_2_acc_1: 0.9633 - pred_layer_2_acc_2: 0.9642 - val_loss: 2.9158 - val_pred_layer_2_loss: 0.1795 - val_pred_layer_0_loss: 0.3962 - val_pred_layer_1_loss: 0.1850 - val_pred_layer_2_acc: 0.9514 - val_pred_layer_0_acc: 0.8237 - val_pred_layer_0_acc_1: 0.8647 - val_pred_layer_0_acc_2: 0.8798 - val_pred_layer_1_acc: 0.9209 - val_pred_layer_1_acc_1: 0.9438 - val_pred_layer_1_acc_2: 0.9501 - val_pred_layer_2_acc_1: 0.9511 - val_pred_layer_2_acc_2: 0.9513\n","\n","Epoch 00130: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 131/200\n","Learning rate:  1e-05\n"," - 291s - loss: 3.0311 - pred_layer_2_loss: 0.1206 - pred_layer_0_loss: 0.4743 - pred_layer_1_loss: 0.1611 - pred_layer_2_acc: 0.9645 - pred_layer_0_acc: 0.7841 - pred_layer_0_acc_1: 0.8374 - pred_layer_0_acc_2: 0.8536 - pred_layer_1_acc: 0.9048 - pred_layer_1_acc_1: 0.9376 - pred_layer_1_acc_2: 0.9542 - pred_layer_2_acc_1: 0.9637 - pred_layer_2_acc_2: 0.9644 - val_loss: 2.9133 - val_pred_layer_2_loss: 0.1787 - val_pred_layer_0_loss: 0.3964 - val_pred_layer_1_loss: 0.1845 - val_pred_layer_2_acc: 0.9515 - val_pred_layer_0_acc: 0.8240 - val_pred_layer_0_acc_1: 0.8644 - val_pred_layer_0_acc_2: 0.8799 - val_pred_layer_1_acc: 0.9214 - val_pred_layer_1_acc_1: 0.9440 - val_pred_layer_1_acc_2: 0.9500 - val_pred_layer_2_acc_1: 0.9511 - val_pred_layer_2_acc_2: 0.9516\n","\n","Epoch 00131: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 132/200\n","Learning rate:  1e-05\n"," - 292s - loss: 3.0421 - pred_layer_2_loss: 0.1209 - pred_layer_0_loss: 0.4752 - pred_layer_1_loss: 0.1624 - pred_layer_2_acc: 0.9654 - pred_layer_0_acc: 0.7823 - pred_layer_0_acc_1: 0.8364 - pred_layer_0_acc_2: 0.8539 - pred_layer_1_acc: 0.9027 - pred_layer_1_acc_1: 0.9372 - pred_layer_1_acc_2: 0.9542 - pred_layer_2_acc_1: 0.9645 - pred_layer_2_acc_2: 0.9652 - val_loss: 2.9214 - val_pred_layer_2_loss: 0.1790 - val_pred_layer_0_loss: 0.3981 - val_pred_layer_1_loss: 0.1849 - val_pred_layer_2_acc: 0.9523 - val_pred_layer_0_acc: 0.8230 - val_pred_layer_0_acc_1: 0.8643 - val_pred_layer_0_acc_2: 0.8790 - val_pred_layer_1_acc: 0.9213 - val_pred_layer_1_acc_1: 0.9438 - val_pred_layer_1_acc_2: 0.9500 - val_pred_layer_2_acc_1: 0.9514 - val_pred_layer_2_acc_2: 0.9519\n","\n","Epoch 00132: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 133/200\n","Learning rate:  1e-05\n"," - 294s - loss: 3.0253 - pred_layer_2_loss: 0.1195 - pred_layer_0_loss: 0.4730 - pred_layer_1_loss: 0.1613 - pred_layer_2_acc: 0.9657 - pred_layer_0_acc: 0.7853 - pred_layer_0_acc_1: 0.8358 - pred_layer_0_acc_2: 0.8540 - pred_layer_1_acc: 0.9036 - pred_layer_1_acc_1: 0.9370 - pred_layer_1_acc_2: 0.9542 - pred_layer_2_acc_1: 0.9653 - pred_layer_2_acc_2: 0.9657 - val_loss: 2.9211 - val_pred_layer_2_loss: 0.1794 - val_pred_layer_0_loss: 0.3976 - val_pred_layer_1_loss: 0.1852 - val_pred_layer_2_acc: 0.9519 - val_pred_layer_0_acc: 0.8234 - val_pred_layer_0_acc_1: 0.8645 - val_pred_layer_0_acc_2: 0.8789 - val_pred_layer_1_acc: 0.9208 - val_pred_layer_1_acc_1: 0.9436 - val_pred_layer_1_acc_2: 0.9496 - val_pred_layer_2_acc_1: 0.9513 - val_pred_layer_2_acc_2: 0.9520\n","\n","Epoch 00133: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 134/200\n","Learning rate:  1e-05\n"," - 292s - loss: 3.0256 - pred_layer_2_loss: 0.1218 - pred_layer_0_loss: 0.4713 - pred_layer_1_loss: 0.1607 - pred_layer_2_acc: 0.9647 - pred_layer_0_acc: 0.7845 - pred_layer_0_acc_1: 0.8366 - pred_layer_0_acc_2: 0.8535 - pred_layer_1_acc: 0.9039 - pred_layer_1_acc_1: 0.9379 - pred_layer_1_acc_2: 0.9544 - pred_layer_2_acc_1: 0.9641 - pred_layer_2_acc_2: 0.9647 - val_loss: 2.9098 - val_pred_layer_2_loss: 0.1779 - val_pred_layer_0_loss: 0.3969 - val_pred_layer_1_loss: 0.1836 - val_pred_layer_2_acc: 0.9521 - val_pred_layer_0_acc: 0.8241 - val_pred_layer_0_acc_1: 0.8648 - val_pred_layer_0_acc_2: 0.8791 - val_pred_layer_1_acc: 0.9213 - val_pred_layer_1_acc_1: 0.9442 - val_pred_layer_1_acc_2: 0.9503 - val_pred_layer_2_acc_1: 0.9517 - val_pred_layer_2_acc_2: 0.9522\n","\n","Epoch 00134: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 135/200\n","Learning rate:  1e-05\n"," - 292s - loss: 3.0270 - pred_layer_2_loss: 0.1213 - pred_layer_0_loss: 0.4726 - pred_layer_1_loss: 0.1615 - pred_layer_2_acc: 0.9649 - pred_layer_0_acc: 0.7850 - pred_layer_0_acc_1: 0.8368 - pred_layer_0_acc_2: 0.8549 - pred_layer_1_acc: 0.9050 - pred_layer_1_acc_1: 0.9375 - pred_layer_1_acc_2: 0.9540 - pred_layer_2_acc_1: 0.9639 - pred_layer_2_acc_2: 0.9649 - val_loss: 2.9188 - val_pred_layer_2_loss: 0.1788 - val_pred_layer_0_loss: 0.3985 - val_pred_layer_1_loss: 0.1846 - val_pred_layer_2_acc: 0.9514 - val_pred_layer_0_acc: 0.8230 - val_pred_layer_0_acc_1: 0.8636 - val_pred_layer_0_acc_2: 0.8783 - val_pred_layer_1_acc: 0.9212 - val_pred_layer_1_acc_1: 0.9437 - val_pred_layer_1_acc_2: 0.9506 - val_pred_layer_2_acc_1: 0.9511 - val_pred_layer_2_acc_2: 0.9515\n","\n","Epoch 00135: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 136/200\n","Learning rate:  1e-05\n"," - 292s - loss: 3.0222 - pred_layer_2_loss: 0.1199 - pred_layer_0_loss: 0.4714 - pred_layer_1_loss: 0.1609 - pred_layer_2_acc: 0.9646 - pred_layer_0_acc: 0.7838 - pred_layer_0_acc_1: 0.8364 - pred_layer_0_acc_2: 0.8543 - pred_layer_1_acc: 0.9038 - pred_layer_1_acc_1: 0.9380 - pred_layer_1_acc_2: 0.9544 - pred_layer_2_acc_1: 0.9641 - pred_layer_2_acc_2: 0.9646 - val_loss: 2.9254 - val_pred_layer_2_loss: 0.1803 - val_pred_layer_0_loss: 0.3984 - val_pred_layer_1_loss: 0.1853 - val_pred_layer_2_acc: 0.9512 - val_pred_layer_0_acc: 0.8231 - val_pred_layer_0_acc_1: 0.8636 - val_pred_layer_0_acc_2: 0.8787 - val_pred_layer_1_acc: 0.9209 - val_pred_layer_1_acc_1: 0.9434 - val_pred_layer_1_acc_2: 0.9504 - val_pred_layer_2_acc_1: 0.9506 - val_pred_layer_2_acc_2: 0.9510\n","\n","Epoch 00136: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 137/200\n","Learning rate:  1e-05\n"," - 294s - loss: 3.0292 - pred_layer_2_loss: 0.1196 - pred_layer_0_loss: 0.4746 - pred_layer_1_loss: 0.1619 - pred_layer_2_acc: 0.9649 - pred_layer_0_acc: 0.7840 - pred_layer_0_acc_1: 0.8366 - pred_layer_0_acc_2: 0.8536 - pred_layer_1_acc: 0.9034 - pred_layer_1_acc_1: 0.9381 - pred_layer_1_acc_2: 0.9543 - pred_layer_2_acc_1: 0.9643 - pred_layer_2_acc_2: 0.9649 - val_loss: 2.9188 - val_pred_layer_2_loss: 0.1792 - val_pred_layer_0_loss: 0.3984 - val_pred_layer_1_loss: 0.1851 - val_pred_layer_2_acc: 0.9521 - val_pred_layer_0_acc: 0.8238 - val_pred_layer_0_acc_1: 0.8642 - val_pred_layer_0_acc_2: 0.8781 - val_pred_layer_1_acc: 0.9213 - val_pred_layer_1_acc_1: 0.9433 - val_pred_layer_1_acc_2: 0.9503 - val_pred_layer_2_acc_1: 0.9509 - val_pred_layer_2_acc_2: 0.9518\n","\n","Epoch 00137: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 138/200\n","Learning rate:  1e-05\n"," - 293s - loss: 3.0132 - pred_layer_2_loss: 0.1189 - pred_layer_0_loss: 0.4712 - pred_layer_1_loss: 0.1599 - pred_layer_2_acc: 0.9653 - pred_layer_0_acc: 0.7847 - pred_layer_0_acc_1: 0.8366 - pred_layer_0_acc_2: 0.8553 - pred_layer_1_acc: 0.9047 - pred_layer_1_acc_1: 0.9379 - pred_layer_1_acc_2: 0.9538 - pred_layer_2_acc_1: 0.9643 - pred_layer_2_acc_2: 0.9653 - val_loss: 2.9241 - val_pred_layer_2_loss: 0.1802 - val_pred_layer_0_loss: 0.3984 - val_pred_layer_1_loss: 0.1858 - val_pred_layer_2_acc: 0.9518 - val_pred_layer_0_acc: 0.8243 - val_pred_layer_0_acc_1: 0.8639 - val_pred_layer_0_acc_2: 0.8790 - val_pred_layer_1_acc: 0.9214 - val_pred_layer_1_acc_1: 0.9435 - val_pred_layer_1_acc_2: 0.9497 - val_pred_layer_2_acc_1: 0.9511 - val_pred_layer_2_acc_2: 0.9516\n","\n","Epoch 00138: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 139/200\n","Learning rate:  1e-05\n"," - 294s - loss: 3.0138 - pred_layer_2_loss: 0.1189 - pred_layer_0_loss: 0.4718 - pred_layer_1_loss: 0.1599 - pred_layer_2_acc: 0.9652 - pred_layer_0_acc: 0.7850 - pred_layer_0_acc_1: 0.8353 - pred_layer_0_acc_2: 0.8542 - pred_layer_1_acc: 0.9053 - pred_layer_1_acc_1: 0.9390 - pred_layer_1_acc_2: 0.9549 - pred_layer_2_acc_1: 0.9642 - pred_layer_2_acc_2: 0.9650 - val_loss: 2.9222 - val_pred_layer_2_loss: 0.1797 - val_pred_layer_0_loss: 0.3982 - val_pred_layer_1_loss: 0.1852 - val_pred_layer_2_acc: 0.9518 - val_pred_layer_0_acc: 0.8236 - val_pred_layer_0_acc_1: 0.8641 - val_pred_layer_0_acc_2: 0.8793 - val_pred_layer_1_acc: 0.9212 - val_pred_layer_1_acc_1: 0.9436 - val_pred_layer_1_acc_2: 0.9499 - val_pred_layer_2_acc_1: 0.9516 - val_pred_layer_2_acc_2: 0.9517\n","\n","Epoch 00139: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 140/200\n","Learning rate:  1e-05\n"," - 294s - loss: 3.0024 - pred_layer_2_loss: 0.1165 - pred_layer_0_loss: 0.4708 - pred_layer_1_loss: 0.1584 - pred_layer_2_acc: 0.9665 - pred_layer_0_acc: 0.7847 - pred_layer_0_acc_1: 0.8377 - pred_layer_0_acc_2: 0.8553 - pred_layer_1_acc: 0.9049 - pred_layer_1_acc_1: 0.9395 - pred_layer_1_acc_2: 0.9550 - pred_layer_2_acc_1: 0.9658 - pred_layer_2_acc_2: 0.9664 - val_loss: 2.9179 - val_pred_layer_2_loss: 0.1802 - val_pred_layer_0_loss: 0.3967 - val_pred_layer_1_loss: 0.1855 - val_pred_layer_2_acc: 0.9518 - val_pred_layer_0_acc: 0.8244 - val_pred_layer_0_acc_1: 0.8645 - val_pred_layer_0_acc_2: 0.8799 - val_pred_layer_1_acc: 0.9217 - val_pred_layer_1_acc_1: 0.9437 - val_pred_layer_1_acc_2: 0.9497 - val_pred_layer_2_acc_1: 0.9514 - val_pred_layer_2_acc_2: 0.9519\n","\n","Epoch 00140: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 141/200\n","Learning rate:  1e-05\n"," - 293s - loss: 3.0192 - pred_layer_2_loss: 0.1198 - pred_layer_0_loss: 0.4708 - pred_layer_1_loss: 0.1620 - pred_layer_2_acc: 0.9649 - pred_layer_0_acc: 0.7849 - pred_layer_0_acc_1: 0.8375 - pred_layer_0_acc_2: 0.8542 - pred_layer_1_acc: 0.9044 - pred_layer_1_acc_1: 0.9371 - pred_layer_1_acc_2: 0.9536 - pred_layer_2_acc_1: 0.9640 - pred_layer_2_acc_2: 0.9649 - val_loss: 2.9219 - val_pred_layer_2_loss: 0.1806 - val_pred_layer_0_loss: 0.3973 - val_pred_layer_1_loss: 0.1856 - val_pred_layer_2_acc: 0.9512 - val_pred_layer_0_acc: 0.8238 - val_pred_layer_0_acc_1: 0.8650 - val_pred_layer_0_acc_2: 0.8792 - val_pred_layer_1_acc: 0.9212 - val_pred_layer_1_acc_1: 0.9433 - val_pred_layer_1_acc_2: 0.9497 - val_pred_layer_2_acc_1: 0.9511 - val_pred_layer_2_acc_2: 0.9515\n","\n","Epoch 00141: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 142/200\n","Learning rate:  1e-05\n"," - 293s - loss: 3.0369 - pred_layer_2_loss: 0.1202 - pred_layer_0_loss: 0.4751 - pred_layer_1_loss: 0.1616 - pred_layer_2_acc: 0.9653 - pred_layer_0_acc: 0.7845 - pred_layer_0_acc_1: 0.8368 - pred_layer_0_acc_2: 0.8536 - pred_layer_1_acc: 0.9049 - pred_layer_1_acc_1: 0.9376 - pred_layer_1_acc_2: 0.9544 - pred_layer_2_acc_1: 0.9648 - pred_layer_2_acc_2: 0.9655 - val_loss: 2.9221 - val_pred_layer_2_loss: 0.1808 - val_pred_layer_0_loss: 0.3975 - val_pred_layer_1_loss: 0.1854 - val_pred_layer_2_acc: 0.9517 - val_pred_layer_0_acc: 0.8242 - val_pred_layer_0_acc_1: 0.8645 - val_pred_layer_0_acc_2: 0.8792 - val_pred_layer_1_acc: 0.9214 - val_pred_layer_1_acc_1: 0.9435 - val_pred_layer_1_acc_2: 0.9499 - val_pred_layer_2_acc_1: 0.9504 - val_pred_layer_2_acc_2: 0.9519\n","\n","Epoch 00142: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 143/200\n","Learning rate:  1e-05\n"," - 293s - loss: 3.0281 - pred_layer_2_loss: 0.1201 - pred_layer_0_loss: 0.4737 - pred_layer_1_loss: 0.1601 - pred_layer_2_acc: 0.9651 - pred_layer_0_acc: 0.7832 - pred_layer_0_acc_1: 0.8358 - pred_layer_0_acc_2: 0.8539 - pred_layer_1_acc: 0.9049 - pred_layer_1_acc_1: 0.9383 - pred_layer_1_acc_2: 0.9542 - pred_layer_2_acc_1: 0.9648 - pred_layer_2_acc_2: 0.9652 - val_loss: 2.9208 - val_pred_layer_2_loss: 0.1797 - val_pred_layer_0_loss: 0.3983 - val_pred_layer_1_loss: 0.1846 - val_pred_layer_2_acc: 0.9517 - val_pred_layer_0_acc: 0.8238 - val_pred_layer_0_acc_1: 0.8636 - val_pred_layer_0_acc_2: 0.8792 - val_pred_layer_1_acc: 0.9209 - val_pred_layer_1_acc_1: 0.9436 - val_pred_layer_1_acc_2: 0.9504 - val_pred_layer_2_acc_1: 0.9512 - val_pred_layer_2_acc_2: 0.9517\n","\n","Epoch 00143: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 144/200\n","Learning rate:  1e-05\n"," - 292s - loss: 3.0234 - pred_layer_2_loss: 0.1190 - pred_layer_0_loss: 0.4734 - pred_layer_1_loss: 0.1605 - pred_layer_2_acc: 0.9659 - pred_layer_0_acc: 0.7851 - pred_layer_0_acc_1: 0.8368 - pred_layer_0_acc_2: 0.8541 - pred_layer_1_acc: 0.9032 - pred_layer_1_acc_1: 0.9376 - pred_layer_1_acc_2: 0.9540 - pred_layer_2_acc_1: 0.9648 - pred_layer_2_acc_2: 0.9658 - val_loss: 2.9203 - val_pred_layer_2_loss: 0.1794 - val_pred_layer_0_loss: 0.3984 - val_pred_layer_1_loss: 0.1844 - val_pred_layer_2_acc: 0.9521 - val_pred_layer_0_acc: 0.8238 - val_pred_layer_0_acc_1: 0.8644 - val_pred_layer_0_acc_2: 0.8787 - val_pred_layer_1_acc: 0.9214 - val_pred_layer_1_acc_1: 0.9436 - val_pred_layer_1_acc_2: 0.9498 - val_pred_layer_2_acc_1: 0.9513 - val_pred_layer_2_acc_2: 0.9520\n","\n","Epoch 00144: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 145/200\n","Learning rate:  1e-05\n"," - 293s - loss: 3.0154 - pred_layer_2_loss: 0.1196 - pred_layer_0_loss: 0.4701 - pred_layer_1_loss: 0.1604 - pred_layer_2_acc: 0.9655 - pred_layer_0_acc: 0.7847 - pred_layer_0_acc_1: 0.8364 - pred_layer_0_acc_2: 0.8554 - pred_layer_1_acc: 0.9053 - pred_layer_1_acc_1: 0.9387 - pred_layer_1_acc_2: 0.9544 - pred_layer_2_acc_1: 0.9646 - pred_layer_2_acc_2: 0.9655 - val_loss: 2.9188 - val_pred_layer_2_loss: 0.1789 - val_pred_layer_0_loss: 0.3989 - val_pred_layer_1_loss: 0.1844 - val_pred_layer_2_acc: 0.9524 - val_pred_layer_0_acc: 0.8232 - val_pred_layer_0_acc_1: 0.8640 - val_pred_layer_0_acc_2: 0.8781 - val_pred_layer_1_acc: 0.9214 - val_pred_layer_1_acc_1: 0.9435 - val_pred_layer_1_acc_2: 0.9501 - val_pred_layer_2_acc_1: 0.9515 - val_pred_layer_2_acc_2: 0.9523\n","\n","Epoch 00145: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 146/200\n","Learning rate:  1e-05\n"," - 295s - loss: 3.0325 - pred_layer_2_loss: 0.1198 - pred_layer_0_loss: 0.4737 - pred_layer_1_loss: 0.1629 - pred_layer_2_acc: 0.9658 - pred_layer_0_acc: 0.7842 - pred_layer_0_acc_1: 0.8360 - pred_layer_0_acc_2: 0.8551 - pred_layer_1_acc: 0.9036 - pred_layer_1_acc_1: 0.9372 - pred_layer_1_acc_2: 0.9538 - pred_layer_2_acc_1: 0.9653 - pred_layer_2_acc_2: 0.9657 - val_loss: 2.9158 - val_pred_layer_2_loss: 0.1791 - val_pred_layer_0_loss: 0.3983 - val_pred_layer_1_loss: 0.1844 - val_pred_layer_2_acc: 0.9520 - val_pred_layer_0_acc: 0.8234 - val_pred_layer_0_acc_1: 0.8642 - val_pred_layer_0_acc_2: 0.8786 - val_pred_layer_1_acc: 0.9218 - val_pred_layer_1_acc_1: 0.9435 - val_pred_layer_1_acc_2: 0.9500 - val_pred_layer_2_acc_1: 0.9514 - val_pred_layer_2_acc_2: 0.9520\n","\n","Epoch 00146: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 147/200\n","Learning rate:  1e-05\n"," - 292s - loss: 3.0299 - pred_layer_2_loss: 0.1177 - pred_layer_0_loss: 0.4744 - pred_layer_1_loss: 0.1616 - pred_layer_2_acc: 0.9654 - pred_layer_0_acc: 0.7838 - pred_layer_0_acc_1: 0.8351 - pred_layer_0_acc_2: 0.8526 - pred_layer_1_acc: 0.9031 - pred_layer_1_acc_1: 0.9368 - pred_layer_1_acc_2: 0.9532 - pred_layer_2_acc_1: 0.9646 - pred_layer_2_acc_2: 0.9656 - val_loss: 2.9183 - val_pred_layer_2_loss: 0.1799 - val_pred_layer_0_loss: 0.3979 - val_pred_layer_1_loss: 0.1848 - val_pred_layer_2_acc: 0.9520 - val_pred_layer_0_acc: 0.8239 - val_pred_layer_0_acc_1: 0.8642 - val_pred_layer_0_acc_2: 0.8789 - val_pred_layer_1_acc: 0.9217 - val_pred_layer_1_acc_1: 0.9434 - val_pred_layer_1_acc_2: 0.9501 - val_pred_layer_2_acc_1: 0.9513 - val_pred_layer_2_acc_2: 0.9519\n","\n","Epoch 00147: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 148/200\n","Learning rate:  1e-05\n"," - 292s - loss: 3.0174 - pred_layer_2_loss: 0.1181 - pred_layer_0_loss: 0.4737 - pred_layer_1_loss: 0.1601 - pred_layer_2_acc: 0.9661 - pred_layer_0_acc: 0.7836 - pred_layer_0_acc_1: 0.8358 - pred_layer_0_acc_2: 0.8535 - pred_layer_1_acc: 0.9054 - pred_layer_1_acc_1: 0.9387 - pred_layer_1_acc_2: 0.9545 - pred_layer_2_acc_1: 0.9652 - pred_layer_2_acc_2: 0.9660 - val_loss: 2.9254 - val_pred_layer_2_loss: 0.1813 - val_pred_layer_0_loss: 0.3985 - val_pred_layer_1_loss: 0.1854 - val_pred_layer_2_acc: 0.9512 - val_pred_layer_0_acc: 0.8238 - val_pred_layer_0_acc_1: 0.8636 - val_pred_layer_0_acc_2: 0.8785 - val_pred_layer_1_acc: 0.9215 - val_pred_layer_1_acc_1: 0.9434 - val_pred_layer_1_acc_2: 0.9499 - val_pred_layer_2_acc_1: 0.9509 - val_pred_layer_2_acc_2: 0.9509\n","\n","Epoch 00148: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 149/200\n","Learning rate:  1e-05\n"," - 294s - loss: 3.0314 - pred_layer_2_loss: 0.1204 - pred_layer_0_loss: 0.4753 - pred_layer_1_loss: 0.1617 - pred_layer_2_acc: 0.9646 - pred_layer_0_acc: 0.7859 - pred_layer_0_acc_1: 0.8357 - pred_layer_0_acc_2: 0.8529 - pred_layer_1_acc: 0.9042 - pred_layer_1_acc_1: 0.9376 - pred_layer_1_acc_2: 0.9540 - pred_layer_2_acc_1: 0.9639 - pred_layer_2_acc_2: 0.9645 - val_loss: 2.9171 - val_pred_layer_2_loss: 0.1802 - val_pred_layer_0_loss: 0.3972 - val_pred_layer_1_loss: 0.1848 - val_pred_layer_2_acc: 0.9518 - val_pred_layer_0_acc: 0.8236 - val_pred_layer_0_acc_1: 0.8642 - val_pred_layer_0_acc_2: 0.8790 - val_pred_layer_1_acc: 0.9214 - val_pred_layer_1_acc_1: 0.9435 - val_pred_layer_1_acc_2: 0.9501 - val_pred_layer_2_acc_1: 0.9512 - val_pred_layer_2_acc_2: 0.9518\n","\n","Epoch 00149: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 150/200\n","Learning rate:  1e-05\n"," - 293s - loss: 3.0270 - pred_layer_2_loss: 0.1188 - pred_layer_0_loss: 0.4748 - pred_layer_1_loss: 0.1616 - pred_layer_2_acc: 0.9656 - pred_layer_0_acc: 0.7844 - pred_layer_0_acc_1: 0.8365 - pred_layer_0_acc_2: 0.8545 - pred_layer_1_acc: 0.9040 - pred_layer_1_acc_1: 0.9381 - pred_layer_1_acc_2: 0.9538 - pred_layer_2_acc_1: 0.9651 - pred_layer_2_acc_2: 0.9656 - val_loss: 2.9170 - val_pred_layer_2_loss: 0.1802 - val_pred_layer_0_loss: 0.3967 - val_pred_layer_1_loss: 0.1849 - val_pred_layer_2_acc: 0.9516 - val_pred_layer_0_acc: 0.8236 - val_pred_layer_0_acc_1: 0.8645 - val_pred_layer_0_acc_2: 0.8795 - val_pred_layer_1_acc: 0.9215 - val_pred_layer_1_acc_1: 0.9433 - val_pred_layer_1_acc_2: 0.9499 - val_pred_layer_2_acc_1: 0.9511 - val_pred_layer_2_acc_2: 0.9516\n","\n","Epoch 00150: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 151/200\n","Learning rate:  1e-05\n"," - 293s - loss: 3.0298 - pred_layer_2_loss: 0.1195 - pred_layer_0_loss: 0.4755 - pred_layer_1_loss: 0.1616 - pred_layer_2_acc: 0.9651 - pred_layer_0_acc: 0.7833 - pred_layer_0_acc_1: 0.8361 - pred_layer_0_acc_2: 0.8539 - pred_layer_1_acc: 0.9044 - pred_layer_1_acc_1: 0.9378 - pred_layer_1_acc_2: 0.9540 - pred_layer_2_acc_1: 0.9642 - pred_layer_2_acc_2: 0.9651 - val_loss: 2.9261 - val_pred_layer_2_loss: 0.1822 - val_pred_layer_0_loss: 0.3972 - val_pred_layer_1_loss: 0.1862 - val_pred_layer_2_acc: 0.9510 - val_pred_layer_0_acc: 0.8239 - val_pred_layer_0_acc_1: 0.8641 - val_pred_layer_0_acc_2: 0.8793 - val_pred_layer_1_acc: 0.9213 - val_pred_layer_1_acc_1: 0.9431 - val_pred_layer_1_acc_2: 0.9495 - val_pred_layer_2_acc_1: 0.9503 - val_pred_layer_2_acc_2: 0.9510\n","\n","Epoch 00151: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 152/200\n","Learning rate:  1e-05\n"," - 292s - loss: 3.0183 - pred_layer_2_loss: 0.1177 - pred_layer_0_loss: 0.4744 - pred_layer_1_loss: 0.1602 - pred_layer_2_acc: 0.9655 - pred_layer_0_acc: 0.7855 - pred_layer_0_acc_1: 0.8373 - pred_layer_0_acc_2: 0.8540 - pred_layer_1_acc: 0.9042 - pred_layer_1_acc_1: 0.9378 - pred_layer_1_acc_2: 0.9532 - pred_layer_2_acc_1: 0.9652 - pred_layer_2_acc_2: 0.9654 - val_loss: 2.9231 - val_pred_layer_2_loss: 0.1816 - val_pred_layer_0_loss: 0.3974 - val_pred_layer_1_loss: 0.1860 - val_pred_layer_2_acc: 0.9508 - val_pred_layer_0_acc: 0.8243 - val_pred_layer_0_acc_1: 0.8629 - val_pred_layer_0_acc_2: 0.8790 - val_pred_layer_1_acc: 0.9214 - val_pred_layer_1_acc_1: 0.9430 - val_pred_layer_1_acc_2: 0.9493 - val_pred_layer_2_acc_1: 0.9505 - val_pred_layer_2_acc_2: 0.9506\n","\n","Epoch 00152: val_pred_layer_2_acc did not improve from 0.95386\n","Epoch 153/200\n","Learning rate:  1e-05\n"],"name":"stdout"}]},{"metadata":{"id":"3_sqnXY5Oh2f","colab_type":"code","colab":{}},"cell_type":"code","source":["model.save_weights('/content/gdrive/My Drive/colab/weights/svhn_share_boost_oct18.h5')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"91F_9LrrlAf-","colab_type":"code","colab":{}},"cell_type":"code","source":["1+2"],"execution_count":0,"outputs":[]},{"metadata":{"id":"063Y3g6o3q16","colab_type":"text"},"cell_type":"markdown","source":["Done"]}]}